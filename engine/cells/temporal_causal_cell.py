# -*- coding: utf-8 -*-
"""TemporalCausalCell â€” ì‹œê³„ì—´ ì¸ê³¼ì¶”ë¡ .

ì‹œê³„ì—´ ë°ì´í„°ì—ì„œ ì¸ê³¼ ê´€ê³„ë¥¼ ë¶„ì„í•˜ëŠ” ì„¸ ê°€ì§€ ë°©ë²•ë¡ :

- **Granger Causality**: ì‹œì°¨(Lag) ê¸°ë°˜ ì¸ê³¼ ë°©í–¥ ê²€ì •
- **CausalImpact (í•©ì„± í†µì œ)**: ê°œì… ì „í›„ ë°˜ì‚¬ì‹¤ ì‹œë‚˜ë¦¬ì˜¤ ì¶”ì •
- **Lag Correlation Analysis**: ìµœì  ì‹œì°¨ ìë™ íƒìƒ‰

Phase 10-2: ì‹œê³„ì—´ ì¸ê³¼ì¶”ë¡ .
"""

from __future__ import annotations

import logging
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional

import numpy as np
import pandas as pd

from engine.cells.base_cell import BaseCell
from engine.config import WhyLabConfig

logger = logging.getLogger(__name__)


@dataclass
class GrangerResult:
    """Granger ì¸ê³¼ ê²€ì • ê²°ê³¼."""
    cause_col: str = ""
    effect_col: str = ""
    max_lag: int = 5
    best_lag: int = 1
    f_stat: float = 0.0
    p_value: float = 1.0
    is_causal: bool = False
    interpretation: str = ""


@dataclass
class CausalImpactResult:
    """ì¸ê³¼ ì˜í–¥(CausalImpact) ì¶”ì • ê²°ê³¼."""
    pre_mean: float = 0.0
    post_mean: float = 0.0
    predicted_post_mean: float = 0.0
    absolute_effect: float = 0.0
    relative_effect: float = 0.0
    p_value: float = 1.0
    significant: bool = False
    intervention_point: int = 0
    interpretation: str = ""


@dataclass
class LagCorrelationResult:
    """ì‹œì°¨ ìƒê´€ ë¶„ì„ ê²°ê³¼."""
    optimal_lag: int = 0
    max_correlation: float = 0.0
    lag_correlations: Dict[int, float] = field(default_factory=dict)
    interpretation: str = ""


class TemporalCausalCell(BaseCell):
    """ì‹œê³„ì—´ ì¸ê³¼ì¶”ë¡  ì…€.

    ì‹œê³„ì—´ êµ¬ì¡°ë¥¼ ê°€ì§„ ë°ì´í„°ì—ì„œ ì¸ê³¼ ê´€ê³„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
    ìë™ìœ¼ë¡œ ì‹œê³„ì—´ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ê³ , ì ìš© ê°€ëŠ¥í•œ ë°©ë²•ë¡ ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    """

    def __init__(self, config: WhyLabConfig) -> None:
        super().__init__(name="temporal_causal_cell", config=config)

    def execute(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """ì‹œê³„ì—´ ì¸ê³¼ ë¶„ì„ ì‹¤í–‰."""
        df = inputs.get("dataframe")
        if df is None:
            self.logger.warning("ë°ì´í„°í”„ë ˆì„ ì—†ìŒ â†’ TemporalCausal ê±´ë„ˆëœ€")
            return inputs

        treatment_col = inputs.get("treatment_col", "treatment")
        outcome_col = inputs.get("outcome_col", "outcome")
        time_col = inputs.get("time_col")
        feature_names = inputs.get("feature_names", [])

        # ì‹œê³„ì—´ ì—¬ë¶€ ìë™ ê°ì§€
        is_temporal = self._detect_temporal(df, time_col)
        if not is_temporal and time_col is None:
            self.logger.info("â„¹ï¸ ì‹œê³„ì—´ êµ¬ì¡° ë¯¸ê°ì§€ â†’ TemporalCausal ê±´ë„ˆëœ€")
            return inputs

        results = {}

        # Granger ì¸ê³¼ ê²€ì •
        if treatment_col in df.columns and outcome_col in df.columns:
            self.logger.info("â±ï¸ Granger ì¸ê³¼ ê²€ì • ì‹œì‘")
            granger = self._granger_test(df, treatment_col, outcome_col)
            results["granger"] = granger

            # ì—­ë°©í–¥ë„ ì²´í¬ (ì–‘ë°©í–¥ Granger)
            granger_reverse = self._granger_test(df, outcome_col, treatment_col)
            results["granger_reverse"] = granger_reverse

        # ì‹œì°¨ ìƒê´€ ë¶„ì„
        if treatment_col in df.columns and outcome_col in df.columns:
            self.logger.info("ğŸ“ˆ ì‹œì°¨ ìƒê´€ ë¶„ì„ ì‹œì‘")
            lag_corr = self._lag_correlation(df, treatment_col, outcome_col)
            results["lag_correlation"] = lag_corr

        # CausalImpact (ê°œì… ì‹œì ì´ ìˆëŠ” ê²½ìš°)
        intervention_point = inputs.get("intervention_point")
        if intervention_point is not None and outcome_col in df.columns:
            self.logger.info("ğŸ“Š CausalImpact ë¶„ì„ ì‹œì‘ (ê°œì…: %s)", intervention_point)
            impact = self._causal_impact(df, outcome_col, intervention_point, feature_names)
            results["causal_impact"] = impact
        elif treatment_col in df.columns and df[treatment_col].nunique() == 2:
            # ê°œì… ì‹œì  ìë™ ì¶”ì • (ì²˜ì¹˜ ë³€ìˆ˜ê°€ 0â†’1ë¡œ ë°”ë€ŒëŠ” ì‹œì )
            auto_point = self._detect_intervention_point(df, treatment_col)
            if auto_point is not None:
                self.logger.info("ğŸ” ê°œì… ì‹œì  ìë™ ê°ì§€: index=%d", auto_point)
                impact = self._causal_impact(df, outcome_col, auto_point, feature_names)
                results["causal_impact"] = impact

        methods_used = list(results.keys())
        if methods_used:
            self.logger.info("âœ… ì‹œê³„ì—´ ì¸ê³¼ ë¶„ì„ ì™„ë£Œ: %s", ", ".join(methods_used))

        return {
            **inputs,
            "temporal_causal": self._serialize(results),
        }

    def _detect_temporal(self, df: pd.DataFrame, time_col: Optional[str]) -> bool:
        """ë°ì´í„°ì˜ ì‹œê³„ì—´ êµ¬ì¡°ë¥¼ ìë™ ê°ì§€í•©ë‹ˆë‹¤."""
        if time_col and time_col in df.columns:
            return True

        # datetime ì¸ë±ìŠ¤ ì²´í¬
        if isinstance(df.index, pd.DatetimeIndex):
            return True

        # datetime ì»¬ëŸ¼ ì²´í¬
        for col in df.columns:
            if pd.api.types.is_datetime64_any_dtype(df[col]):
                return True

        # ìˆœì„œê°€ ìˆëŠ” ì •ìˆ˜ ì¸ë±ìŠ¤ (ì‹œê³„ì—´ ê°€ëŠ¥ì„±)
        if df.index.is_monotonic_increasing and len(df) > 50:
            return True

        return False

    def _granger_test(
        self, df: pd.DataFrame, cause_col: str, effect_col: str, max_lag: int = 5,
    ) -> GrangerResult:
        """Granger ì¸ê³¼ ê²€ì •.

        ì œí•œëœ ëª¨ë¸(ê³¼ê±° Yë§Œ)ê³¼ ë¹„ì œí•œ ëª¨ë¸(ê³¼ê±° Y + X)ì˜ ë¹„êµ.
        """
        from sklearn.linear_model import LinearRegression

        y = df[effect_col].values
        x = df[cause_col].values
        n = len(y)

        best_lag = 1
        best_f = 0.0
        best_p = 1.0

        for lag in range(1, min(max_lag + 1, n // 4)):
            # ì‹œì°¨ ë³€ìˆ˜ ìƒì„±
            Y = y[lag:]
            Y_lags = np.column_stack([y[lag - i - 1:n - i - 1] for i in range(lag)])
            X_lags = np.column_stack([x[lag - i - 1:n - i - 1] for i in range(lag)])

            # ì œí•œ ëª¨ë¸: Y ~ Y_lags
            restricted = LinearRegression().fit(Y_lags, Y)
            rss_r = np.sum((Y - restricted.predict(Y_lags)) ** 2)

            # ë¹„ì œí•œ ëª¨ë¸: Y ~ Y_lags + X_lags
            unrestricted_X = np.hstack([Y_lags, X_lags])
            unrestricted = LinearRegression().fit(unrestricted_X, Y)
            rss_u = np.sum((Y - unrestricted.predict(unrestricted_X)) ** 2)

            # F-ê²€ì •
            n_obs = len(Y)
            k = lag
            f_stat = ((rss_r - rss_u) / k) / (rss_u / max(1, n_obs - 2 * k - 1) + 1e-10)

            from scipy import stats as scipy_stats
            p_value = float(1 - scipy_stats.f.cdf(f_stat, k, max(1, n_obs - 2 * k - 1)))

            if f_stat > best_f:
                best_f = float(f_stat)
                best_p = p_value
                best_lag = lag

        is_causal = best_p < 0.05

        return GrangerResult(
            cause_col=cause_col, effect_col=effect_col,
            max_lag=max_lag, best_lag=best_lag,
            f_stat=best_f, p_value=best_p, is_causal=is_causal,
            interpretation=(
                f"Granger ê²€ì •: {cause_col} â†’ {effect_col} "
                f"{'âœ… ìœ ì˜ (ì¸ê³¼)' if is_causal else 'âŒ ë¹„ìœ ì˜'} "
                f"(F={best_f:.2f}, p={best_p:.4f}, lag={best_lag})"
            ),
        )

    def _lag_correlation(
        self, df: pd.DataFrame, x_col: str, y_col: str, max_lag: int = 10,
    ) -> LagCorrelationResult:
        """ì‹œì°¨ ìƒê´€ ë¶„ì„: ìµœì  ì‹œì°¨ë¥¼ ìë™ìœ¼ë¡œ ì°¾ìŠµë‹ˆë‹¤."""
        x = df[x_col].values
        y = df[y_col].values
        n = len(x)

        correlations = {}
        max_corr = 0.0
        optimal_lag = 0

        for lag in range(-max_lag, max_lag + 1):
            if lag >= 0:
                corr = float(np.corrcoef(x[:n - lag], y[lag:])[0, 1]) if lag < n else 0.0
            else:
                corr = float(np.corrcoef(x[-lag:], y[:n + lag])[0, 1]) if -lag < n else 0.0

            if np.isnan(corr):
                corr = 0.0
            correlations[lag] = corr

            if abs(corr) > abs(max_corr):
                max_corr = corr
                optimal_lag = lag

        return LagCorrelationResult(
            optimal_lag=optimal_lag,
            max_correlation=max_corr,
            lag_correlations=correlations,
            interpretation=(
                f"ìµœì  ì‹œì°¨={optimal_lag} (ìƒê´€={max_corr:.3f}). "
                f"{'ì–‘(+)' if optimal_lag > 0 else 'ìŒ(-)' if optimal_lag < 0 else 'ë™ì‹œ'} ì‹œì°¨ì—ì„œ ìµœëŒ€ ìƒê´€."
            ),
        )

    def _causal_impact(
        self,
        df: pd.DataFrame,
        outcome_col: str,
        intervention_point: int,
        covariates: List[str],
    ) -> CausalImpactResult:
        """ê°„ì´ CausalImpact ë¶„ì„ (í•©ì„± í†µì œ ê¸°ë°˜).

        ê°œì… ì „ ë°ì´í„°ë¡œ ëª¨ë¸ì„ í•™ìŠµí•˜ê³ , ê°œì… í›„ ë°˜ì‚¬ì‹¤ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
        """
        from sklearn.linear_model import BayesianRidge

        y = df[outcome_col].values
        pre_y = y[:intervention_point]
        post_y = y[intervention_point:]

        if len(pre_y) < 10 or len(post_y) < 3:
            return CausalImpactResult(
                intervention_point=intervention_point,
                interpretation="ê°œì… ì „/í›„ ë°ì´í„° ë¶€ì¡±",
            )

        # ê³µë³€ëŸ‰ì´ ìˆìœ¼ë©´ í•©ì„± í†µì œ, ì—†ìœ¼ë©´ ì‹œê³„ì—´ ì¶”ì„¸ ê¸°ë°˜
        cov_cols = [c for c in covariates if c in df.columns and c != outcome_col]

        if cov_cols:
            X = df[cov_cols].fillna(0).values
            X_pre = X[:intervention_point]
            X_post = X[intervention_point:]

            model = BayesianRidge()
            model.fit(X_pre, pre_y)
            predicted = model.predict(X_post)
        else:
            # ì¶”ì„¸ ê¸°ë°˜ ì˜ˆì¸¡ (ì‹œê°„ ì¸ë±ìŠ¤ë¥¼ íŠ¹ì„±ìœ¼ë¡œ)
            t_pre = np.arange(len(pre_y)).reshape(-1, 1)
            t_post = np.arange(len(pre_y), len(pre_y) + len(post_y)).reshape(-1, 1)

            model = BayesianRidge()
            model.fit(t_pre, pre_y)
            predicted = model.predict(t_post)

        # íš¨ê³¼ ì¶”ì •
        absolute_effect = float(np.mean(post_y) - np.mean(predicted))
        predicted_mean = float(np.mean(predicted))
        relative_effect = absolute_effect / (abs(predicted_mean) + 1e-10)

        # p-value ì¶”ì • (ë¶€íŠ¸ìŠ¤íŠ¸ë© ê°„ì´)
        residuals = pre_y - model.predict(
            (df[cov_cols].fillna(0).values[:intervention_point] if cov_cols
             else np.arange(len(pre_y)).reshape(-1, 1))
        )
        se = float(np.std(residuals))
        z = abs(absolute_effect) / (se + 1e-10)
        from scipy import stats as scipy_stats
        p_value = float(2 * (1 - scipy_stats.norm.cdf(z)))

        significant = p_value < 0.05

        return CausalImpactResult(
            pre_mean=float(np.mean(pre_y)),
            post_mean=float(np.mean(post_y)),
            predicted_post_mean=predicted_mean,
            absolute_effect=absolute_effect,
            relative_effect=relative_effect,
            p_value=p_value,
            significant=significant,
            intervention_point=intervention_point,
            interpretation=(
                f"CausalImpact: ì ˆëŒ€ íš¨ê³¼={absolute_effect:.4f}, "
                f"ìƒëŒ€ íš¨ê³¼={relative_effect:.1%}, "
                f"{'âœ… ìœ ì˜' if significant else 'âŒ ë¹„ìœ ì˜'} (p={p_value:.4f})"
            ),
        )

    def _detect_intervention_point(
        self, df: pd.DataFrame, treatment_col: str,
    ) -> Optional[int]:
        """ì²˜ì¹˜ ë³€ìˆ˜ê°€ 0â†’1ë¡œ ë³€í•˜ëŠ” ì‹œì ì„ ìë™ ê°ì§€í•©ë‹ˆë‹¤."""
        t = df[treatment_col].values
        for i in range(1, len(t)):
            if t[i] == 1 and t[i - 1] == 0:
                return i
        return None

    def _serialize(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """ê²°ê³¼ ì§ë ¬í™”."""
        serialized = {}
        for key, val in results.items():
            if hasattr(val, '__dict__'):
                d = {k: v for k, v in val.__dict__.items() if not k.startswith('_')}
                # numpy íƒ€ì… ë³€í™˜
                for k, v in d.items():
                    if isinstance(v, (np.integer, np.floating)):
                        d[k] = v.item()
                serialized[key] = d
            else:
                serialized[key] = val
        return serialized
