# -*- coding: utf-8 -*-
"""Phase 4: ì„€ë„ìš° ë°°í¬ ì»¨íŠ¸ë¡¤ëŸ¬.

CTO ë¹„í‰ ë°˜ì˜:
1. ë¹„ìš© ì„œí‚· ë¸Œë ˆì´ì»¤ â€” ARES ë”¥ ê°ì‚¬ ì¼ì¼ í† í° ìƒí•œ
2. Dry-run ì„€ë„ìš° ëª¨ë“œ â€” Î¶ ë¯¸ì ìš© ëª¨ë‹ˆí„°ë§

Reviewer ê¸°ì—¬:
- ì‹¤ì œ ë¼ì´ë¸Œ ë°ì´í„°ë¡œ "ë¬´ì˜¤ì—¼(No Data Leakage)" ì‹¤ì¦
"""

from __future__ import annotations

import hashlib
import json
import logging
import os
import time
from dataclasses import dataclass, field
from enum import Enum
from typing import Any, Callable, Dict, List, Optional

logger = logging.getLogger("whylab.deploy.shadow")

# Supabase í™˜ê²½ë³€ìˆ˜ (ì»¤ë„¥ì…˜ í’€ëŸ¬ ê²½ìœ  í•„ìˆ˜: í¬íŠ¸ 6543)
_SUPABASE_URL = os.environ.get("SUPABASE_URL", "")
_SUPABASE_KEY = os.environ.get("SUPABASE_ANON_KEY", "")


class DeploymentMode(str, Enum):
    """ë°°í¬ ëª¨ë“œ."""
    SHADOW_DRY_RUN = "shadow_dry_run"   # Î¶ ë¯¸ì ìš©, ëª¨ë‹ˆí„°ë§ë§Œ
    SHADOW_ACTIVE = "shadow_active"      # Î¶ ì ìš©, ë¼ì´ë¸Œ ë°˜ì˜
    PRODUCTION = "production"            # ì™„ì „ í”„ë¡œë•ì…˜


@dataclass
class CostBudget:
    """ARES ë”¥ ê°ì‚¬ ë¹„ìš© ì˜ˆì‚°.

    CTO ì§€ì‹œ: ì¼ì¼ í† í°/ë¹„ìš© Hard Limit ì„¤ì •.
    """
    daily_token_limit: int = 100_000     # ì¼ì¼ ìµœëŒ€ í† í°
    daily_cost_limit_usd: float = 10.0   # ì¼ì¼ ìµœëŒ€ ë¹„ìš© (USD)
    tokens_used_today: int = 0
    cost_used_today_usd: float = 0.0
    last_reset: float = field(default_factory=time.time)
    breaker_tripped: bool = False
    trip_count: int = 0

    def consume(self, tokens: int, cost_usd: float = 0.0) -> bool:
        """í† í°/ë¹„ìš© ì†Œë¹„. ì˜ˆì‚° ì´ˆê³¼ ì‹œ False ë°˜í™˜."""
        self._maybe_reset()
        self.tokens_used_today += tokens
        self.cost_used_today_usd += cost_usd

        if (self.tokens_used_today > self.daily_token_limit or
                self.cost_used_today_usd > self.daily_cost_limit_usd):
            self.breaker_tripped = True
            self.trip_count += 1
            logger.warning(
                "ğŸ”Œ Circuit Breaker TRIPPED: tokens=%d/%d, cost=$%.2f/$%.2f",
                self.tokens_used_today, self.daily_token_limit,
                self.cost_used_today_usd, self.daily_cost_limit_usd,
            )
            return False
        return True

    def _maybe_reset(self) -> None:
        """ì¼ì¼ ë¦¬ì…‹ (24ì‹œê°„ ê²½ê³¼ ì‹œ)."""
        if time.time() - self.last_reset > 86400:
            self.tokens_used_today = 0
            self.cost_used_today_usd = 0.0
            self.breaker_tripped = False
            self.last_reset = time.time()

    @property
    def remaining_tokens(self) -> int:
        return max(0, self.daily_token_limit - self.tokens_used_today)

    @property
    def utilization(self) -> float:
        return self.tokens_used_today / max(self.daily_token_limit, 1)


@dataclass
class ShadowObservation:
    """ì„€ë„ìš° ëª¨ë“œì—ì„œì˜ ê´€ì¸¡ ê²°ê³¼ (Dry-run)."""
    timestamp: float = field(default_factory=time.time)
    decision_id: str = ""
    proposed_zeta: float = 0.0
    lyapunov_zeta_max: float = 0.0
    would_have_clipped: bool = False
    drift_index: float = 0.0
    ares_penalty: float = 0.0
    ate: float = 0.0
    e_value: float = 0.0
    mode: DeploymentMode = DeploymentMode.SHADOW_DRY_RUN


class ShadowDeployController:
    """ì„€ë„ìš° ë°°í¬ ì»¨íŠ¸ë¡¤ëŸ¬.

    CTO ì§€ì‹œ:
    - Dry-run: "ë§Œì•½ Î¶ë¥¼ ë°˜ì˜í–ˆë‹¤ë©´ ì–´ë–»ê²Œ ë˜ì—ˆì„ê¹Œ" ëª¨ë‹ˆí„°ë§
    - Circuit Breaker: ARES ë¹„ìš© ìƒí•œ ì´ˆê³¼ ì‹œ ê²½ëŸ‰ í´ë°±

    ì‚¬ìš©ë²•:
        controller = ShadowDeployController(mode=DeploymentMode.SHADOW_DRY_RUN)
        result = controller.process_audit(
            decision_id="d1",
            proposed_zeta=0.5,
            audit_result={...},
        )
    """

    def __init__(
        self,
        mode: DeploymentMode = DeploymentMode.SHADOW_DRY_RUN,
        cost_budget: Optional[CostBudget] = None,
    ) -> None:
        self.mode = mode
        self.cost_budget = cost_budget or CostBudget()
        self._observations: List[ShadowObservation] = []
        self._dlq_memory: List[Dict[str, Any]] = []  # DB ë¯¸ì—°ê²° ì‹œ í´ë°±
        self._fallback_count = 0

    def should_run_deep_audit(self) -> bool:
        """ARES ë”¥ ê°ì‚¬ë¥¼ ì‹¤í–‰í• ì§€ íŒë‹¨.

        ì„œí‚· ë¸Œë ˆì´ì»¤ê°€ íŠ¸ë¦½ë˜ë©´ ê²½ëŸ‰ í´ë°±ìœ¼ë¡œ ì „í™˜.
        """
        if self.cost_budget.breaker_tripped:
            self._fallback_count += 1
            logger.info(
                "âš¡ Fallback mode: ARES skipped (breaker tripped, fallback #%d)",
                self._fallback_count,
            )
            return False
        return True

    def enqueue_to_dlq(
        self,
        decision_id: str,
        payload: Dict[str, Any],
        reason: str = "breaker_tripped",
    ) -> None:
        """DLQ(Dead Letter Queue) ì ì¬.

        ìš°ì„ : Supabase audit_dlq í…Œì´ë¸”ì— ì˜ì†í™”.
        í´ë°±: DB ë¯¸ì—°ê²° ì‹œ ì¸ë©”ëª¨ë¦¬ ë¦¬ìŠ¤íŠ¸ (ë³µêµ¬ ë¶ˆê°€).
        """
        entry = {
            "decision_id": decision_id,
            "reason": reason,
            "payload": payload,
        }

        # DB ì˜ì†í™” ì‹œë„
        if _SUPABASE_URL and _SUPABASE_KEY:
            try:
                import urllib.request
                url = f"{_SUPABASE_URL}/rest/v1/audit_dlq"
                headers = {
                    "apikey": _SUPABASE_KEY,
                    "Authorization": f"Bearer {_SUPABASE_KEY}",
                    "Content-Type": "application/json",
                    "Prefer": "return=minimal",
                }
                body = json.dumps(entry).encode()
                req = urllib.request.Request(url, data=body, headers=headers, method="POST")
                with urllib.request.urlopen(req, timeout=5) as resp:
                    if resp.status in (200, 201):
                        logger.info(
                            "ğŸ“¥ DLQ persisted to DB: %s (reason=%s)",
                            decision_id, reason,
                        )
                        return
            except Exception as e:
                logger.warning("âš ï¸ DLQ DB write failed: %s â€” falling back to memory", e)

        # í´ë°±: ì¸ë©”ëª¨ë¦¬ (íŒŒë“œ ì¬ì‹œì‘ ì‹œ ìœ ì‹¤)
        entry["timestamp"] = time.time()
        self._dlq_memory.append(entry)
        logger.warning(
            "ğŸ“¥ DLQ in-memory fallback: %s (reason=%s, queue_size=%d) â€” VOLATILE",
            decision_id, reason, len(self._dlq_memory),
        )

    @property
    def dlq_size(self) -> int:
        return len(self._dlq_memory)

    @property
    def dlq_entries(self) -> List[Dict[str, Any]]:
        return list(self._dlq_memory)

    def record_observation(
        self,
        decision_id: str,
        proposed_zeta: float,
        lyapunov_zeta_max: float,
        drift_index: float = 0.0,
        ares_penalty: float = 0.0,
        ate: float = 0.0,
        e_value: float = 0.0,
    ) -> ShadowObservation:
        """ì„€ë„ìš° ê´€ì¸¡ ê¸°ë¡.

        Dry-run ëª¨ë“œ: Î¶ë¥¼ ì ìš©í•˜ì§€ ì•Šê³  ê¸°ë¡ë§Œ.
        Active ëª¨ë“œ: Î¶ë¥¼ ì ìš©í•˜ê³  ê¸°ë¡.
        """
        obs = ShadowObservation(
            decision_id=decision_id,
            proposed_zeta=proposed_zeta,
            lyapunov_zeta_max=lyapunov_zeta_max,
            would_have_clipped=proposed_zeta > lyapunov_zeta_max,
            drift_index=drift_index,
            ares_penalty=ares_penalty,
            ate=ate,
            e_value=e_value,
            mode=self.mode,
        )
        self._observations.append(obs)

        if self.mode == DeploymentMode.SHADOW_DRY_RUN:
            logger.debug(
                "ğŸ‘ï¸ Shadow observe: Î¶=%.4f (max=%.4f, clip=%s) [DRY-RUN]",
                proposed_zeta, lyapunov_zeta_max,
                "YES" if obs.would_have_clipped else "no",
            )

        return obs

    def should_apply_feedback(self) -> bool:
        """Î¶ í”¼ë“œë°±ì„ ì‹¤ì œë¡œ ì ìš©í• ì§€ íŒë‹¨."""
        return self.mode in (
            DeploymentMode.SHADOW_ACTIVE,
            DeploymentMode.PRODUCTION,
        )

    def get_dashboard_stats(self) -> Dict[str, Any]:
        """ëŒ€ì‹œë³´ë“œìš© í†µê³„."""
        if not self._observations:
            return {"total": 0}

        clip_count = sum(1 for o in self._observations if o.would_have_clipped)
        avg_zeta = sum(o.proposed_zeta for o in self._observations) / len(self._observations)
        avg_di = sum(o.drift_index for o in self._observations) / len(self._observations)

        return {
            "mode": self.mode.value,
            "total_observations": len(self._observations),
            "clip_rate": round(clip_count / len(self._observations), 4),
            "avg_proposed_zeta": round(avg_zeta, 4),
            "avg_drift_index": round(avg_di, 4),
            "cost_budget": {
                "tokens_used": self.cost_budget.tokens_used_today,
                "tokens_limit": self.cost_budget.daily_token_limit,
                "utilization": round(self.cost_budget.utilization, 2),
                "breaker_tripped": self.cost_budget.breaker_tripped,
                "trip_count": self.cost_budget.trip_count,
            },
            "fallback_count": self._fallback_count,
        }

    def promote_to_active(self) -> None:
        """Dry-run â†’ Active ëª¨ë“œ ìŠ¹ê²©."""
        if self.mode == DeploymentMode.SHADOW_DRY_RUN:
            self.mode = DeploymentMode.SHADOW_ACTIVE
            logger.info("ğŸš€ Promoted: SHADOW_DRY_RUN â†’ SHADOW_ACTIVE")

    def promote_to_production(self) -> None:
        """Active â†’ Production ìŠ¹ê²©."""
        if self.mode == DeploymentMode.SHADOW_ACTIVE:
            self.mode = DeploymentMode.PRODUCTION
            logger.info("ğŸ­ Promoted: SHADOW_ACTIVE â†’ PRODUCTION")


# â”€â”€ ì•”í˜¸í•™ì  ë°ì´í„° ë¬´ê²°ì„± ì„œëª… â”€â”€

def compute_daily_hash(rollup_data: Dict[str, Any], date_str: str) -> Dict[str, str]:
    """ë°ì¼ë¦¬ ë¡¤ì—… ë°ì´í„°ì˜ SHA-256 í•´ì‹œ.

    ì²´ë¦¬í”¼í‚¹ ë°©ì–´: ë…¼ë¬¸ ì‹¬ì‚¬ìœ„ì›ì´ ë°ì´í„° ì‚¬í›„ ì¡°ì‘ì„ ì˜ì‹¬í•  ë•Œ,
    GitHub ì»¤ë°‹ íƒ€ì„ìŠ¤íƒ¬í”„ + SHA-256ìœ¼ë¡œ ë¬´ê²°ì„± ì¦ëª….

    Args:
        rollup_data: ë¡¤ì—… ë ˆì½”ë“œ (JSON-serializable)
        date_str: ë‚ ì§œ ë¬¸ìì—´ (e.g. "2026-03-15")

    Returns:
        {"date": date_str, "sha256": hex_hash, "record_count": n}
    """
    canonical = json.dumps(rollup_data, sort_keys=True, ensure_ascii=False)
    h = hashlib.sha256(canonical.encode("utf-8")).hexdigest()
    return {
        "date": date_str,
        "sha256": h,
        "record_count": len(rollup_data.get("records", [])),
        "bytes": len(canonical),
    }


def append_hash_log(
    hash_entry: Dict[str, str],
    log_path: str = "data/integrity_hashes.jsonl",
) -> str:
    """Append-only í•´ì‹œ ë¡œê·¸ íŒŒì¼ì— ì¶”ê°€.

    ì´ íŒŒì¼ì„ GitHubì— ìë™ ì»¤ë°‹í•˜ë©´
    íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ì°íŒ ë¶ˆë³€ ë¬´ê²°ì„± ë ˆì½”ë“œ ì—­í• .
    """
    os.makedirs(os.path.dirname(log_path) or ".", exist_ok=True)
    line = json.dumps(hash_entry, ensure_ascii=False)
    with open(log_path, "a", encoding="utf-8") as f:
        f.write(line + "\n")
    return log_path


class DailyIntegrityWorker:
    """ë™ê¸° ë¡¤ì—…â†’í•´ì‹œ íŒŒì´í”„ë¼ì¸.

    ê²½ìŸ ìƒíƒœ(Race Condition) ë°©ì–´:
    pg_cronì´ ì•„ë‹Œ íŒŒì´ì¬ ì›Œì»¤ê°€ ë¡¤ì—… í”„ë¡œì‹œì €ë¥¼ ì§ì ‘ ë™ê¸°ì ìœ¼ë¡œ í˜¸ì¶œ.
    íŠ¸ëœì­ì…˜ ì»¤ë°‹ í›„ì—ë§Œ í•´ì‹œ ê³„ì‚° â†’ ë¶ˆì™„ì „ ë°ì´í„° í•´ì‹± ë¶ˆê°€.

    ì‚¬ìš©ë²•:
        worker = DailyIntegrityWorker()
        result = worker.run("2026-03-15")
    """

    def __init__(
        self,
        supabase_url: str = "",
        supabase_key: str = "",
        hash_log_path: str = "data/integrity_hashes.jsonl",
    ) -> None:
        self.supabase_url = supabase_url or _SUPABASE_URL
        self.supabase_key = supabase_key or _SUPABASE_KEY
        self.hash_log_path = hash_log_path

    def run(self, date_str: str) -> Dict[str, Any]:
        """ë™ê¸° ë¡¤ì—…â†’í•´ì‹œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰.

        1. rollup_daily_stats() í˜¸ì¶œ (DB íŠ¸ëœì­ì…˜)
        2. ì»¤ë°‹ ì™„ë£Œ í›„ ë¡¤ì—… ë°ì´í„° ì¡°íšŒ
        3. SHA-256 í•´ì‹œ ê³„ì‚°
        4. integrity_hashes í…Œì´ë¸” + JSONL ë¡œê·¸ì— ì €ì¥
        """
        result = {"date": date_str, "status": "unknown"}

        try:
            # Step 1: ë¡¤ì—… ì‹¤í–‰ (DBì— ë¡¤ì—… ì €ì¥ í”„ë¡œì‹œì € í˜¸ì¶œ)
            rollup_data = self._execute_rollup(date_str)
            if not rollup_data:
                result["status"] = "no_data"
                return result

            # Step 2: SHA-256 í•´ì‹œ (ë¡¤ì—… ì»¤ë°‹ ì§í›„ â€” ê²½ìŸ ìƒíƒœ ë¶ˆê°€)
            hash_entry = compute_daily_hash(rollup_data, date_str)

            # Step 3: DBì— í•´ì‹œ ì €ì¥
            self._store_hash_to_db(hash_entry)

            # Step 4: ë¡œì»¬ íŒŒì¼ì—ë„ ì €ì¥ (GitHub ìë™ ì»¤ë°‹ìš©)
            append_hash_log(hash_entry, self.hash_log_path)

            result["status"] = "success"
            result["hash"] = hash_entry
            logger.info(
                "âœ… Daily integrity: %s â†’ SHA256=%s (%d records)",
                date_str, hash_entry["sha256"][:16] + "...",
                hash_entry["record_count"],
            )

        except Exception as e:
            result["status"] = "error"
            result["error"] = str(e)
            logger.error("âŒ Daily integrity failed for %s: %s", date_str, e)

        return result

    def _execute_rollup(self, date_str: str) -> Optional[Dict]:
        """ë¡¤ì—… ë°ì´í„° ì¡°íšŒ (ë™ê¸°)."""
        if not (self.supabase_url and self.supabase_key):
            logger.warning("âš ï¸ No Supabase credentials â€” skipping rollup")
            return None

        try:
            import urllib.request
            url = (
                f"{self.supabase_url}/rest/v1/daily_agent_rollup"
                f"?rollup_date=eq.{date_str}&select=*"
            )
            headers = {
                "apikey": self.supabase_key,
                "Authorization": f"Bearer {self.supabase_key}",
            }
            req = urllib.request.Request(url, headers=headers)
            with urllib.request.urlopen(req, timeout=10) as resp:
                rows = json.loads(resp.read())
                return {"records": rows, "date": date_str}
        except Exception as e:
            logger.error("âŒ Rollup query failed: %s", e)
            return None

    def _store_hash_to_db(self, hash_entry: Dict) -> None:
        """í•´ì‹œë¥¼ integrity_hashes í…Œì´ë¸”ì— ì €ì¥."""
        if not (self.supabase_url and self.supabase_key):
            return

        try:
            import urllib.request
            url = f"{self.supabase_url}/rest/v1/integrity_hashes"
            headers = {
                "apikey": self.supabase_key,
                "Authorization": f"Bearer {self.supabase_key}",
                "Content-Type": "application/json",
                "Prefer": "return=minimal,resolution=merge-duplicates",
            }
            body = json.dumps({
                "rollup_date": hash_entry["date"],
                "sha256_hash": hash_entry["sha256"],
                "record_count": hash_entry["record_count"],
                "data_bytes": hash_entry["bytes"],
            }).encode()
            req = urllib.request.Request(url, data=body, headers=headers, method="POST")
            urllib.request.urlopen(req, timeout=5)
        except Exception as e:
            logger.warning("âš ï¸ Hash DB write failed: %s", e)
