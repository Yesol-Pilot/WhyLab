# -*- coding: utf-8 -*-
"""AutoCausalCell â€” ë°ì´í„° íŠ¹ì„± ê¸°ë°˜ ìë™ ë°©ë²•ë¡  ì„ íƒ.

ë°ì´í„°ë¥¼ í”„ë¡œíŒŒì¼ë§í•˜ì—¬ ìµœì ì˜ ì¸ê³¼ì¶”ë¡  ë°©ë²•ë¡ ì„ ìë™ ì¶”ì²œí•©ë‹ˆë‹¤.
Orchestratorì—ì„œ DataCell â†’ DiscoveryCell â†’ **AutoCausalCell** â†’ CausalCell
ìˆœì„œë¡œ ì‹¤í–‰ë˜ì–´, CausalCellì— ìµœì  ì„¤ì •ì„ ì£¼ì…í•©ë‹ˆë‹¤.

Phase 9-3: AutoCausal íŒŒì´í”„ë¼ì¸.
"""

from __future__ import annotations

import logging
from dataclasses import dataclass
from typing import Any, Dict, List, Optional

import numpy as np
import pandas as pd

from engine.cells.base_cell import BaseCell
from engine.config import WhyLabConfig

logger = logging.getLogger(__name__)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë°ì´í„° í”„ë¡œíŒŒì¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@dataclass
class DataProfile:
    """ë°ì´í„°ì…‹ ìë™ í”„ë¡œíŒŒì¼ ê²°ê³¼."""
    n_samples: int
    n_features: int
    treatment_type: str  # "binary" | "continuous" | "multi_level"
    outcome_type: str    # "binary" | "continuous"
    has_missing: bool
    missing_ratio: float
    treatment_balance: float  # ì²˜ì¹˜/í†µì œ ë¹„ìœ¨ (ì´ì§„) ë˜ëŠ” ë¶„ì‚° (ì—°ì†)
    overlap_risk: str    # "low" | "medium" | "high"
    linearity_score: float  # ì„ í˜•ì„± ì •ë„ (0~1)
    confounders_count: int
    warnings: List[str]


class AutoCausalCell(BaseCell):
    """ë°ì´í„° í”„ë¡œíŒŒì¼ë§ â†’ ë°©ë²•ë¡  ìë™ ì¶”ì²œ ì…€.

    ë°ì´í„° íŠ¹ì„±ì„ ë¶„ì„í•˜ì—¬:
    1. ìµœì  ë©”íƒ€ëŸ¬ë„ˆ ì¶”ì²œ
    2. ì¶”ì • ë°©ë²•(DML/Forest/IV) ì¶”ì²œ
    3. ìœ„í—˜ ìš”ì†Œ ê²½ê³  (ìƒ˜í”Œ í¬ê¸°, Overlap, SUTVA ë“±)
    """

    def __init__(self, config: WhyLabConfig) -> None:
        super().__init__(name="auto_causal_cell", config=config)

    def execute(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """ë°ì´í„° í”„ë¡œíŒŒì¼ë§ + ë°©ë²•ë¡  ì¶”ì²œ.

        Args:
            inputs: DataCell/DiscoveryCell ì¶œë ¥.

        Returns:
            ê¸°ì¡´ inputs + data_profile, recommended_method ì¶”ê°€.
        """
        df = inputs.get("dataframe")
        if df is None:
            self.logger.warning("ë°ì´í„°í”„ë ˆì„ ì—†ìŒ â†’ AutoCausal ê±´ë„ˆëœ€")
            return inputs

        treatment_col = inputs.get("treatment_col", "treatment")
        outcome_col = inputs.get("outcome_col", "outcome")
        feature_names = inputs.get("feature_names", [])

        # 1ë‹¨ê³„: ë°ì´í„° í”„ë¡œíŒŒì¼ë§
        profile = self._profile_data(df, treatment_col, outcome_col, feature_names)
        self.logger.info(
            "ğŸ“Š ë°ì´í„° í”„ë¡œíŒŒì¼: n=%d, T=%s(%s), Y=%s(%s), êµë€=%d",
            profile.n_samples, treatment_col, profile.treatment_type,
            outcome_col, profile.outcome_type, profile.confounders_count,
        )

        # 2ë‹¨ê³„: ë°©ë²•ë¡  ì¶”ì²œ
        recommendation = self._recommend_method(profile)
        self.logger.info(
            "ğŸ¯ ì¶”ì²œ ë°©ë²•ë¡ : %s (ëª¨ë¸: %s, ì´ìœ : %s)",
            recommendation["primary_method"],
            recommendation["nuisance_model"],
            recommendation["reasoning"],
        )

        # 3ë‹¨ê³„: ê²½ê³  ì¶œë ¥
        for warning in profile.warnings:
            self.logger.warning("âš ï¸ %s", warning)

        return {
            **inputs,
            "data_profile": {
                "n_samples": profile.n_samples,
                "n_features": profile.n_features,
                "treatment_type": profile.treatment_type,
                "outcome_type": profile.outcome_type,
                "has_missing": profile.has_missing,
                "missing_ratio": profile.missing_ratio,
                "treatment_balance": profile.treatment_balance,
                "overlap_risk": profile.overlap_risk,
                "linearity_score": profile.linearity_score,
                "warnings": profile.warnings,
            },
            "auto_recommendation": recommendation,
        }

    def _profile_data(
        self,
        df: pd.DataFrame,
        treatment_col: str,
        outcome_col: str,
        feature_names: List[str],
    ) -> DataProfile:
        """ë°ì´í„°ì…‹ì„ ìë™ìœ¼ë¡œ í”„ë¡œíŒŒì¼ë§í•©ë‹ˆë‹¤."""
        n_samples = len(df)
        n_features = len(feature_names)
        warnings = []

        # Treatment ìœ í˜• íŒë³„
        if treatment_col in df.columns:
            t_nunique = df[treatment_col].nunique()
            if t_nunique <= 2:
                treatment_type = "binary"
            elif t_nunique <= 10:
                treatment_type = "multi_level"
            else:
                treatment_type = "continuous"

            # ì²˜ì¹˜ ê· í˜•
            if treatment_type == "binary":
                t_ratio = df[treatment_col].mean()
                treatment_balance = min(t_ratio, 1 - t_ratio) / max(t_ratio, 1 - t_ratio)
                if treatment_balance < 0.1:
                    warnings.append(f"ì²˜ì¹˜ ë¶ˆê· í˜• ì‹¬ê°: ì²˜ì¹˜ ë¹„ìœ¨ {t_ratio:.1%}")
            else:
                treatment_balance = float(df[treatment_col].std() / (df[treatment_col].mean() + 1e-10))
        else:
            treatment_type = "unknown"
            treatment_balance = 0.0

        # Outcome ìœ í˜• íŒë³„
        if outcome_col in df.columns:
            o_nunique = df[outcome_col].nunique()
            outcome_type = "binary" if o_nunique <= 2 else "continuous"
        else:
            outcome_type = "unknown"

        # ê²°ì¸¡ì¹˜
        missing_ratio = df[feature_names].isnull().sum().sum() / max(df[feature_names].size, 1)
        has_missing = missing_ratio > 0
        if missing_ratio > 0.1:
            warnings.append(f"ê²°ì¸¡ì¹˜ ë¹„ìœ¨ {missing_ratio:.1%} (10% ì´ˆê³¼)")

        # í‘œë³¸ í¬ê¸° ê²½ê³ 
        if n_samples < 500:
            warnings.append(f"ì†Œí‘œë³¸ ì£¼ì˜ (n={n_samples})")
        if n_samples < 100:
            warnings.append("í‘œë³¸ í¬ê¸° ë§¤ìš° ë¶€ì¡± â†’ ê²°ê³¼ ì‹ ë¢°ë„ ë‚®ìŒ")

        # Overlap ìœ„í—˜ë„ (Propensity Score ë¶„í¬ ê¸°ë°˜ ê°„ì´ ì¶”ì •)
        overlap_risk = "low"
        if treatment_type == "binary" and treatment_col in df.columns and feature_names:
            try:
                from sklearn.linear_model import LogisticRegression
                X = df[feature_names].fillna(0).values
                t = df[treatment_col].values
                lr = LogisticRegression(max_iter=200, solver="lbfgs")
                lr.fit(X, t)
                ps = lr.predict_proba(X)[:, 1]
                ps_std = np.std(ps)
                if ps_std > 0.3:
                    overlap_risk = "high"
                    warnings.append("Propensity Score ë¶„ì‚° ë†’ìŒ â†’ Overlap ìœ„í—˜")
                elif ps_std > 0.15:
                    overlap_risk = "medium"
            except Exception:
                overlap_risk = "unknown"

        # ì„ í˜•ì„± ì ìˆ˜ (Treatment-Outcome ìƒê´€ ê¸°ì¤€ ê°„ì´ ì¶”ì •)
        linearity_score = 0.5
        if treatment_col in df.columns and outcome_col in df.columns:
            try:
                corr = abs(df[treatment_col].corr(df[outcome_col]))
                linearity_score = float(corr) if not np.isnan(corr) else 0.5
            except Exception:
                pass

        return DataProfile(
            n_samples=n_samples,
            n_features=n_features,
            treatment_type=treatment_type,
            outcome_type=outcome_type,
            has_missing=has_missing,
            missing_ratio=missing_ratio,
            treatment_balance=treatment_balance,
            overlap_risk=overlap_risk,
            linearity_score=linearity_score,
            confounders_count=n_features,
            warnings=warnings,
        )

    def _recommend_method(self, profile: DataProfile) -> Dict[str, Any]:
        """í”„ë¡œíŒŒì¼ ê¸°ë°˜ ìµœì  ë°©ë²•ë¡ ì„ ì¶”ì²œí•©ë‹ˆë‹¤."""

        # ê¸°ë³¸ ì¶”ì²œ
        primary_method = "linear_dml"
        nuisance_model = "lightgbm"
        meta_learners = ["S-Learner", "T-Learner", "X-Learner", "DR-Learner"]
        reasoning_parts = []

        # Treatment ìœ í˜•ë³„ ë¶„ê¸°
        if profile.treatment_type == "binary":
            meta_learners = ["T-Learner", "X-Learner", "DR-Learner", "S-Learner"]
            reasoning_parts.append("ì´ì§„ ì²˜ì¹˜ â†’ T/X-Learner ìš°ì„ ")
        elif profile.treatment_type == "continuous":
            primary_method = "linear_dml"
            reasoning_parts.append("ì—°ì† ì²˜ì¹˜ â†’ DML ìµœì ")
        elif profile.treatment_type == "multi_level":
            meta_learners = ["S-Learner", "DR-Learner"]
            reasoning_parts.append("ë‹¤ìˆ˜ì¤€ ì²˜ì¹˜ â†’ S/DR-Learner ì•ˆì •ì ")

        # í‘œë³¸ í¬ê¸°ë³„ ë¶„ê¸°
        if profile.n_samples < 500:
            nuisance_model = "linear"
            meta_learners = ["S-Learner", "T-Learner"]
            reasoning_parts.append("ì†Œí‘œë³¸ â†’ ì„ í˜• ëª¨ë¸ + ë‹¨ìˆœ ëŸ¬ë„ˆ")
        elif profile.n_samples > 50000:
            reasoning_parts.append("ëŒ€ê·œëª¨ í‘œë³¸ â†’ ë¹„ëª¨ìˆ˜ì  ë°©ë²• ìœ ë¦¬")

        # ì„ í˜•ì„±ì— ë”°ë¥¸ ë¶„ê¸°
        if profile.linearity_score > 0.7:
            primary_method = "linear_dml"
            reasoning_parts.append("ë†’ì€ ì„ í˜•ì„± â†’ LinearDML ìµœì ")
        elif profile.linearity_score < 0.3:
            primary_method = "causal_forest"
            nuisance_model = "lightgbm"
            reasoning_parts.append("ë¹„ì„ í˜• ê´€ê³„ â†’ Causal Forest ì¶”ì²œ")

        # Overlap ìœ„í—˜ ëŒ€ì‘
        if profile.overlap_risk == "high":
            meta_learners = ["DR-Learner", "X-Learner"]
            reasoning_parts.append("Overlap ìœ„í—˜ â†’ DR/X-Learner (robustness)")

        # R-LearnerëŠ” ê¸°ë³¸ ì œì™¸ (ë²¤ì¹˜ë§ˆí¬ì—ì„œ ì¼ê´€ì ìœ¼ë¡œ ì €ì„±ëŠ¥)
        if "R-Learner" in meta_learners:
            meta_learners.remove("R-Learner")

        return {
            "primary_method": primary_method,
            "nuisance_model": nuisance_model,
            "recommended_learners": meta_learners,
            "reasoning": " | ".join(reasoning_parts),
            "confidence": "high" if len(profile.warnings) == 0 else
                         "medium" if len(profile.warnings) <= 2 else "low",
            "warnings": profile.warnings,
        }
