# -*- coding: utf-8 -*-
"""ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ â€” DragonNet/TARNet í¬í•¨.

6ì¢… ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë©”íƒ€ëŸ¬ë„ˆ + DragonNet + TARNet + LinearDMLì„ ë¹„êµí•©ë‹ˆë‹¤.
"""
import sys
import os
import logging
import time
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(ROOT))

import numpy as np
import pandas as pd

from engine.data.benchmark_data import BENCHMARK_REGISTRY
from engine.cells.meta_learner_cell import (
    SLearner, TLearner, XLearner, DRLearner, RLearner,
)

# DeepCATECell ì„ íƒì  ì„í¬íŠ¸
try:
    from engine.cells.deep_cate_cell import DeepCATECell, DeepCATEConfig
    HAS_DEEP = True
except ImportError:
    HAS_DEEP = False
    print("WARNING: DeepCATECell not found -- DragonNet/TARNet skipped")

logging.basicConfig(level=logging.INFO, format="%(message)s")
logger = logging.getLogger(__name__)


def sqrt_pehe(tau_hat, tau_true):
    return float(np.sqrt(np.mean((tau_hat - tau_true) ** 2)))


def ate_bias(tau_hat, tau_true):
    return float(np.abs(np.mean(tau_hat) - np.mean(tau_true)))


def run_benchmark():
    # ì†Œê·œëª¨ nìœ¼ë¡œ ë¹ ë¥¸ ì‹¤í–‰ (CriteoëŠ” 5000ìœ¼ë¡œ ì œí•œ)
    dataset_configs = {
        "ihdp": {"n_reps": 5},
        "acic": {"n_reps": 3},
        "jobs": {"n_reps": 5},
        "twins": {"n_reps": 3},
        "criteo": {"n_reps": 2},
        "lalonde": {"n_reps": 3},
    }

    # ë©”íƒ€ëŸ¬ë„ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬
    LEARNERS = {
        "S-Learner": SLearner,
        "T-Learner": TLearner,
        "X-Learner": XLearner,
        "DR-Learner": DRLearner,
        "R-Learner": RLearner,
    }

    # ë”¥ëŸ¬ë‹ ì•„í‚¤í…ì²˜
    DEEP_ARCHS = {}
    if HAS_DEEP:
        DEEP_ARCHS = {"DragonNet": "dragonnet", "TARNet": "tarnet"}

    all_results = {}
    start = time.time()

    for ds_name, ds_cfg in dataset_configs.items():
        if ds_name not in BENCHMARK_REGISTRY:
            continue

        loader = BENCHMARK_REGISTRY[ds_name]()
        n_reps = ds_cfg["n_reps"]

        print(f"\n{'='*60}")
        print(f"ğŸ“Š {ds_name.upper()} (ë°˜ë³µ {n_reps}íšŒ)")
        print(f"{'='*60}")

        metrics = {name: {"pehe": [], "ate_bias": []}
                   for name in list(LEARNERS) + list(DEEP_ARCHS)}

        for rep in range(n_reps):
            data = loader.load(seed=42 + rep)

            # ì¼ë°˜ ë©”íƒ€ëŸ¬ë„ˆ
            for name, Cls in LEARNERS.items():
                try:
                    from engine.config import WhyLabConfig
                    learner = Cls(config=WhyLabConfig())
                    learner.fit(data.X, data.T, data.Y)
                    tau = learner.predict_cate(data.X)
                    metrics[name]["pehe"].append(sqrt_pehe(tau, data.tau_true))
                    metrics[name]["ate_bias"].append(ate_bias(tau, data.tau_true))
                except Exception as e:
                    metrics[name]["pehe"].append(float("nan"))
                    metrics[name]["ate_bias"].append(float("nan"))

            # ë”¥ëŸ¬ë‹ CATE
            for name, arch in DEEP_ARCHS.items():
                try:
                    deep_cfg = DeepCATEConfig(
                        architecture=arch,
                        shared_dims=(64, 32),
                        head_dims=(32,),
                        epochs=100,
                        batch_size=min(64, len(data.X)),
                        use_gpu=True,
                    )
                    cell = DeepCATECell(deep_config=deep_cfg)
                    cell.fit(data.X, data.T, data.Y)
                    tau = cell.predict_cate(data.X)
                    metrics[name]["pehe"].append(sqrt_pehe(tau, data.tau_true))
                    metrics[name]["ate_bias"].append(ate_bias(tau, data.tau_true))
                except Exception as e:
                    print(f"  âš ï¸ {name} (rep={rep}) ì‹¤íŒ¨: {e}")
                    metrics[name]["pehe"].append(float("nan"))
                    metrics[name]["ate_bias"].append(float("nan"))

            print(f"  âœ… Rep {rep+1}/{n_reps}")

        ds_results = {}
        for name, m in metrics.items():
            pa = np.array(m["pehe"])
            ba = np.array(m["ate_bias"])
            ds_results[name] = {
                "pehe_mean": float(np.nanmean(pa)),
                "pehe_std": float(np.nanstd(pa)),
                "ate_bias_mean": float(np.nanmean(ba)),
                "ate_bias_std": float(np.nanstd(ba)),
            }
            print(f"  {name:14s}: âˆšPEHE={np.nanmean(pa):.4f}Â±{np.nanstd(pa):.4f}  "
                  f"ATE Bias={np.nanmean(ba):.4f}Â±{np.nanstd(ba):.4f}")

        all_results[ds_name] = ds_results

    elapsed = time.time() - start
    print(f"\nâ±ï¸ ì´ ì†Œìš” ì‹œê°„: {elapsed:.1f}ì´ˆ")

    # ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” ìƒì„±
    print("\n\n## ë²¤ì¹˜ë§ˆí¬ ë¹„êµí‘œ\n")
    ds_names = list(all_results.keys())
    header = "| Method |"
    sep = "|---|"
    for ds in ds_names:
        header += f" {ds.upper()} âˆšPEHE |"
        sep += "---|"

    print(header)
    print(sep)

    ordered = list(LEARNERS) + list(DEEP_ARCHS)
    for method in ordered:
        row = f"| {method} |"
        for ds in ds_names:
            if ds in all_results and method in all_results[ds]:
                r = all_results[ds][method]
                row += f" {r['pehe_mean']:.4f}Â±{r['pehe_std']:.4f} |"
            else:
                row += " â€” |"
        print(row)

    # ê²°ê³¼ ì €ì¥
    report_dir = ROOT / "paper" / "reports" / "benchmarks"
    report_dir.mkdir(parents=True, exist_ok=True)
    report_path = report_dir / "benchmark_dragonnet.md"

    with open(report_path, "w", encoding="utf-8") as f:
        f.write("# WhyLab ë²¤ì¹˜ë§ˆí¬ â€” DragonNet/TARNet í¬í•¨\n\n")
        f.write(f"ì‹¤í–‰ ì‹œê°„: {elapsed:.1f}ì´ˆ\n\n")
        f.write(header + "\n")
        f.write(sep + "\n")
        for method in ordered:
            row = f"| {method} |"
            for ds in ds_names:
                if ds in all_results and method in all_results[ds]:
                    r = all_results[ds][method]
                    row += f" {r['pehe_mean']:.4f}Â±{r['pehe_std']:.4f} |"
                else:
                    row += " â€” |"
            f.write(row + "\n")

    print(f"\nğŸ“„ ê²°ê³¼ ì €ì¥: {report_path}")


if __name__ == "__main__":
    run_benchmark()
