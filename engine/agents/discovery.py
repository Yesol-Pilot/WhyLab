# -*- coding: utf-8 -*-
"""Discovery Agent â€” ì¸ê³¼ êµ¬ì¡° ë°œê²¬ì„ ìœ„í•œ Nucleus Module.

ë°ì´í„°ì™€ ë©”íƒ€ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë³€ìˆ˜ ê°„ì˜ ì¸ê³¼ ê´€ê³„(DAG)ë¥¼ ìŠ¤ìŠ¤ë¡œ ìˆ˜ë¦½í•©ë‹ˆë‹¤.
LLMì˜ ìƒì‹ì  ì¶”ë¡ (Prior Knowledge)ê³¼ í†µê³„ì  ì•Œê³ ë¦¬ì¦˜(PC Algorithm)ì„ ê²°í•©í•˜ëŠ”
í•˜ì´ë¸Œë¦¬ë“œ ë°œê²¬ ì „ëµì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
"""

from __future__ import annotations

import logging
from typing import Any, Dict, List, Optional, Tuple

import pandas as pd
import numpy as np
import networkx as nx

from engine.config import WhyLabConfig

class DiscoveryAgent:
    """ì¸ê³¼ êµ¬ì¡°(DAG)ë¥¼ ììœ¨ì ìœ¼ë¡œ ë°œê²¬í•˜ëŠ” ì—ì´ì „íŠ¸ (Nucleus)."""

    def __init__(self, config: WhyLabConfig) -> None:
        self.config = config
        self.logger = logging.getLogger("whylab.agents.discovery")
        self._llm_client = None  # ì¶”í›„ LLM í´ë¼ì´ì–¸íŠ¸ ì—°ë™ (MCP ë“±)

    def auto_discover(
        self, df: pd.DataFrame, description: str = "",
    ) -> Dict[str, Any]:
        """CSVë§Œ ë„£ìœ¼ë©´ treatment/outcome/confounderë¥¼ ìë™ íƒìƒ‰í•©ë‹ˆë‹¤.

        Args:
            df: ë¶„ì„ ëŒ€ìƒ ë°ì´í„°í”„ë ˆì„.
            description: (ì„ íƒ) ë°ì´í„° ì„¤ëª… í…ìŠ¤íŠ¸.

        Returns:
            roles dict: treatment, outcome, confounders, dag.
        """
        self.logger.info("ğŸ” Auto-Discovery ì‹œì‘: %d ì»¬ëŸ¼ ë¶„ì„", len(df.columns))

        columns = df.columns.tolist()
        dtypes = {col: str(df[col].dtype) for col in columns}
        sample = df.head(3).to_dict(orient="records")

        # LLMìœ¼ë¡œ ì—­í•  íƒìƒ‰
        roles = self._discover_roles_with_llm(columns, dtypes, sample, description)

        if roles:
            self.logger.info("ğŸ¤– LLM ì—­í•  íƒìƒ‰ ì™„ë£Œ: T=%s, Y=%s",
                             roles.get("treatment"), roles.get("outcome"))
        else:
            # í´ë°±: ë„ë©”ì¸ íœ´ë¦¬ìŠ¤í‹±
            roles = self._discover_roles_heuristic(df)
            self.logger.info("ğŸ“ íœ´ë¦¬ìŠ¤í‹± ì—­í•  íƒìƒ‰: T=%s, Y=%s",
                             roles.get("treatment"), roles.get("outcome"))

        # DAG ë°œê²¬
        metadata = {
            "feature_names": roles.get("confounders", []),
            "treatment_col": roles.get("treatment"),
            "outcome_col": roles.get("outcome"),
        }
        dag = self.discover(df, metadata)
        roles["dag"] = list(dag.edges())

        return roles

    def discover(self, df: pd.DataFrame, metadata: Dict[str, Any]) -> nx.DiGraph:
        """ë°ì´í„°ë¡œë¶€í„° ì¸ê³¼ ê·¸ë˜í”„ë¥¼ ë°œê²¬í•©ë‹ˆë‹¤.

        Args:
            df: ë¶„ì„ ëŒ€ìƒ ë°ì´í„°í”„ë ˆì„.
            metadata: ì»¬ëŸ¼ ì„¤ëª… ë“± ë©”íƒ€ë°ì´í„°.

        Returns:
            NetworkX DiGraph ê°ì²´ (ë°œê²¬ëœ DAG).
        """
        self.logger.info("ğŸ§  Nucleus(Discovery) í™œì„±í™”: ë°ì´í„° ë¶„ì„ ì‹œì‘ (Rows: %d)", len(df))

        # ë¶„ì„ ëŒ€ìƒ ì¹¼ëŸ¼ë§Œ ì„ íƒ (íŒŒìƒ ì¹¼ëŸ¼ ì œì™¸ â†’ singular matrix ë°©ì§€)
        analysis_cols = list(metadata.get("feature_names", []))
        for col_key in ("treatment_col", "outcome_col"):
            col = metadata.get(col_key)
            if col and col not in analysis_cols:
                analysis_cols.append(col)
        analysis_df = df[analysis_cols] if analysis_cols else df

        # 1. LLM ê¸°ë°˜ ì‚¬ì „ ì§€ì‹(Prior Knowledge) ìˆ˜ë¦½
        prior_dag = self._reason_with_llm(metadata)

        # 2. í†µê³„ì  ì¸ê³¼ ë°œê²¬ (PC Algorithm)
        stat_dag = self._discover_statistically(analysis_df)

        # 3. í•˜ì´ë¸Œë¦¬ë“œ ë³‘í•© (Ensemble)
        final_dag = self._merge_graphs(prior_dag, stat_dag)

        self.logger.info("âœ¨ ì¸ê³¼ êµ¬ì¡° ë°œê²¬ ì™„ë£Œ (Nodes: %d, Edges: %d)",
                         final_dag.number_of_nodes(), final_dag.number_of_edges())
        return final_dag

    def _discover_roles_with_llm(
        self, columns, dtypes, sample, description,
    ) -> Optional[Dict[str, Any]]:
        """LLMìœ¼ë¡œ ë³€ìˆ˜ ì—­í• ì„ íƒìƒ‰í•©ë‹ˆë‹¤."""
        import os
        api_key = os.environ.get("GEMINI_API_KEY") or os.environ.get("GOOGLE_API_KEY")
        if not api_key:
            return None

        try:
            import google.generativeai as genai
            import json
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel("gemini-2.0-flash")

            prompt = (
                "ë‹¹ì‹ ì€ ì¸ê³¼ì¶”ë¡  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ë°ì´í„°ì…‹ì˜ ì»¬ëŸ¼ì„ ë¶„ì„í•˜ì—¬ "
                "treatment(ì²˜ì¹˜), outcome(ê²°ê³¼), confounders(êµë€ë³€ìˆ˜)ë¥¼ ì‹ë³„í•´ì£¼ì„¸ìš”.\n\n"
                f"ì»¬ëŸ¼: {columns}\n"
                f"íƒ€ì…: {dtypes}\n"
                f"ìƒ˜í”Œ: {sample[:2]}\n"
                f"ì„¤ëª…: {description or 'ì—†ìŒ'}\n\n"
                "ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:\n"
                '{"treatment": "ì»¬ëŸ¼ëª…", "outcome": "ì»¬ëŸ¼ëª…", '
                '"confounders": ["ì»¬ëŸ¼1", "ì»¬ëŸ¼2", ...], '
                '"reasoning": "í•œ ì¤„ ì„¤ëª…"}'
            )

            response = model.generate_content(prompt)
            text = response.text.strip()
            # JSON ì¶”ì¶œ
            if "```" in text:
                text = text.split("```")[1].replace("json", "").strip()
            return json.loads(text)
        except Exception as e:
            self.logger.warning("LLM ì—­í•  íƒìƒ‰ ì‹¤íŒ¨: %s", e)
            return None

    def _discover_roles_heuristic(self, df: pd.DataFrame) -> Dict[str, Any]:
        """íœ´ë¦¬ìŠ¤í‹± ê¸°ë°˜ ë³€ìˆ˜ ì—­í•  íƒìƒ‰ (í´ë°±)."""
        columns = df.select_dtypes(include=[np.number]).columns.tolist()

        # ì´ì§„ ë³€ìˆ˜ â†’ outcome í›„ë³´
        binary_cols = [c for c in columns if df[c].nunique() <= 2]
        # ì—°ì† ë³€ìˆ˜ â†’ treatment í›„ë³´
        continuous_cols = [c for c in columns if df[c].nunique() > 10]

        outcome = binary_cols[0] if binary_cols else columns[-1]
        treatment = continuous_cols[0] if continuous_cols else columns[0]
        confounders = [c for c in columns if c not in (treatment, outcome)]

        return {
            "treatment": treatment,
            "outcome": outcome,
            "confounders": confounders,
            "reasoning": "íœ´ë¦¬ìŠ¤í‹±: ì´ì§„ë³€ìˆ˜â†’outcome, ì—°ì†ë³€ìˆ˜â†’treatment",
        }

    def _reason_with_llm(self, metadata: Dict[str, Any]) -> nx.DiGraph:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ë³€ìˆ˜ ê°„ì˜ ì¸ê³¼ê´€ê³„ë¥¼ ì¶”ë¡ í•©ë‹ˆë‹¤."""
        self.logger.info("   [1] LLM Reasoning: ë³€ìˆ˜ ì˜ë¯¸ë¡ ì  ë¶„ì„ ì¤‘...")

        dag = nx.DiGraph()
        nodes = metadata.get("feature_names", []) + [
            metadata.get("treatment_col"), metadata.get("outcome_col")
        ]
        for node in nodes:
            if node:
                dag.add_node(node)

        # Gemini LLM í˜¸ì¶œ ì‹œë„
        import os
        api_key = os.environ.get("GEMINI_API_KEY") or os.environ.get("GOOGLE_API_KEY")
        if api_key:
            try:
                import google.generativeai as genai
                import json
                genai.configure(api_key=api_key)
                model = genai.GenerativeModel("gemini-2.0-flash")

                prompt = (
                    "ë‹¹ì‹ ì€ ì¸ê³¼ì¶”ë¡  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ë³€ìˆ˜ë“¤ ê°„ì˜ ì¸ê³¼ê´€ê³„(DAG)ë¥¼ "
                    "ë„ë©”ì¸ ì§€ì‹ìœ¼ë¡œ ì¶”ë¡ í•˜ì„¸ìš”.\n\n"
                    f"ë³€ìˆ˜: {[n for n in nodes if n]}\n"
                    f"Treatment: {metadata.get('treatment_col')}\n"
                    f"Outcome: {metadata.get('outcome_col')}\n\n"
                    "JSON ë°°ì—´ë¡œ ì—£ì§€ë¥¼ ë°˜í™˜í•˜ì„¸ìš”: "
                    '[["ì›ì¸", "ê²°ê³¼"], ["ì›ì¸2", "ê²°ê³¼2"], ...]'
                )

                response = model.generate_content(prompt)
                text = response.text.strip()
                if "```" in text:
                    text = text.split("```")[1].replace("json", "").strip()
                edges = json.loads(text)
                for u, v in edges:
                    if u in dag.nodes and v in dag.nodes:
                        dag.add_edge(u, v)
                self.logger.info("       ğŸ¤– LLM ê°€ì„¤ ìˆ˜ë¦½ ì™„ë£Œ (ì—£ì§€ %dê°œ)", dag.number_of_edges())
                return dag
            except Exception as e:
                self.logger.warning("       LLM ì‹¤íŒ¨ â†’ ê·œì¹™ ê¸°ë°˜ í´ë°±: %s", e)

        # í´ë°±: ë„ë©”ì¸ ê·œì¹™ ê¸°ë°˜
        if "age" in nodes:
            for target in ("credit_limit", "is_default", "income", "credit_score"):
                if target in nodes:
                    dag.add_edge("age", target)
        if "income" in nodes:
            for target in ("credit_limit", "is_default", "credit_score"):
                if target in nodes:
                    dag.add_edge("income", target)
        if "credit_score" in nodes:
            for target in ("credit_limit", "is_default"):
                if target in nodes:
                    dag.add_edge("credit_score", target)

        treatment = metadata.get("treatment_col")
        outcome = metadata.get("outcome_col")
        if treatment and outcome and treatment in nodes and outcome in nodes:
            dag.add_edge(treatment, outcome)

        self.logger.info("       ê·œì¹™ ê¸°ë°˜ ê°€ì„¤ ìˆ˜ë¦½ ì™„ë£Œ (ì—£ì§€ %dê°œ)", dag.number_of_edges())
        return dag

    def _discover_statistically(self, df: pd.DataFrame) -> nx.DiGraph:
        """PC ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ì¡°ê±´ë¶€ ë…ë¦½ì„± ê¸°ë°˜ ì¸ê³¼ê´€ê³„ë¥¼ ë°œê²¬í•©ë‹ˆë‹¤."""
        self.logger.info("   [2] Statistical Discovery: PC Algorithm ì‹¤í–‰ ì¤‘...")

        numeric_df = df.select_dtypes(include=[np.number])
        columns = numeric_df.columns.tolist()
        data = numeric_df.values

        dag = nx.DiGraph()
        dag.add_nodes_from(columns)

        try:
            from causallearn.search.ConstraintBased.PC import pc

            cg = pc(data, alpha=0.05, indep_test='fisherz', show_progress=False)
            adj = cg.G.graph  # numpy adjacency matrix

            for i in range(len(columns)):
                for j in range(len(columns)):
                    if adj[i, j] == -1 and adj[j, i] == 1:
                        # i â†’ j (ë°©í–¥ í™•ì •)
                        dag.add_edge(columns[i], columns[j])
                    elif adj[i, j] == -1 and adj[j, i] == -1:
                        # i â€” j (ë¬´ë°©í–¥) â†’ ë„ë©”ì¸ heuristicìœ¼ë¡œ ë°©í–¥ ê²°ì •
                        if columns[i] in ("age", "income", "credit_score"):
                            dag.add_edge(columns[i], columns[j])
                        else:
                            dag.add_edge(columns[j], columns[i])

            self.logger.info("       PC Algorithm ì™„ë£Œ (ì—£ì§€ %dê°œ ë°œê²¬)", dag.number_of_edges())

        except ImportError:
            self.logger.warning("       causal-learn ë¯¸ì„¤ì¹˜ â€” ìƒê´€ heuristic fallback ì‚¬ìš©")
            corr_matrix = numeric_df.corr().abs()
            threshold = 0.3

            for i, col_a in enumerate(columns):
                for j, col_b in enumerate(columns):
                    if i >= j:
                        continue
                    if corr_matrix.iloc[i, j] > threshold:
                        if col_a == "age":
                            dag.add_edge(col_a, col_b)
                        elif col_b == "age":
                            dag.add_edge(col_b, col_a)
                        else:
                            dag.add_edge(col_a, col_b)

        return dag

    def _merge_graphs(self, prior: nx.DiGraph, stat: nx.DiGraph) -> nx.DiGraph:
        """LLMì˜ ê°€ì„¤(Prior)ê³¼ í†µê³„ì  ë°œê²¬(Data)ì„ í†µí•©í•©ë‹ˆë‹¤."""
        self.logger.info("   [3] Hybrid Fusion: ê°€ì„¤ê³¼ ë°ì´í„°ì˜ í†µí•©")
        
        # ê¸°ë³¸ ì „ëµ: í†µê³„ì  ë°œê²¬ì„ ì¡´ì¤‘í•˜ë˜, LLMì˜ ìƒì‹ìœ¼ë¡œ ë°©í–¥ì„ êµì •
        merged = stat.copy()
        
        # LLMì˜ ê°•ë ¥í•œ ì œì•½ì¡°ê±´(Hard Constraints) ì ìš©
        # ì˜ˆ: Priorì— ìˆëŠ” ì—£ì§€ëŠ” ë°˜ë“œì‹œ í¬í•¨í•˜ê±°ë‚˜ ë°©í–¥ì„ ê°•ì œ
        for u, v in prior.edges():
            if not merged.has_edge(u, v):
                # ë°ì´í„°ì—ì„  ì•½í–ˆì§€ë§Œ ìƒì‹ì ìœ¼ë¡œ í™•ì‹¤í•˜ë©´ ì¶”ê°€
                if not merged.has_edge(v, u): # ì—­ë°©í–¥ì´ ì—†ë‹¤ë©´
                    merged.add_edge(u, v)
            elif merged.has_edge(v, u):
                # ë°ì´í„°ê°€ ì—­ë°©í–¥ì„ ê°€ë¦¬í‚¤ë©´, ìƒì‹(LLM)ì„ ìš°ì„ í•˜ì—¬ ë’¤ì§‘ìŒ
                merged.remove_edge(v, u)
                merged.add_edge(u, v)
                
        return merged
