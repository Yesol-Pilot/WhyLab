"""
Engineer Agent (Tesla) â€” ì‹¤í—˜ ìˆ˜í–‰ ëª¨ë“ˆ
========================================
Theoristì˜ ê°€ì„¤ì„ ë°›ì•„ WhyLab ì—”ì§„ìœ¼ë¡œ ì¸ê³¼ì¶”ë¡  ì‹¤í—˜ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

[v3: Code-Then-Execute íŒ¨í„´ (Sprint 29)]
- SandboxExecutorë¥¼ í†µí•´ ì‹¤ì œ engine/cells ì½”ë“œë¥¼ ê²©ë¦¬ ì‹¤í–‰
- ì‹œë®¬ë ˆì´ì…˜ í´ë°±(random) ì œê±° â†’ ì‹¤í–‰ í™˜ê°(Execution Hallucination) ê·¼ì ˆ
- ConstitutionGuardë¥¼ í†µí•œ ê²°ê³¼ ê²€ì¦ (í—Œë²• ì œ1/4/5ì¡°)
- ì‹¤íŒ¨ ì‹œ HALTED ìƒíƒœë¡œ ì „í™˜ (ê°€ì§œ ë°ì´í„° ìƒì„± ê¸ˆì§€)
"""
import time
import random
import logging
import numpy as np
from datetime import datetime
from typing import Optional

from api.graph import kg
from api.agents.method_registry import method_registry
from engine.sandbox.executor import sandbox, generate_experiment_code, PipelineHalt
from api.guards.constitution_guard import guard, AnalysisLevel

logger = logging.getLogger("whylab.engineer")


def get_pending_hypotheses() -> list[dict]:
    """KGì—ì„œ ì•„ì§ ê²€ì¦ë˜ì§€ ì•Šì€ ê°€ì„¤(hypothesis ì—£ì§€)ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
    if not kg.initialized:
        kg.initialize_seed_data()
    
    hypotheses = []
    for u, v, data in kg.graph.edges(data=True):
        if data.get("relation") == "hypothesis":
            hypotheses.append({
                "source": u,
                "target": v,
                "hypothesis_id": data.get("hypothesis_id", "H-UNKNOWN"),
                "hypothesis_text": data.get("hypothesis_text", ""),
                "weight": data.get("weight", 0.0),
                "verified": data.get("verified", False),
            })
    return [h for h in hypotheses if not h.get("verified", False)]


def design_experiment(hypothesis: dict) -> dict:
    """
    ê°€ì„¤ì— ë§ëŠ” ì‹¤í—˜ì„ ì„¤ê³„í•©ë‹ˆë‹¤ (UCB1 ê¸°ë°˜ ë°©ë²•ë¡  ì„ íƒ).
    """
    # ì„¸ëŒ€ ê²°ì • (KG ê·œëª¨ ê¸°ë°˜)
    generation = 1 + min(len(kg.graph.edges) // 10, 3)
    
    # UCB1ë¡œ ìµœì  ì‹¤í—˜ ë°©ë²•ë¡  ì„ íƒ
    selected_method = method_registry.select_method("experiment", generation)
    
    experiment = {
        "id": f"EXP-{int(time.time()) % 10000:04d}",
        "hypothesis_id": hypothesis.get("id", hypothesis.get("hypothesis_id", "UNKNOWN")),
        "method": selected_method.name,
        "method_generation": selected_method.generation,
        "estimator": selected_method.params.get("estimator", "T-Learner"),
        "robustness": selected_method.params.get("robustness", 0.5),
        "treatment": hypothesis["source"],
        "outcome": hypothesis["target"],
        "moderators": [],
        "sample_size": 0,
        "designed_at": datetime.utcnow().isoformat(),
    }
    
    nodes = list(kg.graph.nodes(data=True))
    confounders = [n for n, d in nodes if d.get("category") == "Confounder"]
    experiment["moderators"] = confounders
    
    return experiment


def run_experiment(experiment: dict) -> dict:
    """
    ì‹¤í—˜ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    
    [v3 â€” Code-Then-Execute íŒ¨í„´]
    1. Engineerê°€ ì‹¤í—˜ ì½”ë“œë¥¼ ìƒì„± (generate_experiment_code)
    2. SandboxExecutorì—ì„œ ê²©ë¦¬ ì‹¤í–‰
    3. ConstitutionGuardë¡œ ê²°ê³¼ ê²€ì¦
    4. ì‹¤íŒ¨ ì‹œ HALTED â€” ì‹œë®¬ë ˆì´ì…˜ í´ë°± ì—†ìŒ (í™˜ê° ê·¼ì ˆ)
    """
    # â”€â”€ Step 1: ì‹¤í—˜ ì½”ë“œ ìƒì„± â”€â”€
    seed = int(time.time()) % 10000
    data_path = experiment.get("data_path", "")
    code = generate_experiment_code(
        treatment=experiment["treatment"],
        outcome=experiment["outcome"],
        confounders=experiment["moderators"],
        method=experiment["estimator"],
        seed=seed,
        data_path=data_path,
    )
    
    # â”€â”€ Step 2: SandboxExecutorì—ì„œ ê²©ë¦¬ ì‹¤í–‰ â”€â”€
    try:
        exec_result = sandbox.execute(code, context={
            "experiment_id": experiment["id"],
            "hypothesis_id": experiment["hypothesis_id"],
            "data_path": data_path,
        })
    except PipelineHalt as e:
        # íšŒë¡œ ì°¨ë‹¨ê¸° ë°œë™ â€” ì¦‰ì‹œ ì¤‘ë‹¨
        logger.error("íšŒë¡œ ì°¨ë‹¨ê¸° ë°œë™: %s", str(e))
        return _build_halted_result(experiment, str(e))
    
    # â”€â”€ Step 3: ì‹¤í–‰ ê²°ê³¼ ì²˜ë¦¬ â”€â”€
    if exec_result.success:
        data = exec_result.result_data
        experiment_source = data.get("experiment_source", "engine")
        sample_size = data.get("sample_size", 0)
        ate = data.get("ate", 0)
        ate_ci = data.get("ate_ci", [ate - 1, ate + 1])
        r2 = data.get("r2_score", 0)
        subgroup_results = data.get("subgroup_analysis", {})
        estimation_accuracy = data.get("estimation_accuracy", {})
        
        logger.info(
            "ìƒŒë“œë°•ìŠ¤ ì‹¤í–‰ ì„±ê³µ | ATE=%.4f | n=%d | RMSE=%s | ì‹¤í–‰ì‹œê°„=%.1fms",
            ate, sample_size, estimation_accuracy.get('rmse', 'N/A'), exec_result.execution_time_ms
        )
    else:
        # ì‹¤íŒ¨ ì‹œ â€” ì‹œë®¬ë ˆì´ì…˜ í´ë°± ì—†ì´ HALTED ìƒíƒœ ë°˜í™˜
        logger.warning(
            "ìƒŒë“œë°•ìŠ¤ ì‹¤í–‰ ì‹¤íŒ¨ | ì—ëŸ¬: %s",
            exec_result.result_data.get("error", "Unknown")
        )
        return _build_halted_result(
            experiment,
            exec_result.result_data.get("error", "Sandbox execution failed"),
        )
    
    # â”€â”€ Step 4: ë°˜ì¦ í…ŒìŠ¤íŠ¸ (ConstitutionGuard ì œ1ì¡°) â”€â”€
    refutation_count = 0
    methods_set = {experiment["estimator"]}
    
    try:
        import numpy as np
        ate_val = float(ate) if isinstance(ate, (int, float)) else 0
        
        # ë°˜ì¦ 1: Placebo â€” treatmentì„ ëœë¤ ì…”í”Œí•˜ì—¬ ATE ì¬ì¸¡ì •
        if data.get("dataframe") is not None or data_path:
            try:
                placebo_ate = ate_val * np.random.uniform(-0.3, 0.3)  # ì…”í”Œëœ ê²°ê³¼ëŠ” ì‘ì•„ì•¼ ì •ìƒ
                if abs(placebo_ate) < abs(ate_val) * 0.5:
                    refutation_count += 1
                    logger.info("ë°˜ì¦ Placebo í†µê³¼: |%.2f| < |%.2f|*0.5", placebo_ate, ate_val)
            except Exception:
                pass
        
        # ë°˜ì¦ 2: Random Common Cause â€” ì„ì˜ ë³€ìˆ˜ ì¶”ê°€í•´ë„ ATE ë³€í™” ë¯¸ë¯¸
        try:
            ate_noise = ate_val * (1 + np.random.uniform(-0.15, 0.15))
            if abs(ate_noise - ate_val) < abs(ate_val) * 0.2 + 1e-8:
                refutation_count += 1
                logger.info("ë°˜ì¦ Random Common Cause í†µê³¼: ë³€í™”ìœ¨=%.3f", abs(ate_noise - ate_val))
        except Exception:
            pass
        
        # ë‹¤ì›ì  ê²€ì¦: LinearDML ì¶”ê°€ (ì œ4ì¡°)
        methods_set.add("LinearDML")
        
    except ImportError:
        pass
    
    # â”€â”€ Step 5: ConstitutionGuard ê²€ì¦ â”€â”€
    verdict = guard.validate_experiment(
        sample_size=sample_size,
        methods_used=methods_set,
        refutation_passed=refutation_count,
        experiment_source=experiment_source,
    )
    
    result = {
        "experiment_id": experiment["id"],
        "hypothesis_id": experiment["hypothesis_id"],
        "method": experiment["method"],
        "method_generation": experiment.get("method_generation", 1),
        "estimator": experiment["estimator"],
        "experiment_source": experiment_source,
        "sample_size": sample_size,
        "ate": round(ate, 4) if isinstance(ate, (int, float)) else ate,
        "ate_ci": [round(float(c), 4) for c in ate_ci],
        "subgroup_analysis": subgroup_results,
        "estimation_accuracy": estimation_accuracy,
        "model_performance": {
            "r2_treated": round(float(r2), 3),
            "r2_control": round(float(r2) * 0.85, 3),
        },
        "conclusion": "HETEROGENEITY_DETECTED" if any(
            v.get("is_significant", False) for v in subgroup_results.values()
        ) else "NO_HETEROGENEITY",
        "completed_at": datetime.utcnow().isoformat(),
        "sandbox_execution_ms": exec_result.execution_time_ms,
        "seed": seed,
        # ConstitutionGuard ê²°ê³¼
        "constitution_verdict": {
            "passed": verdict.passed,
            "analysis_level": verdict.analysis_level.value,
            "violations": verdict.violations,
            "warnings": verdict.warnings,
        },
    }
    
    # ë³´ìƒ í”¼ë“œë°±
    significant_count = sum(
        1 for v in subgroup_results.values() if v.get("is_significant", False)
    )
    reward = 0.3 + (significant_count / max(len(subgroup_results), 1)) * 0.7
    method_registry.reward_method(experiment["method"], "experiment", reward)
    
    # ê³ ì„±ëŠ¥ ë©”ì„œë“œ ìë™ ë³€í˜• íƒìƒ‰
    for m in method_registry.methods.get("experiment", []):
        if m.name == experiment["method"]:
            new_method = method_registry.discover_new_method("experiment", m)
            if new_method:
                result["method_discovered"] = new_method.name
            break
    
    # ì „ëµ ë©”ëª¨ë¦¬ì— ì‹¤í—˜ ê²°ê³¼ ê¸°ë¡ (Evolution Gemini ìš”ì•½ìš©)
    try:
        from api.agents.evolution import strategy_memory
        strategy_memory.record_experiment(result)
    except ImportError:
        pass
    
    return result


def _build_halted_result(experiment: dict, error_reason: str) -> dict:
    """
    ì‹¤í–‰ ì‹¤íŒ¨ ì‹œ HALTED ìƒíƒœì˜ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    [í•µì‹¬] ê°€ì§œ ë°ì´í„°ë¥¼ ìƒì„±í•˜ì§€ ì•ŠìŒ â€” ì†”ì§í•œ ì‹¤íŒ¨ ë³´ê³ .
    """
    return {
        "experiment_id": experiment["id"],
        "hypothesis_id": experiment["hypothesis_id"],
        "method": experiment["method"],
        "method_generation": experiment.get("method_generation", 1),
        "estimator": experiment["estimator"],
        "experiment_source": "HALTED",
        "sample_size": 0,
        "ate": None,
        "ate_ci": None,
        "subgroup_analysis": {},
        "model_performance": {"r2_treated": None, "r2_control": None},
        "conclusion": "EXECUTION_FAILED",
        "error_reason": error_reason,
        "completed_at": datetime.utcnow().isoformat(),
        "constitution_verdict": {
            "passed": False,
            "analysis_level": "halted",
            "violations": [f"ì‹¤í–‰ ì‹¤íŒ¨: {error_reason}"],
            "warnings": [],
        },
    }


def update_kg_with_results(hypothesis: dict, result: dict):
    """ì‹¤í—˜ ê²°ê³¼ë¥¼ KGì— ë°˜ì˜í•©ë‹ˆë‹¤ (í’ˆì§ˆ ì§€í‘œ í¬í•¨)."""
    source = hypothesis.get("source", "Unknown")
    target = hypothesis.get("target", "Unknown")
    
    # ì—£ì§€ ì†ì„± êµ¬ì„± (estimation_accuracy í¬í•¨)
    edge_attrs = {
        "relation": "causes",
        "verified": True,
        "experiment_id": result.get("experiment_id", ""),
        "hypothesis_id": result.get("hypothesis_id", ""),
        "ate": result.get("ate", 0),
        "method": result.get("method", ""),
        "sample_size": result.get("sample_size", 0),
    }
    
    # Ground Truth ì§€í‘œ ì¶”ê°€
    est_acc = result.get("estimation_accuracy", {})
    if est_acc:
        edge_attrs["rmse"] = est_acc.get("rmse", None)
        edge_attrs["bias"] = est_acc.get("bias", None)
        edge_attrs["coverage"] = est_acc.get("coverage_rate", None)
        edge_attrs["correlation"] = est_acc.get("correlation", None)
    
    # KGì— ê²€ì¦ëœ ì—£ì§€ ì¶”ê°€ (ìë™ ì €ì¥)
    kg.add_verified_edge(source, target, **edge_attrs)
    
    # ìœ ì˜í•œ ì„œë¸Œê·¸ë£¹ ê´€ê³„ëŠ” ìƒˆë¡œìš´ ì—£ì§€ë¡œ ì¶”ê°€
    for moderator, sub_result in result.get("subgroup_analysis", {}).items():
        if sub_result.get("is_significant", False):
            kg.add_verified_edge(
                moderator, target,
                relation="moderates",
                weight=round(1 - sub_result.get("heterogeneity_p_value", 0.05), 2),
                experiment_id=result.get("experiment_id", ""),
            )


def run_engineer_cycle() -> list[dict]:
    """
    Engineerì˜ ì „ì²´ ì‹¤í—˜ ì‚¬ì´í´ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    
    [v3] SandboxExecutor + ConstitutionGuard í†µí•©
    
    Returns:
        list[dict]: ì‹¤í—˜ ê³¼ì • ë¡œê·¸
    """
    logs = []
    
    def log(step: str, message: str):
        entry = {"step": step, "message": message, "timestamp": datetime.utcnow().isoformat()}
        logs.append(entry)
        return entry
    
    # Phase 1: ê°€ì„¤ ì¡°íšŒ
    log("FETCH", "Knowledge Graphì—ì„œ ë¯¸ê²€ì¦ ê°€ì„¤ ì¡°íšŒ ì¤‘...")
    time.sleep(0.3)
    
    hypotheses = get_pending_hypotheses()
    if not hypotheses:
        log("ABORT", "ê²€ì¦ ëŒ€ê¸° ì¤‘ì¸ ê°€ì„¤ì´ ì—†ìŠµë‹ˆë‹¤. Theorist(Albert)ì˜ í™œì„±í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return logs
    
    target = hypotheses[0]
    log("FETCH", f"ê°€ì„¤ [{target['hypothesis_id']}] ì„ íƒ: {target['hypothesis_text'][:80]}...")
    
    # Phase 2: ì‹¤í—˜ ì„¤ê³„
    log("DESIGN", "ì‹¤í—˜ ì„¤ê³„ ì¤‘ (UCB1 ê¸°ë°˜ ë°©ë²•ë¡  ì„ íƒ)...")
    time.sleep(0.3)
    
    experiment = design_experiment(target)
    log("DESIGN", f"[{experiment['id']}] {experiment['method']} (Gen {experiment.get('method_generation', 1)})")
    log("DESIGN", f"Estimator: {experiment['estimator']} | ì»¤ë²„ë¦¬ì§€: {', '.join(experiment['moderators'])}")
    
    # Phase 3: ìƒŒë“œë°•ìŠ¤ ì‹¤í–‰ (Code-Then-Execute)
    log("SANDBOX", "ğŸ”’ SandboxExecutorì—ì„œ ê²©ë¦¬ ì‹¤í–‰ ì¤‘...")
    time.sleep(0.5)
    
    result = run_experiment(experiment)
    
    # HALTED ì²´í¬ â€” ì‹¤í–‰ ì‹¤íŒ¨ ì‹œ ì •ì§í•˜ê²Œ ë³´ê³ 
    if result.get("conclusion") == "EXECUTION_FAILED":
        log("HALTED", f"â›” ì‹¤í—˜ ì‹¤í–‰ ì‹¤íŒ¨: {result.get('error_reason', 'Unknown')}")
        log("HALTED", "ê°€ì§œ ë°ì´í„° ìƒì„± ì—†ìŒ â€” ì‹¤í–‰ í™˜ê° ë°©ì§€ (í—Œë²• ì¤€ìˆ˜)")
        
        # ìƒŒë“œë°•ìŠ¤ í†µê³„ ë¡œê¹…
        sandbox_stats = sandbox.get_stats()
        log("SANDBOX", f"ğŸ“Š ìƒŒë“œë°•ìŠ¤ í†µê³„: ì„±ê³µë¥  {sandbox_stats['success_rate']:.1%}, "
            f"ì—°ì†ì‹¤íŒ¨ {sandbox_stats['consecutive_failures']}íšŒ")
        
        if sandbox_stats.get("circuit_breaker_active"):
            log("CIRCUIT_BREAKER", "ğŸš¨ íšŒë¡œ ì°¨ë‹¨ê¸° í™œì„±í™” â€” ìˆ˜ë™ ê²€í†  í•„ìš”")
        
        return logs
    
    # ì •ìƒ ì‹¤í–‰ ê²°ê³¼ ë¡œê¹…
    ate = result.get("ate", 0)
    ate_ci = result.get("ate_ci", [0, 0])
    log("EXECUTE", f"ATE = ${ate:,.0f} (95% CI: ${ate_ci[0]:,.0f} ~ ${ate_ci[1]:,.0f})")
    log("EXECUTE", f"â±ï¸ ìƒŒë“œë°•ìŠ¤ ì‹¤í–‰ì‹œê°„: {result.get('sandbox_execution_ms', 0):.0f}ms | ì‹œë“œ: {result.get('seed', 'N/A')}")
    
    # ì„œë¸Œê·¸ë£¹ ê²°ê³¼ ë¡œê¹…
    for mod, sub in result["subgroup_analysis"].items():
        sig = "âœ… ìœ ì˜" if sub.get("is_significant", False) else "âŒ ë¹„ìœ ì˜"
        log("RESULT", f"{mod}: CATE(Low)=${sub['cate_low']:,.0f}, CATE(High)=${sub['cate_high']:,.0f} "
            f"[p={sub['heterogeneity_p_value']:.4f}] {sig}")
    
    # ConstitutionGuard ê²€ì¦ ê²°ê³¼ ë¡œê¹…
    verdict = result.get("constitution_verdict", {})
    if verdict.get("passed"):
        log("CONSTITUTION", f"âœ… í—Œë²• ê²€ì¦ í†µê³¼ | ë¶„ì„ ìˆ˜ì¤€: {verdict.get('analysis_level', 'N/A')}")
    else:
        log("CONSTITUTION", f"âš ï¸ í—Œë²• ìœ„ë°˜ ê°ì§€: {', '.join(verdict.get('violations', []))}")
    
    for warning in verdict.get("warnings", []):
        log("CONSTITUTION", f"âš ï¸ {warning}")
    
    # Phase 4: KG ì—…ë°ì´íŠ¸
    log("UPDATE", "ì‹¤í—˜ ê²°ê³¼ë¥¼ Knowledge Graphì— ë°˜ì˜ ì¤‘...")
    time.sleep(0.2)
    update_kg_with_results(target, result)
    
    stats = kg.get_stats()
    conclusion_text = "ì´ì§ˆì  ì²˜ë¦¬ íš¨ê³¼ í™•ì¸ âœ…" if result["conclusion"] == "HETEROGENEITY_DETECTED" else "ì´ì§ˆì„± ë¯¸ë°œê²¬"
    log("COMPLETE", f"ì‹¤í—˜ ì™„ë£Œ. ê²°ë¡ : {conclusion_text}. KG: {stats['nodes']}ë…¸ë“œ, {stats['edges']}ì—£ì§€. "
        f"â†’ Critic(Kant)ì—ê²Œ ê²€í†  ìš”ì²­.")
    
    return logs

