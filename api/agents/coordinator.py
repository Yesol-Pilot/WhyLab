"""
Coordinator Agent v2 â€” E2E ì—°êµ¬ ìˆœí™˜ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ (Sprint 36)
================================================================
STEAM â†’ Theorist â†’ Engineer â†’ Sandbox â†’ Critic â†’ KG ë°˜ì˜ê¹Œì§€
ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ì™„ì „ ìˆœí™˜ì„ êµ¬í˜„í•©ë‹ˆë‹¤.

[ì„¤ê³„ ë¬¸ì„œ Â§3.1 ê³„ì¸µì  ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°-ì›Œì»¤ íŒ¨í„´]
- CoordinatorëŠ” ìœ ì¼í•œ ì „ì—­ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
- ëª¨ë“  ì—ì´ì „íŠ¸ ê°„ ë©”ì‹œì§€ íŒ¨ì‹±ì€ Coordinatorë¥¼ ê²½ìœ 

[7ë‹¨ê³„ íŒŒì´í”„ë¼ì¸]
1. select_agenda    â€” Directorì—ì„œ Grand Challenge ì„ íƒ
2. supply_data      â€” STEAM Generatorë¡œ í•©ì„± ë°ì´í„° ìƒì„±
3. generate_hypo    â€” Theorist í˜¸ì¶œ (KG gap ê¸°ë°˜)
4. run_experiment   â€” Engineerì— data_path ì „ë‹¬, Sandbox ì‹¤í–‰
5. review_result    â€” Critic íŒì • + ì¬ì‹¤í–‰ ë£¨í”„ (ìµœëŒ€ 2íšŒ)
6. update_knowledge â€” KGì— ê²°ê³¼ ë°˜ì˜
7. log_cycle        â€” DBì— ì‚¬ì´í´ ë¡œê·¸ ê¸°ë¡
"""
import os
import time
import logging
from datetime import datetime
from typing import Optional

logger = logging.getLogger("whylab.coordinator")

# â”€â”€ ì„¤ì • ìƒìˆ˜ â”€â”€
MAX_RETRY_ON_REVISE = 2          # Critic REVISE ì‹œ ì¬ì‹œë„ íšŸìˆ˜
CONSECUTIVE_TOPIC_LIMIT = 3      # í—Œë²• ì œ13ì¡°: ê°™ì€ ì£¼ì œ ì—°ì† ì„ íƒ ì œí•œ
DEFAULT_SAMPLE_SIZE = 3000
DEFAULT_SEED = 42


class CoordinatorV2:
    """
    v2 Coordinator â€” 7ë‹¨ê³„ E2E íŒŒì´í”„ë¼ì¸.
    
    ê¸°ì¡´ run_coordinator_cycle() í•¨ìˆ˜ë¥¼ ëŒ€ì²´í•©ë‹ˆë‹¤.
    """
    
    def __init__(self):
        self._recent_topics: list[str] = []
        self._cycle_count = 0
        self._last_cycle_at: Optional[str] = None
    
    def run_cycle(self) -> dict:
        """
        ì „ì²´ ì—°êµ¬ ì‚¬ì´í´ 1íšŒë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
        
        Returns:
            dict: ì‚¬ì´í´ ê²°ê³¼ (stages, hypothesis, experiment, verdict, metrics)
        """
        self._cycle_count += 1
        cycle_id = f"CYCLE-{self._cycle_count:04d}"
        start_time = time.time()
        
        result = {
            "cycle_id": cycle_id,
            "started_at": datetime.utcnow().isoformat(),
            "stages": [],
            "status": "IN_PROGRESS",
        }
        
        try:
            # â”€â”€ Step 1: ì•„ì  ë‹¤ ì„ íƒ â”€â”€
            challenge = self._select_agenda(result)
            
            # â”€â”€ Step 2: STEAM ë°ì´í„° ê³µê¸‰ â”€â”€
            data_info = self._supply_data(result, challenge)
            
            # â”€â”€ Step 3: ê°€ì„¤ ìƒì„± (STEAM ë°ì´í„° ì»¨í…ìŠ¤íŠ¸ í¬í•¨) â”€â”€
            hypothesis = self._generate_hypothesis(result, data_info)
            
            # â”€â”€ Step 4+5: ì‹¤í—˜ + íŒì • (ì¬ì‹œë„ ë£¨í”„) â”€â”€
            experiment_result, verdict = self._experiment_review_loop(
                result, hypothesis, data_info
            )
            
            # â”€â”€ Step 6: KG ì—…ë°ì´íŠ¸ â”€â”€
            self._update_knowledge(result, hypothesis, experiment_result, verdict)
            
            # â”€â”€ Step 7: ê²°ê³¼ ì¢…í•© â”€â”€
            elapsed = time.time() - start_time
            result["status"] = "COMPLETE"
            result["elapsed_seconds"] = round(elapsed, 2)
            result["hypothesis"] = hypothesis
            result["experiment"] = experiment_result
            result["verdict"] = verdict
            result["metrics"] = {
                "cycle_id": cycle_id,
                "challenge": challenge.get("id", "unknown"),
                "data_quality": data_info.get("quality_grade", "N/A"),
                "ate": experiment_result.get("ate", None),
                "verdict_action": verdict.get("action", "UNKNOWN"),
                "elapsed_seconds": round(elapsed, 2),
            }
            
        except Exception as e:
            logger.error("ì—°êµ¬ ì‚¬ì´í´ ì‹¤íŒ¨: %s", str(e))
            result["status"] = "ERROR"
            result["error"] = str(e)
        
        self._last_cycle_at = datetime.utcnow().isoformat()
        result["ended_at"] = self._last_cycle_at
        
        self._log_stage(result, "COMPLETE", f"ì‚¬ì´í´ {cycle_id} ì¢…ë£Œ â€” {result['status']}")
        
        return result
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Step 1: ì•„ì  ë‹¤ ì„ íƒ (í—Œë²• ì œ13ì¡° ì ìš©)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    def _select_agenda(self, result: dict) -> dict:
        """Directorì—ì„œ Grand Challengeë¥¼ ì„ íƒí•©ë‹ˆë‹¤."""
        self._log_stage(result, "AGENDA", "Grand Challenge ì„ íƒ ì¤‘...")
        
        from engine.agents.director import LabDirector
        director = LabDirector()
        challenges = director.challenges  # DirectorëŠ” challenges ë¦¬ìŠ¤íŠ¸ í•„ë“œ ì‚¬ìš©
        
        if not challenges:
            raise RuntimeError("Grand Challenges DBê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        
        # í—Œë²• ì œ13ì¡°: ê°™ì€ ì£¼ì œ 3íšŒ ì—°ì† ê¸ˆì§€
        available = [
            c for c in challenges
            if c.get("id", "") not in self._recent_topics[-CONSECUTIVE_TOPIC_LIMIT:]
        ] or challenges  # ëª¨ë‘ ì œì™¸ë˜ë©´ ì „ì²´ í’€ì—ì„œ ì„ íƒ
        
        # ì˜í–¥ë„(Impact) Ã— ë‚œì´ë„(Difficulty) ê¸°ë°˜ ì„ íƒ
        impact_map = {"Critical": 4, "High": 3, "Medium": 2, "Low": 1}
        selected = max(available, key=lambda c: impact_map.get(c.get("impact", "Medium"), 2))
        
        self._recent_topics.append(selected.get("id", "unknown"))
        self._log_stage(
            result, "AGENDA",
            f"ì„ íƒ: [{selected.get('id', '?')}] {selected.get('title', 'Untitled')} (ì˜í–¥ë„: {selected.get('impact', 'N/A')})"
        )
        
        return selected
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Step 2: STEAM í•©ì„± ë°ì´í„° ê³µê¸‰
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    def _supply_data(self, result: dict, challenge: dict) -> dict:
        """STEAM Generatorë¡œ í•©ì„± ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        self._log_stage(result, "DATA", "STEAM í•©ì„± ë°ì´í„° ìƒì„± ì‹œì‘...")
        
        from engine.data.steam_generator import steam  # ëª¨ë“ˆ ë ˆë²¨ ì‹±ê¸€í„´
        
        # Challenge ì¹´í…Œê³ ë¦¬ì™€ DGP ë§¤í•‘
        dgp_list = steam.available_dgps  # @property â†’ list[str]
        if not dgp_list:
            raise RuntimeError("STEAM DGP í…œí”Œë¦¿ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ë§¤ì¹­ ì‹œë„ â†’ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ DGP ì‚¬ìš©
        category = challenge.get("category", "").lower()
        matched_dgp = None
        if category:
            for dname in dgp_list:
                template = steam._templates.get(dname)
                if template and category in template.category.lower():
                    matched_dgp = dname
                    break
        
        dgp_name = matched_dgp or dgp_list[0]
        
        # ë°ì´í„° ìƒì„± â†’ SyntheticData ê°ì²´ ë°˜í™˜
        syn_data = steam.generate(
            dgp_name=dgp_name,
            n=DEFAULT_SAMPLE_SIZE,
            seed=DEFAULT_SEED,
        )
        
        # í’ˆì§ˆ í‰ê°€
        quality = steam.evaluate_quality(syn_data)
        quality_grade = quality.get("grade", "N/A")
        ate_true = syn_data.ate_true
        
        # CSVë¡œ ì €ì¥
        data_path = self._save_data_csv(syn_data, dgp_name)
        
        # STEAM ë°ì´í„°ì˜ ì‹¤ì œ ì»¬ëŸ¼ëª… ì¶”ì¶œ (ê°€ì„¤ ë³€ìˆ˜ëª…ê³¼ ë§¤í•‘ìš©)
        all_cols = list(syn_data.df.columns)
        confounders = [c for c in all_cols 
                       if c not in (syn_data.treatment_col, syn_data.outcome_col)]
        
        data_info = {
            "dgp_name": dgp_name,
            "sample_size": syn_data.n,
            "quality_grade": quality_grade,
            "ate_true": ate_true,
            "data_path": data_path,
            "treatment": syn_data.treatment_col,
            "outcome": syn_data.outcome_col,
            "confounders": confounders[:6],  # ìƒìœ„ 6ê°œë¡œ ì œí•œ (ê³¼ì í•© ë°©ì§€)
        }
        
        self._log_stage(
            result, "DATA",
            f"STEAM ìƒì„± ì™„ë£Œ: {dgp_name} (n={syn_data.n}, Grade={quality_grade}, ATE={ate_true:.3f})"
        )
        
        return data_info
    
    def _save_data_csv(self, syn_data, dgp_name: str) -> str:
        """SyntheticDataì˜ DataFrameì„ CSVë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
        base_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "uploads")
        os.makedirs(base_dir, exist_ok=True)
        
        timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
        filename = f"steam_{dgp_name}_{timestamp}.csv"
        filepath = os.path.join(base_dir, filename)
        
        # SyntheticData.df (pandas DataFrame) â†’ CSV
        syn_data.df.to_csv(filepath, index=False, encoding="utf-8")
        
        logger.info("STEAM ë°ì´í„° ì €ì¥: %s (%dí–‰)", filepath, len(syn_data.df))
        return filepath
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Step 3: ê°€ì„¤ ìƒì„±
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    def _generate_hypothesis(self, result: dict, data_info: dict = None) -> dict:
        """Theoristë¥¼ í˜¸ì¶œí•˜ì—¬ ê°€ì„¤ì„ ìƒì„±í•˜ê³ , STEAM ë³€ìˆ˜ë¥¼ ê°•ì œ ë§¤í•‘í•©ë‹ˆë‹¤."""
        self._log_stage(result, "HYPOTHESIS", "Theorist(Albert) ê°€ì„¤ ìƒì„± ì¤‘...")
        
        from api.agents.theorist import generate_hypothesis
        hypothesis = generate_hypothesis()
        
        # STEAM ë°ì´í„°ì˜ treatment/outcomeì„ ê°€ì„¤ì— **ê°•ì œ ë§¤í•‘**
        # Theoristê°€ KG seed ë³€ìˆ˜ëª…ì„ ì‚¬ìš©í•˜ë¯€ë¡œ, STEAM ë³€ìˆ˜ëª…ìœ¼ë¡œ ë®ì–´ì“°ê¸° í•„ìˆ˜
        if data_info:
            hypothesis["source"] = data_info.get("treatment", hypothesis.get("iv", "Treatment"))
            hypothesis["target"] = data_info.get("outcome", hypothesis.get("dv", "Outcome"))
            hypothesis["iv"] = hypothesis["source"]
            hypothesis["dv"] = hypothesis["target"]
        
        self._log_stage(
            result, "HYPOTHESIS",
            f"[{hypothesis.get('id','?')}] {hypothesis.get('text','')[:80]}... "
            f"(source: {hypothesis.get('hypothesis_source', 'N/A')}, "
            f"IV={hypothesis.get('source','?')}, DV={hypothesis.get('target','?')})"
        )
        
        return hypothesis
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Step 4+5: ì‹¤í—˜ + íŒì • ë£¨í”„
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    def _experiment_review_loop(
        self, result: dict, hypothesis: dict, data_info: dict
    ) -> tuple[dict, dict]:
        """
        Engineer ì‹¤í—˜ â†’ Critic íŒì • â†’ í•„ìš”ì‹œ ì¬ì‹¤í–‰ (ìµœëŒ€ MAX_RETRY_ON_REVISEíšŒ).
        """
        from api.agents.engineer import design_experiment, run_experiment
        from api.agents.critic import review_experiment
        
        experiment_result = {}
        verdict = {"action": "REJECT", "reason": "ì‹¤í—˜ì´ ìˆ˜í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
        
        # STEAM ë°ì´í„°ì—ì„œ moderators(ê³µë³€ëŸ‰) ìë™ ì¶”ì¶œ
        data_path = data_info.get("data_path", "")
        steam_moderators = []
        if data_path:
            try:
                import pandas as pd
                df_cols = list(pd.read_csv(data_path, nrows=0).columns)
                treatment_col = data_info.get("treatment", "")
                outcome_col = hypothesis.get("target", "")
                # treatment/outcome ì œì™¸í•œ ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ = ê³µë³€ëŸ‰
                steam_moderators = [
                    c for c in df_cols
                    if c not in (treatment_col, outcome_col, "true_cate")
                ]
            except Exception:
                pass
        
        for attempt in range(1, MAX_RETRY_ON_REVISE + 2):
            # â”€â”€ Step 4: ì‹¤í—˜ â”€â”€
            self._log_stage(
                result, "EXPERIMENT",
                f"Engineer(Tesla) ì‹¤í—˜ #{attempt} ì‹¤í–‰ ì¤‘... (data: {data_info['dgp_name']})"
            )
            
            experiment = design_experiment(hypothesis)
            # STEAM ë°ì´í„° ê²½ë¡œ + ê³µë³€ëŸ‰ ì£¼ì…          # STEAM ë°ì´í„°ì˜ ì‹¤ì œ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ì˜¤ë²„ë¼ì´ë“œ
            # (KG ê°€ì„¤ ë³€ìˆ˜ëª… "Job Training Program" â‰  CSV ì»¬ëŸ¼ëª… "alignment_training")
            experiment["data_path"] = data_path
            experiment["data_sample_size"] = data_info.get("sample_size", DEFAULT_SAMPLE_SIZE)
            if steam_moderators:
                experiment["moderators"] = steam_moderators
            
            if data_info.get("treatment"):
                experiment["treatment"] = data_info["treatment"]
            if data_info.get("outcome"):
                experiment["outcome"] = data_info["outcome"]
            if data_info.get("confounders"):
                experiment["moderators"] = data_info["confounders"]
            
            experiment_result = run_experiment(experiment)
            
            is_halted = experiment_result.get("experiment_source") == "HALTED"
            ate = experiment_result.get("ate", "N/A")
            
            self._log_stage(
                result, "EXPERIMENT",
                f"ì‹¤í—˜ #{attempt} ì™„ë£Œ â€” ATE={ate}, Source={'HALTED' if is_halted else 'engine'}"
            )
            
            # â”€â”€ Step 5: íŒì • â”€â”€
            self._log_stage(result, "REVIEW", f"Critic(Kant) íŒì • #{attempt}...")
            verdict = review_experiment(experiment_result)
            action = verdict.get("verdict", verdict.get("action", "REJECT")) if isinstance(verdict, dict) else "REJECT"
            
            self._log_stage(
                result, "REVIEW",
                f"Critic íŒì •: {action} (ì‹œë„ {attempt}/{MAX_RETRY_ON_REVISE + 1})"
            )
            
            if action == "ACCEPT":
                logger.info("ì‹¤í—˜ ACCEPT â€” ì‚¬ì´í´ ì„±ê³µ")
                break
            elif action == "REVISE" and attempt <= MAX_RETRY_ON_REVISE:
                logger.warning("REVISE â€” ì¬ì‹œë„ %d/%d", attempt, MAX_RETRY_ON_REVISE)
                continue
            else:
                logger.warning("REJECT ë˜ëŠ” ì¬ì‹œë„ í•œë„ ì´ˆê³¼ â€” ì‚¬ì´í´ ì¢…ë£Œ")
                break
        
        return experiment_result, verdict
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Step 6: Knowledge Graph ì—…ë°ì´íŠ¸
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    def _update_knowledge(
        self, result: dict, hypothesis: dict, experiment: dict, verdict: dict
    ):
        """ì‹¤í—˜ ê²°ê³¼ë¥¼ Knowledge Graphì— ë°˜ì˜í•©ë‹ˆë‹¤."""
        self._log_stage(result, "KG_UPDATE", "Knowledge Graph ì—…ë°ì´íŠ¸ ì¤‘...")
        
        from api.graph import kg
        
        action = verdict.get("verdict", verdict.get("action", "REJECT")) if isinstance(verdict, dict) else "REJECT"
        
        ate = experiment.get("ate")
        method = experiment.get("method", "unknown")
        exp_id = experiment.get("experiment_id", "")
        source = hypothesis.get("source", hypothesis.get("iv", "Unknown"))
        target = hypothesis.get("target", hypothesis.get("dv", "Unknown"))
        
        if action == "ACCEPT":
            # ì„±ê³µ â†’ ê²€ì¦ëœ ì—£ì§€
            kg.add_verified_edge(
                source, target,
                relation="causes", verified=True, weight=0.8,
                ate=ate, method=method, experiment_id=exp_id,
                verdict="ACCEPT", confidence="high",
            )
            self._log_stage(result, "KG_UPDATE", f"âœ… ê²€ì¦ ì™„ë£Œ: {source} â†’ {target} (ATE={ate})")
        elif action == "REVISE":
            # ì¡°ê±´ë¶€ â†’ LOW_CONFIDENCE ì—£ì§€
            kg.add_verified_edge(
                source, target,
                relation="may_cause", verified=False, weight=0.4,
                ate=ate, method=method, experiment_id=exp_id,
                verdict="REVISE", confidence="low",
            )
            self._log_stage(result, "KG_UPDATE", f"âš ï¸ ì¡°ê±´ë¶€: {source} â†’ {target} (ATE={ate})")
        else:
            # REJECT â†’ íƒìƒ‰ì  ê²°ê³¼ë¡œ ê¸°ë¡ (ì§€ì‹ ì¶•ì  ë³´ì¥)
            kg.add_verified_edge(
                source, target,
                relation="explored", verified=False, weight=0.1,
                ate=ate, method=method, experiment_id=exp_id,
                verdict="REJECT", confidence="exploratory",
            )
            self._log_stage(result, "KG_UPDATE", f"ğŸ” íƒìƒ‰: {source} â†’ {target} (ATE={ate}, REJECT)")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ìœ í‹¸ë¦¬í‹°
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    def _log_stage(self, result: dict, stage: str, message: str):
        """ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ì— ë‹¨ê³„ ë¡œê·¸ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤."""
        entry = {
            "stage": stage,
            "message": message,
            "timestamp": datetime.utcnow().isoformat(),
        }
        result["stages"].append(entry)
        logger.info("[%s] %s", stage, message)
    
    def get_status(self) -> dict:
        """Coordinator í˜„ì¬ ìƒíƒœë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return {
            "version": "v2",
            "cycle_count": self._cycle_count,
            "last_cycle_at": self._last_cycle_at,
            "recent_topics": self._recent_topics[-5:],
        }


# â”€â”€ ì‹±ê¸€í„´ â”€â”€
coordinator_v2 = CoordinatorV2()


# â”€â”€ í•˜ìœ„ í˜¸í™˜: ê¸°ì¡´ run_coordinator_cycle() ì¸í„°í˜ì´ìŠ¤ ìœ ì§€ â”€â”€
def run_coordinator_cycle() -> list[dict]:
    """
    ê¸°ì¡´ API í˜¸í™˜ìš© ë˜í¼.
    Coordinator v2ë¥¼ ì‹¤í–‰í•˜ê³ , ê¸°ì¡´ ë¡œê·¸ í¬ë§·ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    result = coordinator_v2.run_cycle()
    
    # ê¸°ì¡´ í¬ë§· í˜¸í™˜: stages â†’ logs ë¦¬ìŠ¤íŠ¸ ë³€í™˜
    logs = []
    for stage in result.get("stages", []):
        logs.append({
            "step": stage["stage"],
            "message": stage["message"],
            "timestamp": stage["timestamp"],
        })
    
    return logs
