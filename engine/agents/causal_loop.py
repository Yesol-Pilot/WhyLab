# -*- coding: utf-8 -*-
"""CausalLoopAgent â€” ë°˜ë³µ ìê¸°êµì • ì¸ê³¼ ë°œê²¬ ì—ì´ì „íŠ¸.

ê°€ì„¤ â†’ ê²€ì¦ â†’ ë°˜ì¦ â†’ ìˆ˜ì • ìˆœí™˜ ì›Œí¬í”Œë¡œ.
LLMì´ ê°€ì„¤ì„ ìƒì„±í•˜ê³ , í†µê³„ì  ë°©ë²•ì´ ê²€ì¦í•˜ê³ ,
ë¶ˆì¼ì¹˜ ì‹œ ì—ì´ì „íŠ¸ê°€ ê°€ì„¤ì„ ìˆ˜ì •í•˜ì—¬ ë°˜ë³µí•©ë‹ˆë‹¤.

R&D ìŠ¤í”„ë¦°íŠ¸ 1: CausalLoop Agent (ì¶• 2-1).
"""

from __future__ import annotations

import logging
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
import pandas as pd

logger = logging.getLogger(__name__)


@dataclass
class CausalHypothesis:
    """ì¸ê³¼ ê°€ì„¤."""
    edges: List[Tuple[str, str]]  # (ì›ì¸, ê²°ê³¼) ìŒ ë¦¬ìŠ¤íŠ¸
    confidence: float = 0.0
    rationale: str = ""
    iteration: int = 0


@dataclass
class LoopState:
    """ë°˜ë³µ ìƒíƒœ."""
    hypotheses: List[CausalHypothesis] = field(default_factory=list)
    validations: List[Dict[str, Any]] = field(default_factory=list)
    refutations: List[Dict[str, Any]] = field(default_factory=list)
    converged: bool = False
    iterations: int = 0
    final_dag: List[Tuple[str, str]] = field(default_factory=list)


class CausalLoopAgent:
    """ë°˜ë³µ ìê¸°êµì • ì¸ê³¼ ë°œê²¬ ì—ì´ì „íŠ¸.

    CausalLoop í”„ë¡œì„¸ìŠ¤:
    1. **ê°€ì„¤ ìƒì„±** (Hypothesize): LLM ë˜ëŠ” PC ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ì´ˆê¸° DAG ê°€ì„¤ ìƒì„±
    2. **ê²€ì¦** (Validate): ì¡°ê±´ë¶€ ë…ë¦½ ê²€ì • + ìƒê´€ ë¶„ì„ìœ¼ë¡œ ê°€ì„¤ ê²€ì¦
    3. **ë°˜ì¦** (Refute): ë°˜ì¦ ì¦ê±°(ì—­ë°©í–¥ ì¸ê³¼, ìˆ¨ê²¨ì§„ êµë€) íƒìƒ‰
    4. **ìˆ˜ì •** (Revise): ë¶ˆì¼ì¹˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ì„¤ ìˆ˜ì •
    5. **ìˆ˜ë ´ íŒë‹¨**: ìˆ˜ì • ì—†ìœ¼ë©´ ìˆ˜ë ´, ì•„ë‹ˆë©´ 1ë¡œ ë³µê·€

    Args:
        max_iterations: ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜.
        convergence_threshold: ìˆ˜ë ´ íŒë‹¨ ì„ê³„ê°’ (ë³€ê²½ëœ ì—£ì§€ ë¹„ìœ¨).
        significance_level: í†µê³„ ê²€ì • ìœ ì˜ ìˆ˜ì¤€.
    """

    def __init__(
        self,
        max_iterations: int = 5,
        convergence_threshold: float = 0.05,
        significance_level: float = 0.05,
    ) -> None:
        self.max_iterations = max_iterations
        self.convergence_threshold = convergence_threshold
        self.significance_level = significance_level

    def run(
        self,
        df: pd.DataFrame,
        treatment: str,
        outcome: str,
        features: Optional[List[str]] = None,
    ) -> LoopState:
        """CausalLoopë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

        Args:
            df: ë¶„ì„ ëŒ€ìƒ ë°ì´í„°í”„ë ˆì„.
            treatment: ì²˜ì¹˜ ë³€ìˆ˜ëª….
            outcome: ê²°ê³¼ ë³€ìˆ˜ëª….
            features: ê³µë³€ëŸ‰ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ìë™ ê°ì§€).

        Returns:
            LoopState: ë°˜ë³µ ê²°ê³¼.
        """
        if features is None:
            features = [c for c in df.columns if c not in [treatment, outcome]]

        all_vars = features + [treatment, outcome]
        state = LoopState()

        logger.info("ğŸ”„ CausalLoop ì‹œì‘ â€” ë³€ìˆ˜ %dê°œ, ìµœëŒ€ %díšŒ ë°˜ë³µ", len(all_vars), self.max_iterations)

        for iteration in range(1, self.max_iterations + 1):
            state.iterations = iteration

            # â”€â”€â”€â”€ 1. ê°€ì„¤ ìƒì„± â”€â”€â”€â”€
            hypothesis = self._hypothesize(df, all_vars, treatment, outcome, state)
            state.hypotheses.append(hypothesis)

            # â”€â”€â”€â”€ 2. ê²€ì¦ â”€â”€â”€â”€
            validation = self._validate(df, hypothesis, all_vars)
            state.validations.append(validation)

            # â”€â”€â”€â”€ 3. ë°˜ì¦ â”€â”€â”€â”€
            refutation = self._refute(df, hypothesis, treatment, outcome, features)
            state.refutations.append(refutation)

            # â”€â”€â”€â”€ 4. ìˆ˜ë ´ íŒë‹¨ â”€â”€â”€â”€
            if self._check_convergence(state, hypothesis, validation, refutation):
                state.converged = True
                state.final_dag = hypothesis.edges
                logger.info(
                    "âœ… CausalLoop ìˆ˜ë ´ (ë°˜ë³µ %díšŒ) â€” ì—£ì§€ %dê°œ",
                    iteration, len(hypothesis.edges),
                )
                break

            # â”€â”€â”€â”€ 5. ìˆ˜ì • (ë‹¤ìŒ ë°˜ë³µì—ì„œ ê°€ì„¤ ìƒì„± ì‹œ ë°˜ì˜) â”€â”€â”€â”€
            logger.info(
                "ğŸ” ë°˜ë³µ %d: ìˆ˜ì • í•„ìš” â€” ê¸°ê° %dê°œ, ì‹ ê·œ í›„ë³´ %dê°œ",
                iteration,
                refutation.get("rejected_count", 0),
                refutation.get("new_candidates", 0),
            )

        if not state.converged:
            # ìµœëŒ€ ë°˜ë³µ ë„ë‹¬ â€” ë§ˆì§€ë§‰ ê°€ì„¤ ì‚¬ìš©
            state.final_dag = state.hypotheses[-1].edges
            logger.warning("âš ï¸ CausalLoop ìµœëŒ€ ë°˜ë³µ ë„ë‹¬. ë§ˆì§€ë§‰ ê°€ì„¤ ì‚¬ìš©.")

        return state

    def _hypothesize(
        self,
        df: pd.DataFrame,
        all_vars: List[str],
        treatment: str,
        outcome: str,
        state: LoopState,
    ) -> CausalHypothesis:
        """ì¸ê³¼ ê°€ì„¤ì„ ìƒì„±í•©ë‹ˆë‹¤.

        ì²« ë°˜ë³µ: ìƒê´€ê´€ê³„ ê¸°ë°˜ ì´ˆê¸° DAG êµ¬ì„±.
        ì´í›„ ë°˜ë³µ: ì´ì „ ë°˜ì¦ ê²°ê³¼ë¥¼ ë°˜ì˜í•˜ì—¬ ìˆ˜ì •ëœ DAG.
        """
        iteration = state.iterations
        numeric_cols = [c for c in all_vars if df[c].dtype in [np.float64, np.int64, float, int]]

        if not numeric_cols:
            return CausalHypothesis(edges=[(treatment, outcome)], iteration=iteration)

        corr_matrix = df[numeric_cols].corr().abs()
        edges = []

        # Treatment â†’ Outcome (í•µì‹¬ ì—£ì§€)
        if treatment in numeric_cols and outcome in numeric_cols:
            edges.append((treatment, outcome))

        # ê°•í•œ ìƒê´€ê´€ê³„ ê¸°ë°˜ ì—£ì§€ í›„ë³´
        for i, v1 in enumerate(numeric_cols):
            for v2 in numeric_cols[i + 1:]:
                if v1 == v2:
                    continue
                r = corr_matrix.loc[v1, v2] if v1 in corr_matrix.index and v2 in corr_matrix.columns else 0
                if r > 0.3:
                    # ë°©í–¥ ê²°ì •: Treatment/Outcome ìš°ì„ 
                    if v2 == outcome:
                        edges.append((v1, v2))
                    elif v1 == outcome:
                        edges.append((v2, v1))
                    elif v1 == treatment:
                        edges.append((v1, v2))
                    elif v2 == treatment:
                        edges.append((v2, v1))
                    else:
                        edges.append((v1, v2))

        # ì´ì „ ë°˜ì¦ì—ì„œ ê¸°ê°ëœ ì—£ì§€ ì œê±°
        if state.refutations:
            last_refutation = state.refutations[-1]
            rejected = set(tuple(e) for e in last_refutation.get("rejected_edges", []))
            edges = [e for e in edges if e not in rejected]

        # ì¤‘ë³µ ì œê±°
        edges = list(set(edges))

        return CausalHypothesis(
            edges=edges,
            confidence=0.5 + 0.1 * iteration,
            rationale=f"ë°˜ë³µ {iteration}: ìƒê´€ ê¸°ë°˜ + ì´ì „ ë°˜ì¦ ë°˜ì˜",
            iteration=iteration,
        )

    def _validate(
        self,
        df: pd.DataFrame,
        hypothesis: CausalHypothesis,
        all_vars: List[str],
    ) -> Dict[str, Any]:
        """ê°€ì„¤ì˜ ê° ì—£ì§€ë¥¼ ì¡°ê±´ë¶€ ë…ë¦½ ê²€ì •ìœ¼ë¡œ ê²€ì¦í•©ë‹ˆë‹¤."""
        from scipy import stats

        validated = []
        failed = []

        for cause, effect in hypothesis.edges:
            if cause not in df.columns or effect not in df.columns:
                failed.append((cause, effect, "ë³€ìˆ˜ ì—†ìŒ"))
                continue

            try:
                # ë‹¨ìˆœ ìƒê´€ ê²€ì •
                if df[cause].dtype in [np.float64, np.int64, float, int] and \
                   df[effect].dtype in [np.float64, np.int64, float, int]:
                    r, p_val = stats.pearsonr(df[cause].dropna(), df[effect].dropna())

                    if p_val < self.significance_level:
                        validated.append({
                            "edge": (cause, effect),
                            "correlation": round(float(r), 4),
                            "p_value": round(float(p_val), 6),
                            "status": "validated",
                        })
                    else:
                        failed.append((cause, effect, f"p={p_val:.4f}"))
                else:
                    validated.append({
                        "edge": (cause, effect),
                        "status": "skipped_non_numeric",
                    })
            except Exception as e:
                failed.append((cause, effect, str(e)))

        return {
            "validated": validated,
            "failed": failed,
            "validation_rate": len(validated) / max(len(hypothesis.edges), 1),
        }

    def _refute(
        self,
        df: pd.DataFrame,
        hypothesis: CausalHypothesis,
        treatment: str,
        outcome: str,
        features: List[str],
    ) -> Dict[str, Any]:
        """ê°€ì„¤ì— ëŒ€í•œ ë°˜ì¦ ì¦ê±°ë¥¼ íƒìƒ‰í•©ë‹ˆë‹¤."""
        from scipy import stats

        rejected_edges = []
        new_candidates = []

        for cause, effect in hypothesis.edges:
            if cause not in df.columns or effect not in df.columns:
                continue

            # ë°˜ì¦ 1: ì—­ë°©í–¥ì´ ë” ê°•í•œê°€?
            try:
                if df[cause].dtype in [np.float64, np.int64, float, int] and \
                   df[effect].dtype in [np.float64, np.int64, float, int]:
                    # ë¶€ë¶„ ìƒê´€ â€” ë‹¤ë¥¸ ë³€ìˆ˜ í†µì œ í›„ì—ë„ ìœ ì§€ë˜ëŠ”ì§€
                    other_vars = [v for v in features if v != cause and v != effect and v in df.columns]
                    if other_vars:
                        # ì”ì°¨ ê¸°ë°˜ ë¶€ë¶„ ìƒê´€
                        from sklearn.linear_model import LinearRegression
                        valid_others = [v for v in other_vars[:5] if df[v].dtype in [np.float64, np.int64, float, int]]
                        if valid_others:
                            mask = df[[cause, effect] + valid_others].dropna().index
                            if len(mask) > 10:
                                X_ctrl = df.loc[mask, valid_others].values
                                res_cause = cause
                                res_effect = effect

                                lr1 = LinearRegression().fit(X_ctrl, df.loc[mask, cause])
                                lr2 = LinearRegression().fit(X_ctrl, df.loc[mask, effect])

                                resid1 = df.loc[mask, cause] - lr1.predict(X_ctrl)
                                resid2 = df.loc[mask, effect] - lr2.predict(X_ctrl)

                                partial_r, partial_p = stats.pearsonr(resid1, resid2)

                                if partial_p > self.significance_level:
                                    rejected_edges.append((cause, effect))
            except Exception:
                pass

        # ë°˜ì¦ 2: ëˆ„ë½ëœ ì—£ì§€ í›„ë³´ íƒìƒ‰
        existing = set(hypothesis.edges)
        numeric_features = [f for f in features if f in df.columns and df[f].dtype in [np.float64, np.int64, float, int]]

        for feat in numeric_features[:10]:
            if outcome in df.columns and df[outcome].dtype in [np.float64, np.int64, float, int]:
                try:
                    r, p = stats.pearsonr(df[feat].dropna(), df[outcome].dropna())
                    if abs(r) > 0.2 and p < 0.01 and (feat, outcome) not in existing:
                        new_candidates.append((feat, outcome))
                except Exception:
                    pass

        return {
            "rejected_edges": rejected_edges,
            "rejected_count": len(rejected_edges),
            "new_candidates": new_candidates,
            "new_candidate_count": len(new_candidates),
        }

    def _check_convergence(
        self,
        state: LoopState,
        hypothesis: CausalHypothesis,
        validation: Dict[str, Any],
        refutation: Dict[str, Any],
    ) -> bool:
        """ìˆ˜ë ´ ì—¬ë¶€ë¥¼ íŒë‹¨í•©ë‹ˆë‹¤."""
        # ê¸°ê°ëœ ì—£ì§€ê°€ ì—†ê³ , ìƒˆ í›„ë³´ë„ ì—†ìœ¼ë©´ ìˆ˜ë ´
        if refutation["rejected_count"] == 0 and refutation["new_candidate_count"] == 0:
            return True

        # ë³€ê²½ ë¹„ìœ¨ì´ ì„ê³„ê°’ ì´í•˜ë©´ ìˆ˜ë ´
        total_edges = max(len(hypothesis.edges), 1)
        change_rate = (refutation["rejected_count"] + refutation["new_candidate_count"]) / total_edges

        return change_rate <= self.convergence_threshold
