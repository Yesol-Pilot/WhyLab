# -*- coding: utf-8 -*-
"""Multi-Agent Debate â€” ì¸ê³¼ íŒê²° ìë™í™”.

3ê°œ ì—ì´ì „íŠ¸(Advocate, Critic, Judge)ê°€ ì¸ê³¼ì¶”ë¡  ê²°ê³¼ë¥¼ ì–‘ì¸¡ì—ì„œ
ê³µê²©/ë°©ì–´í•˜ê³ , ê°€ì¤‘ ìŠ¤ì½”ì–´ë§ìœ¼ë¡œ ìë™ íŒê²°í•©ë‹ˆë‹¤.

ì´ê²ƒì´ WhyLabì˜ í•µì‹¬ ì°¨ë³„ì ì…ë‹ˆë‹¤:
  ê¸°ì¡´: "ì¸ê³¼ì¶”ë¡  â†’ ìˆ«ì â†’ ì¸ê°„ í•´ì„"
  WhyLab: "ì¸ê³¼ì¶”ë¡  â†’ AI ì–‘ì¸¡ ê³µë°© â†’ ìë™ íŒê²° + ê·¼ê±° ë³´ê³ ì„œ"

ì°¸ê³ : Liang et al. (2023) "Encouraging Divergent Thinking in LLMs
through Multi-Agent Debate"
"""

from __future__ import annotations

import logging
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional

import numpy as np

logger = logging.getLogger(__name__)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë°ì´í„° êµ¬ì¡°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@dataclass
class Evidence:
    """êµ¬ì¡°í™”ëœ ì¦ê±° ë‹¨ìœ„.

    Attributes:
        claim: ì£¼ì¥ ë‚´ìš© (ì˜ˆ: "5ê°œ ë©”íƒ€ëŸ¬ë„ˆ ì¤‘ 4ê°œ ë™ì¼ ë°©í–¥")
        evidence_type: ì¦ê±° ìœ í˜• ("statistical" | "robustness" | "domain")
        strength: ì¦ê±° ê°•ë„ (0.0 ~ 1.0)
        source: ì¦ê±° ì¶œì²˜ (ì˜ˆ: "meta_learner_consensus")
        data: ìˆ˜ì¹˜ ê·¼ê±° ë°ì´í„°
        business_impact: ë¹„ì¦ˆë‹ˆìŠ¤ ì˜í–¥ ë¶„ì„ (ì˜ˆ: "Revenue +5%", "Risk High")
    """
    claim: str
    evidence_type: str
    strength: float
    source: str
    data: Dict[str, Any] = field(default_factory=dict)
    business_impact: Optional[str] = None


@dataclass
class Verdict:
    """ìµœì¢… íŒê²° ê²°ê³¼.

    Attributes:
        verdict: "CAUSAL" | "NOT_CAUSAL" | "UNCERTAIN"
        confidence: í™•ì‹ ë„ (0.0 ~ 1.0)
        pro_score: ì˜¹í˜¸ì¸¡ ì´ì 
        con_score: ë¹„íŒì¸¡ ì´ì 
        pro_evidence: ì˜¹í˜¸ ì¦ê±° ë¦¬ìŠ¤íŠ¸
        con_evidence: ë¹„íŒ ì¦ê±° ë¦¬ìŠ¤íŠ¸
        recommendation: ì¶”ê°€ ë¶„ì„ ì œì•ˆ
        rounds: ì‹¤í–‰ëœ Debate ë¼ìš´ë“œ ìˆ˜
    """
    verdict: str
    confidence: float
    pro_score: float
    con_score: float
    pro_evidence: List[Evidence]
    con_evidence: List[Evidence]
    recommendation: str
    rounds: int = 1


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Advocate (ì˜¹í˜¸ ì—ì´ì „íŠ¸)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class AdvocateAgent:
    """ì¸ê³¼ íš¨ê³¼ì˜ ì¡´ì¬ë¥¼ ì˜¹í˜¸í•˜ëŠ” ì—ì´ì „íŠ¸.

    10ê°€ì§€ ì¦ê±°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ì¸ê³¼ ê´€ê³„ì˜ ì¡´ì¬ë¥¼ ì§€ì§€í•©ë‹ˆë‹¤.
    ê° ì¦ê±°ëŠ” íŒŒì´í”„ë¼ì¸ ê²°ê³¼ì—ì„œ ì¶”ì¶œë˜ë©°, ëˆ„ë½ ì‹œ ì•ˆì „í•˜ê²Œ ê±´ë„ˆëœë‹ˆë‹¤.
    """

    def gather_evidence(self, results: Dict[str, Any]) -> List[Evidence]:
        """íŒŒì´í”„ë¼ì¸ ê²°ê³¼ì—ì„œ ê¸ì • ì¦ê±°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
        evidence = []

        # 1. ë©”íƒ€ëŸ¬ë„ˆ í•©ì˜ìœ¨
        evidence.append(self._meta_learner_consensus(results))

        # 2. Bootstrap p-value
        evidence.append(self._bootstrap_significance(results))

        # 3. ATE ìœ ì˜ì„± (0 ë¯¸í¬í•¨)
        evidence.append(self._ate_significance(results))

        # 4. E-value í¬ê¸°
        evidence.append(self._e_value_strength(results))

        # 5. Conformal CI zero-exclusion
        evidence.append(self._conformal_zero_exclusion(results))

        # 6. LOO ì•ˆì •ì„±
        evidence.append(self._loo_stability(results))

        # 7. Subset ì•ˆì •ì„±
        evidence.append(self._subset_stability(results))

        # 8. Overlap ì–‘í˜¸
        evidence.append(self._overlap_quality(results))

        # 9. GATES ì´ì§ˆì„±
        evidence.append(self._gates_heterogeneity(results))

        # 10. SHAP-CATE ì •í•©ì„±
        evidence.append(self._shap_cate_coherence(results))

        # None í•„í„°ë§ ë° ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ ì£¼ì…
        valid = []
        for e in evidence:
            if e is not None:
                e.business_impact = self._generate_impact(e)
                valid.append(e)

        logger.info("ğŸ“— Advocate (Growth Hacker): %dê°œ ì¦ê±° ìˆ˜ì§‘ (ê°•ë„ í•©ê³„: %.2f)",
                     len(valid), sum(e.strength for e in valid))
        return valid

    def _generate_impact(self, e: Evidence) -> str:
        """ì¦ê±°ë¥¼ ë¹„ì¦ˆë‹ˆìŠ¤ ê¸°íšŒë¡œ ë²ˆì—­ (Growth Hacker Persona)."""
        if e.source == "meta_learner_consensus":
            return "ëª¨ë¸ ê°„ í•©ì˜ë¡œ ì˜ˆì¸¡ ì‹ ë¢°ë„ í™•ë³´ â†’ ê³¼ê°í•œ ë§ˆì¼€íŒ… ì§‘í–‰ ê°€ëŠ¥"
        if e.source == "bootstrap_ci" or e.source == "ate_significance":
            return "í†µê³„ì  ìœ ì˜ì„± í™•ë³´ â†’ KPI ê°œì„  ê°€ëŠ¥ì„± ë†’ìŒ"
        if e.source == "gates_heterogeneity":
            return "íƒ€ê²ŸíŒ… íš¨ìœ¨í™” ê¸°íšŒ ë°œê²¬ (ìƒìœ„ 20% ìœ ì € ì§‘ì¤‘ ê³µëµ)"
        return "ì•ˆì •ì ì¸ ì„±ê³¼ ê¸°ëŒ€"

    def _meta_learner_consensus(self, r: Dict) -> Optional[Evidence]:
        """ë©”íƒ€ëŸ¬ë„ˆ í•©ì˜ìœ¨."""
        meta = r.get("meta_learner_results", {})
        ensemble = meta.get("ensemble", {})
        consensus = ensemble.get("consensus", 0)
        if consensus == 0:
            return None
        return Evidence(
            claim=f"ë©”íƒ€ëŸ¬ë„ˆ {consensus*100:.0f}% ë™ì¼ ë°©í–¥",
            evidence_type="statistical",
            strength=consensus,
            source="meta_learner_consensus",
            data={"consensus": consensus},
        )

    def _bootstrap_significance(self, r: Dict) -> Optional[Evidence]:
        """Bootstrap ë°˜ì¦ í†µê³¼."""
        refutation = r.get("refutation_results", {})
        placebo = refutation.get("placebo_test", {})
        p_value = placebo.get("p_value")
        if p_value is None:
            return None
        strength = max(0, 1 - p_value)
        return Evidence(
            claim=f"Placebo p={p_value:.4f} (ì›ë˜ íš¨ê³¼ ìœ ì˜)",
            evidence_type="robustness",
            strength=strength,
            source="placebo_p_value",
            data={"p_value": p_value},
        )

    def _ate_significance(self, r: Dict) -> Optional[Evidence]:
        """ATE Bootstrap CIê°€ 0ì„ í¬í•¨í•˜ì§€ ì•ŠëŠ”ì§€."""
        refutation = r.get("refutation_results", {})
        bootstrap = refutation.get("bootstrap_ci", {})
        ci_lower = bootstrap.get("ci_lower")
        ci_upper = bootstrap.get("ci_upper")
        if ci_lower is None or ci_upper is None:
            return None
        excludes_zero = (ci_lower > 0) or (ci_upper < 0)
        return Evidence(
            claim=f"Bootstrap CI [{ci_lower:.4f}, {ci_upper:.4f}] {'0 ë¯¸í¬í•¨ âœ“' if excludes_zero else '0 í¬í•¨'}",
            evidence_type="statistical",
            strength=1.0 if excludes_zero else 0.2,
            source="bootstrap_ci",
            data={"ci_lower": ci_lower, "ci_upper": ci_upper},
        )

    def _e_value_strength(self, r: Dict) -> Optional[Evidence]:
        """E-value í¬ê¸°."""
        sensitivity = r.get("sensitivity_results", {})
        e_val_raw = sensitivity.get("e_value")
        if e_val_raw is None:
            return None
        # e_valueëŠ” dict (point, ci_bound) ë˜ëŠ” float
        e_value = e_val_raw.get("point", 0) if isinstance(e_val_raw, dict) else float(e_val_raw)
        if e_value == 0:
            return None
        strength = min(e_value / 3.0, 1.0)
        return Evidence(
            claim=f"E-value={e_value:.2f} ({'ê°•ê±´' if e_value >= 2 else 'ì·¨ì•½'})",
            evidence_type="robustness",
            strength=strength,
            source="e_value",
            data={"e_value": e_value},
        )

    def _conformal_zero_exclusion(self, r: Dict) -> Optional[Evidence]:
        """Conformal CIê°€ 0ì„ í¬í•¨í•˜ì§€ ì•ŠëŠ”ì§€."""
        conformal = r.get("conformal_results", {})
        ci_lower = conformal.get("ci_lower_mean")
        ci_upper = conformal.get("ci_upper_mean")
        if ci_lower is None or ci_upper is None:
            return None
        excludes = (ci_lower > 0) or (ci_upper < 0)
        return Evidence(
            claim=f"Conformal CI {'0 ë¯¸í¬í•¨ â†’ ìœ ì˜' if excludes else '0 í¬í•¨ â†’ ë¶ˆí™•ì‹¤'}",
            evidence_type="statistical",
            strength=1.0 if excludes else 0.1,
            source="conformal_ci",
            data={"ci_lower_mean": ci_lower, "ci_upper_mean": ci_upper},
        )

    def _loo_stability(self, r: Dict) -> Optional[Evidence]:
        """Leave-One-Out ì•ˆì •ì„±."""
        refutation = r.get("refutation_results", {})
        loo = refutation.get("leave_one_out", {})
        sign_flip = loo.get("any_sign_flip")
        if sign_flip is None:
            return None
        return Evidence(
            claim=f"LOO êµë€ë³€ìˆ˜ ì œê±° í›„ {'ë¶€í˜¸ ìœ ì§€ âœ“' if not sign_flip else 'ë¶€í˜¸ ë°˜ì „ âœ—'}",
            evidence_type="robustness",
            strength=1.0 if not sign_flip else 0.0,
            source="loo_confounder",
            data={"any_sign_flip": sign_flip},
        )

    def _subset_stability(self, r: Dict) -> Optional[Evidence]:
        """Subset ì•ˆì •ì„±."""
        refutation = r.get("refutation_results", {})
        subset = refutation.get("subset_validation", {})
        stability = subset.get("avg_stability")
        if stability is None:
            return None
        return Evidence(
            claim=f"ì„œë¸Œì…‹ ì•ˆì •ì„±: {stability:.2f}",
            evidence_type="robustness",
            strength=stability,
            source="subset_stability",
            data={"avg_stability": stability},
        )

    def _overlap_quality(self, r: Dict) -> Optional[Evidence]:
        """Overlap ì–‘í˜¸."""
        sensitivity = r.get("sensitivity_results", {})
        overlap_raw = sensitivity.get("overlap")
        if overlap_raw is None:
            return None
        # overlapì€ dict (overlap_score, status) ë˜ëŠ” float
        overlap = overlap_raw.get("overlap_score", 0) if isinstance(overlap_raw, dict) else float(overlap_raw)
        strength = min(overlap / 0.9, 1.0) if overlap > 0.5 else 0.0
        return Evidence(
            claim=f"Overlap={overlap:.2f} ({'ì–‘í˜¸' if overlap > 0.7 else 'ì£¼ì˜'})",
            evidence_type="statistical",
            strength=strength,
            source="overlap",
            data={"overlap": overlap},
        )

    def _gates_heterogeneity(self, r: Dict) -> Optional[Evidence]:
        """GATES F-statistic ìœ ì˜."""
        sensitivity = r.get("sensitivity_results", {})
        # gatesëŠ” í‚¤ê°€ 'gates' ë˜ëŠ” 'gates_results'ì¼ ìˆ˜ ìˆìŒ
        gates = sensitivity.get("gates_results") or sensitivity.get("gates", {})
        if isinstance(gates, dict):
            f_sig = gates.get("f_stat_significant")
            # f_statisticì´ ìˆìœ¼ë©´ ìœ ì˜ì„± íŒë‹¨
            if f_sig is None and "f_statistic" in gates:
                f_sig = gates["f_statistic"] > 3.84  # F(1,n-2) 5% ì„ê³„ê°’
        else:
            f_sig = None
        if f_sig is None:
            return None
        return Evidence(
            claim=f"GATES ì´ì§ˆì„± {'ìœ ì˜ âœ“' if f_sig else 'ë¹„ìœ ì˜'}",
            evidence_type="statistical",
            strength=1.0 if f_sig else 0.3,
            source="gates_heterogeneity",
            data={"f_stat_significant": f_sig},
        )

    def _shap_cate_coherence(self, r: Dict) -> Optional[Evidence]:
        """SHAP ì¤‘ìš”ë„ì™€ CATE ë³€ìˆ˜ ì •í•©ì„±."""
        importance = r.get("feature_importance", {})
        feature_names = r.get("feature_names", [])
        if not importance or not feature_names:
            return None
        # ìƒìœ„ 3ê°œ SHAP ë³€ìˆ˜ê°€ ì‹¤ì œ êµë€ë³€ìˆ˜ì— í¬í•¨ë˜ëŠ”ì§€
        top_shap = sorted(importance, key=importance.get, reverse=True)[:3]
        overlap = len(set(top_shap) & set(feature_names)) / max(len(top_shap), 1)
        return Evidence(
            claim=f"SHAP-êµë€ë³€ìˆ˜ ì •í•©ì„±: {overlap*100:.0f}%",
            evidence_type="domain",
            strength=overlap,
            source="shap_coherence",
            data={"top_shap": top_shap, "overlap_ratio": overlap},
        )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Critic (ë¹„íŒ ì—ì´ì „íŠ¸)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class CriticAgent:
    """ì¸ê³¼ íš¨ê³¼ë¥¼ ê³µê²©í•˜ëŠ” ì—ì´ì „íŠ¸.

    8ê°€ì§€ ê³µê²© ë²¡í„°ë¥¼ í™œìš©í•˜ì—¬ ì¸ê³¼ íŒë‹¨ì˜ ì•½ì ì„ ì§€ì í•©ë‹ˆë‹¤.
    """

    def challenge(self, results: Dict[str, Any]) -> List[Evidence]:
        """íŒŒì´í”„ë¼ì¸ ê²°ê³¼ì—ì„œ ë°˜ë¡  ì¦ê±°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
        attacks = []

        attacks.append(self._e_value_weak(results))
        attacks.append(self._overlap_violation(results))
        attacks.append(self._ci_too_wide(results))
        attacks.append(self._placebo_failure(results))
        attacks.append(self._loo_sign_flip(results))
        attacks.append(self._meta_disagreement(results))
        attacks.append(self._subset_instability(results))
        attacks.append(self._small_sample(results))

        # None í•„í„°ë§ ë° ë¹„ì¦ˆë‹ˆìŠ¤ ë¦¬ìŠ¤í¬ ì£¼ì…
        valid = []
        for a in attacks:
            if a is not None:
                a.business_impact = self._generate_risk(a)
                valid.append(a)

        logger.info("ğŸ“• Critic (Risk Manager): %dê°œ ê³µê²© ìˆ˜ì§‘ (ê°•ë„ í•©ê³„: %.2f)",
                     len(valid), sum(e.strength for e in valid))
        return valid

    def _generate_risk(self, e: Evidence) -> str:
        """ì¦ê±°ë¥¼ ë¹„ì¦ˆë‹ˆìŠ¤ ë¦¬ìŠ¤í¬ë¡œ ë²ˆì—­ (Risk Manager Persona)."""
        if e.source == "e_value_weak":
            return "ë¯¸ê´€ì¸¡ ì™¸ë¶€ ë³€ìˆ˜(ê²½ê¸° ì¹¨ì²´ ë“±)ì— ì·¨ì•½ â†’ ì˜ˆìƒì¹˜ ëª»í•œ ì†ì‹¤ ìœ„í—˜"
        if e.source == "overlap_violation":
            return "íŠ¹ì • ìœ ì €êµ°ì— í¸í–¥ëœ ê²°ê³¼ â†’ ì¼ë°˜í™” ì‹œ ì„±ê³¼ í•˜ë½ ìš°ë ¤"
        if e.source == "placebo_failure":
            return "ê°€ì§œ íš¨ê³¼ì¼ ê°€ëŠ¥ì„± ë†’ìŒ â†’ ë§ˆì¼€íŒ… ì˜ˆì‚° ë‚­ë¹„ ê²½ê³ "
        if e.source == "ci_too_wide":
            return "ì„±ê³¼ ë³€ë™í­ì´ ë„ˆë¬´ í¼ â†’ KPI ë‹¬ì„± ë¶ˆí™•ì‹¤ì„± ì¦ëŒ€"
        return "ìš´ì˜ ë¦¬ìŠ¤í¬ ì¡´ì¬"

    def _e_value_weak(self, r: Dict) -> Optional[Evidence]:
        """E-value ì·¨ì•½."""
        e_val_raw = r.get("sensitivity_results", {}).get("e_value")
        if e_val_raw is None:
            return None
        e_value = e_val_raw.get("point", 0) if isinstance(e_val_raw, dict) else float(e_val_raw)
        if e_value >= 2.0:
            return None
        strength = (2.0 - e_value) / 2.0
        return Evidence(
            claim=f"E-value={e_value:.2f} < 2.0 â†’ ë¯¸ê´€ì¸¡ êµë€ì— ì·¨ì•½",
            evidence_type="robustness",
            strength=strength,
            source="e_value_weak",
            data={"e_value": e_value},
        )

    def _overlap_violation(self, r: Dict) -> Optional[Evidence]:
        """Overlap ìœ„ë°˜."""
        overlap_raw = r.get("sensitivity_results", {}).get("overlap")
        if overlap_raw is None:
            return None
        overlap = overlap_raw.get("overlap_score", 0) if isinstance(overlap_raw, dict) else float(overlap_raw)
        if overlap >= 0.7:
            return None
        strength = (0.7 - overlap) / 0.7
        return Evidence(
            claim=f"Overlap={overlap:.2f} < 0.7 â†’ positivity ìœ„ë°˜ ìœ„í—˜",
            evidence_type="statistical",
            strength=strength,
            source="overlap_violation",
            data={"overlap": overlap},
        )

    def _ci_too_wide(self, r: Dict) -> Optional[Evidence]:
        """CI ê³¼ëŒ€."""
        refutation = r.get("refutation_results", {})
        bootstrap = refutation.get("bootstrap_ci", {})
        ci_lower = bootstrap.get("ci_lower")
        ci_upper = bootstrap.get("ci_upper")
        # ateëŠ” float ë˜ëŠ” dictì¼ ìˆ˜ ìˆìŒ (ExportCell ì „/í›„)
        ate_raw = r.get("ate")
        if isinstance(ate_raw, dict):
            ate = ate_raw.get("value", 0)
        elif isinstance(ate_raw, (int, float)):
            ate = float(ate_raw)
        else:
            ate = None
        if ci_lower is None or ci_upper is None or ate is None or ate == 0:
            return None
        width = abs(ci_upper - ci_lower)
        ratio = width / abs(ate)
        if ratio <= 2.0:
            return None
        strength = min(ratio / 5.0, 1.0)  # 5ë°° ì´ìƒì´ë©´ ìµœëŒ€
        return Evidence(
            claim=f"CI í­={width:.4f} (ATEì˜ {ratio:.1f}ë°°) â†’ ì¶”ì • ë¶ˆì•ˆì •",
            evidence_type="statistical",
            strength=strength,
            source="ci_too_wide",
            data={"width": width, "ratio": ratio},
        )

    def _placebo_failure(self, r: Dict) -> Optional[Evidence]:
        """Placebo ì‹¤íŒ¨."""
        p_value = r.get("refutation_results", {}).get("placebo_test", {}).get("p_value")
        if p_value is None or p_value >= 0.05:
            return None
        return Evidence(
            claim=f"Placebo p={p_value:.4f} < 0.05 â†’ í—ˆìœ„ ì–‘ì„± ìœ„í—˜",
            evidence_type="robustness",
            strength=1.0 - p_value,
            source="placebo_failure",
            data={"p_value": p_value},
        )

    def _loo_sign_flip(self, r: Dict) -> Optional[Evidence]:
        """LOO ë¶€í˜¸ ë°˜ì „."""
        loo = r.get("refutation_results", {}).get("leave_one_out", {})
        details = loo.get("details", [])
        if not details:
            return None
        flips = [d for d in details if d.get("sign_flip", False)]
        if not flips:
            return None
        flip_ratio = len(flips) / len(details)
        return Evidence(
            claim=f"êµë€ë³€ìˆ˜ {len(flips)}ê°œ ì œê±° ì‹œ ATE ë¶€í˜¸ ë°˜ì „ ({flip_ratio*100:.0f}%)",
            evidence_type="robustness",
            strength=flip_ratio,
            source="loo_sign_flip",
            data={"flip_count": len(flips), "flip_ratio": flip_ratio},
        )

    def _meta_disagreement(self, r: Dict) -> Optional[Evidence]:
        """ë©”íƒ€ëŸ¬ë„ˆ ë¶ˆì¼ì¹˜."""
        consensus = r.get("meta_learner_results", {}).get("ensemble", {}).get("consensus", 1)
        if consensus >= 0.6:
            return None
        strength = 1.0 - consensus
        return Evidence(
            claim=f"ë©”íƒ€ëŸ¬ë„ˆ í•©ì˜ìœ¨ {consensus*100:.0f}% < 60% â†’ ì¶”ì • ë°©í–¥ ë¶ˆí™•ì‹¤",
            evidence_type="statistical",
            strength=strength,
            source="meta_disagreement",
            data={"consensus": consensus},
        )

    def _subset_instability(self, r: Dict) -> Optional[Evidence]:
        """Subset ë¶ˆì•ˆì •."""
        stability = r.get("refutation_results", {}).get("subset_validation", {}).get("avg_stability")
        if stability is None or stability >= 0.85:
            return None
        strength = 1.0 - stability
        return Evidence(
            claim=f"ì„œë¸Œì…‹ ì•ˆì •ì„±={stability:.2f} < 0.85 â†’ í‘œë³¸ ì˜ì¡´ì ",
            evidence_type="robustness",
            strength=strength,
            source="subset_instability",
            data={"avg_stability": stability},
        )

    def _small_sample(self, r: Dict) -> Optional[Evidence]:
        """í‘œë³¸ í¬ê¸° ë¶€ì¡±."""
        df = r.get("dataframe")
        if df is None:
            return None
        n = len(df)
        if n >= 500:
            return None
        strength = max(0, 1 - n / 500)
        return Evidence(
            claim=f"n={n} < 500 â†’ ì†Œí‘œë³¸ ë¶ˆì•ˆì •",
            evidence_type="statistical",
            strength=strength,
            source="small_sample",
            data={"n": n},
        )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Judge (íŒê²° ì—ì´ì „íŠ¸)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class JudgeAgent:
    """ì–‘ì¸¡ ì¦ê±°ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… íŒê²°.

    ì¦ê±° ìœ í˜•ë³„ ê°€ì¤‘ì¹˜:
      - statistical: 1.0 (í†µê³„ì  ì¦ê±° ê¸°ë³¸)
      - robustness: 1.2 (ê²¬ê³ ì„± ì¦ê±° ê°€ì¤‘)
      - domain: 0.8 (ë„ë©”ì¸ ì§€ì‹ í• ì¸)
    """

    DEFAULT_WEIGHTS = {
        "statistical": 1.0,
        "robustness": 1.2,
        "domain": 0.8,
    }

    def __init__(self, weights: Optional[Dict[str, float]] = None):
        self.weights = weights or self.DEFAULT_WEIGHTS

    def deliberate(
        self,
        pro: List[Evidence],
        con: List[Evidence],
        threshold: float = 0.7,
    ) -> Verdict:
        """ì–‘ì¸¡ ì¦ê±°ë¥¼ ê°€ì¤‘ í•©ì‚°í•˜ì—¬ íŒê²°í•©ë‹ˆë‹¤.

        Args:
            pro: ì˜¹í˜¸ ì¦ê±° ë¦¬ìŠ¤íŠ¸.
            con: ë¹„íŒ ì¦ê±° ë¦¬ìŠ¤íŠ¸.
            threshold: CAUSAL íŒê²° ìµœì†Œ í™•ì‹ ë„.

        Returns:
            Verdict ë°ì´í„°í´ë˜ìŠ¤.
        """
        pro_score = sum(
            e.strength * self.weights.get(e.evidence_type, 1.0)
            for e in pro
        )
        con_score = sum(
            e.strength * self.weights.get(e.evidence_type, 1.0)
            for e in con
        )

        total = pro_score + con_score + 1e-10
        confidence = pro_score / total

        verdict_str = "UNCERTAIN"
        if confidence >= threshold:
            verdict_str = "CAUSAL"
        elif confidence <= (1.0 - threshold):
            verdict_str = "NOT_CAUSAL"

        recommendation = self._generate_recommendation(verdict_str, pro, con, confidence)

        logger.info(
            "âš–ï¸ Judge (Product Owner): %s (í™•ì‹ ë„=%.2f) â†’ %s",
            verdict_str, confidence, recommendation,
        )

        return Verdict(
            verdict=verdict_str,
            confidence=confidence,
            pro_score=pro_score,
            con_score=con_score,
            pro_evidence=pro,
            con_evidence=con,
            recommendation=recommendation,
        )

    def _generate_recommendation(
        self,
        verdict: str,
        pro: List[Evidence],
        con: List[Evidence],
        confidence: float,
    ) -> str:
        """ë¹„ì¦ˆë‹ˆìŠ¤ ì•¡ì…˜ ì•„ì´í…œ ë„ì¶œ (Product Owner Persona)."""
        if verdict == "CAUSAL":
            # Growth ì‹ í˜¸ ê°•í•¨
            impacts = [e.business_impact for e in pro if e.business_impact]
            main_impact = impacts[0] if impacts else "ì„±ê³¼ ê°œì„  ê¸°ëŒ€"
            
            if confidence > 0.9:
                return f"ğŸš€ [ìŠ¹ì¸] ì „ë©´ ë°°í¬ (Rollout 100%). {main_impact}."
            return f"ğŸ“ˆ [ì¡°ê±´ë¶€ ìŠ¹ì¸] ë‹¨ê³„ì  ë°°í¬ (Rollout 20% â†’ 50%). {main_impact}."

        elif verdict == "NOT_CAUSAL":
            # Risk ì‹ í˜¸ ê°•í•¨
            risks = [e.business_impact for e in con if e.business_impact]
            main_risk = risks[0] if risks else "íš¨ê³¼ ë¯¸ë¯¸"
            
            return f"ğŸ›‘ [ê¸°ê°] ë°°í¬ ì¤‘ë‹¨. ë¦¬ì†ŒìŠ¤ íšŒìˆ˜ ê¶Œì¥. ì‚¬ìœ : {main_risk}"

        else:  # UNCERTAIN
            # Trade-off ìƒí™©
            risks = [e.business_impact for e in con if e.business_impact]
            return f"âš–ï¸ [ë³´ë¥˜] 5% íŠ¸ë˜í”½ A/B í…ŒìŠ¤íŠ¸ ì œì•ˆ. ì£¼ìš” ë¦¬ìŠ¤í¬ ê²€ì¦ í•„ìš”: {risks[0] if risks else 'ë¶ˆí™•ì‹¤ì„± í•´ì†Œ í•„ìš”'}"
