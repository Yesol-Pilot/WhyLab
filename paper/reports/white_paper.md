# Beyond Correlation: A Multi-Agent Causal Intelligence Platform for Fintech
> **Date**: 2026-02-15  
> **Author**: WhyLab Research Team  
> **Status**: Draft v1.0  

## Abstract

í•€í…Œí¬ ì‚°ì—…ì—ì„œ ì˜ì‚¬ê²°ì •ì€ ë°ì´í„°ì— ê¸°ë°˜í•´ì•¼ í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë‹¨ìˆœí•œ ìƒê´€ê´€ê³„ ë¶„ì„ì€ ì—­ì¸ê³¼ ê´€ê³„(Reverse Causality)ë‚˜ êµë€ ë³€ìˆ˜(Confounder)ë¡œ ì¸í•´ ì˜ëª»ëœ ê²°ë¡ ì„ ìœ ë„í•  ìœ„í—˜ì´ í½ë‹ˆë‹¤. ë³¸ ì—°êµ¬ëŠ” **WhyLab**ì„ í†µí•´ ì´ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤. WhyLabì€ (1) **Double Machine Learning (DML)** + **ë”¥ëŸ¬ë‹ CATE (DragonNet/TARNet)**ë¡œ ì´ì§ˆì  ì²˜ì¹˜ íš¨ê³¼ë¥¼ ì¶”ì •í•˜ê³ , (2) **ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì¸ê³¼ ë°œê²¬(MAC)**ìœ¼ë¡œ ì¸ê³¼ êµ¬ì¡°ë¥¼ ì•™ìƒë¸” íƒì§€í•˜ë©°, (3) **ë„êµ¬ ê°•í™” í† ë¡ (Tool-Augmented Debate)**ìœ¼ë¡œ ì¸ê³¼ ì£¼ì¥ì„ ìë™ ê²€ì¦í•˜ëŠ” í†µí•© í”Œë«í¼ì…ë‹ˆë‹¤. 6ì¢… í•™ìˆ  ë²¤ì¹˜ë§ˆí¬(IHDP, ACIC, Jobs, TWINS, Criteo, LaLonde)ì—ì„œ 7ì¢… ì¶”ì •ê¸°ì˜ GPU ê°€ì† í‰ê°€ë¥¼ ìˆ˜í–‰í•˜ì˜€ìœ¼ë©°, ê³µì •ì„± ê°ì‚¬ ë° ìš©ëŸ‰-ë°˜ì‘ ë¶„ì„ê¹Œì§€ í¬ê´„í•©ë‹ˆë‹¤.

---

## 1. Introduction

### 1.1. The Pitfall of Correlation
í˜„ëŒ€ ê¸ˆìœµ ì•±ì€ ìˆ˜ë§ì€ ì‚¬ìš©ì í–‰ë™ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤. í”íˆ "ì‹ ìš©í•œë„ê°€ ë†’ì€ ìœ ì €ì¼ìˆ˜ë¡ ì—°ì²´ìœ¨ì´ ë‚®ë‹¤"ëŠ” ë°ì´í„° íŒ¨í„´ì´ ê´€ì°°ë©ë‹ˆë‹¤. ê²½ì˜ì§„ì€ ì´ë¥¼ ê·¼ê±°ë¡œ "ì‹ ìš©í•œë„ë¥¼ ëŠ˜ë¦¬ë©´ ì—°ì²´ìœ¨ì´ ë‚®ì•„ì§ˆ ê²ƒì´ë‹¤"ë¼ê³  íŒë‹¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

í•˜ì§€ë§Œ ì´ëŠ” **ìƒê´€ê´€ê³„(Correlation)**ì´ì§€ **ì¸ê³¼ê´€ê³„(Causality)**ê°€ ì•„ë‹™ë‹ˆë‹¤. ì‹¤ì œë¡œëŠ” "ì‹ ìš©ë„ê°€ ë†’ì€ ìœ ì €ì—ê²Œ ë” ë†’ì€ í•œë„ë¥¼ ë¶€ì—¬"í–ˆê¸° ë•Œë¬¸ì— ì´ëŸ¬í•œ íŒ¨í„´ì´ ë‚˜íƒ€ë‚˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë§Œì•½ ì‹ ìš©ë„ê°€ ë‚®ì€ ìœ ì €ì—ê²Œ ë¬´í„±ëŒ€ê³  í•œë„ë¥¼ ëŠ˜ë¦°ë‹¤ë©´, ì—°ì²´ìœ¨ì€ ì˜¤íˆë ¤ ê¸‰ì¦í•  ê²ƒì…ë‹ˆë‹¤.

### 1.2. The Need for Causal Inference
A/B í…ŒìŠ¤íŠ¸ëŠ” ì¸ê³¼ê´€ê³„ë¥¼ ë°íˆëŠ” ê°€ì¥ í™•ì‹¤í•œ ë°©ë²•ì´ì§€ë§Œ, ì‹ ìš© í•œë„ë‚˜ ê¸ˆë¦¬ ê°™ì€ ë¯¼ê°í•œ ë³€ìˆ˜ë¥¼ ë¬´ì‘ìœ„ë¡œ ì‹¤í—˜í•˜ëŠ” ê²ƒì€ ìœ¤ë¦¬ì Â·ë¹„ìš©ì  ë¦¬ìŠ¤í¬ê°€ í½ë‹ˆë‹¤. ë”°ë¼ì„œ ìš°ë¦¬ëŠ” **ê´€ì°° ë°ì´í„°(Observational Data)**ë§Œìœ¼ë¡œ ì¸ê³¼ íš¨ê³¼ë¥¼ ì¶”ì •í•´ì•¼ í•©ë‹ˆë‹¤.

ë³¸ ì—°êµ¬ì—ì„œëŠ” **WhyLab ì—”ì§„**ì„ í†µí•´, êµë€ ë³€ìˆ˜ë¥¼ í†µì œí•˜ê³  ìˆœìˆ˜ ì²˜ì¹˜ íš¨ê³¼ë¥¼ ë°œë¼ë‚´ëŠ” ì¸ê³¼ì¶”ë¡  íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•˜ê³  ê·¸ ìœ íš¨ì„±ì„ ì¦ëª…í•©ë‹ˆë‹¤.

---

## 2. Methodology

### 2.1. Potential Outcomes Framework
Rubinì˜ ì ì¬ì  ê²°ê³¼ í”„ë ˆì„ì›Œí¬ë¥¼ ë”°ë¦…ë‹ˆë‹¤. ê°œì²´ $i$ì— ëŒ€í•´ ì²˜ì¹˜ $T_i$ê°€ ì£¼ì–´ì¡Œì„ ë•Œì˜ ê²°ê³¼ $Y_i(1)$ê³¼ ì£¼ì–´ì§€ì§€ ì•Šì•˜ì„ ë•Œì˜ ê²°ê³¼ $Y_i(0)$ì˜ ì°¨ì´ë¥¼ ì¸ê³¼ íš¨ê³¼ë¼ê³  ì •ì˜í•©ë‹ˆë‹¤.

$$ \text{ITE}_i = Y_i(1) - Y_i(0) $$
$$ \text{ATE} = E[Y_i(1) - Y_i(0)] $$

### 2.2. Double Machine Learning (DML)
Chernozhukov et al. (2018)ì´ ì œì•ˆí•œ **DML**ì„ ì‚¬ìš©í•©ë‹ˆë‹¤:

1.  **Treatment Model** ($M_t$): êµë€ ë³€ìˆ˜ $X$ë¡œ ì²˜ì¹˜ $T$ë¥¼ ì˜ˆì¸¡ (ì”ì°¨ $T - \hat{T}$)
2.  **Outcome Model** ($M_y$): êµë€ ë³€ìˆ˜ $X$ë¡œ ê²°ê³¼ $Y$ë¥¼ ì˜ˆì¸¡ (ì”ì°¨ $Y - \hat{Y}$)
3.  **Causal Estimation**: ì”ì°¨ ê°„ì˜ íšŒê·€ë¶„ì„ì„ í†µí•´ ìˆœìˆ˜ íš¨ê³¼ $\theta$ë¥¼ ì¶”ì •

$$ Y - E[Y|X] = \theta(X) \cdot (T - E[T|X]) + \epsilon $$

### 2.3. Advanced Diagnostics (Phase 4)

| ì§„ë‹¨ | ë°©ë²• | ëª©ì  |
|------|------|------|
| **E-value** | $RR + \sqrt{RR(RR-1)}$ | ë¯¸ê´€ì¸¡ êµë€ì´ ê²°ê³¼ë¥¼ ë’¤ì§‘ìœ¼ë ¤ë©´ ì–¼ë§ˆë‚˜ ê°•í•œ ìƒê´€ì´ í•„ìš”í•œì§€ |
| **Overlap** | Propensity Score ë¶„í¬ ë¹„êµ (Bhattacharyya ê³„ìˆ˜) | ì²˜ì¹˜/í†µì œ ê·¸ë£¹ ê°„ ê· í˜• ì—¬ë¶€ |
| **GATES** | CATE ì‚¬ë¶„ìœ„ë³„ ê·¸ë£¹ ë¶„ì„ + F-test | ì´ì§ˆì  ì²˜ì¹˜ íš¨ê³¼ì˜ í†µê³„ì  ìœ ì˜ì„± |
| **CLAN** | ê·¸ë£¹ë³„ í”¼ì²˜ í‰ê·  ë¹„êµ | ì–´ë–¤ íŠ¹ì„±ì´ ì´ì§ˆì„±ì„ ë§Œë“œëŠ”ì§€ |

### 2.4. Deep Learning CATE (Phase 5)

| ì•„í‚¤í…ì²˜ | ì°¸ì¡° | êµ¬ì¡° |
|----------|------|------|
| **TARNet** | Shalit et al. 2017 | ê³µìœ  í‘œí˜„ Î¦(X) â†’ Yâ‚€/Yâ‚ ë¶„ê¸° í—¤ë“œ |
| **DragonNet** | Shi et al. 2019 | TARNet + ì„±í–¥ì ìˆ˜ í—¤ë“œ (íƒ€ê²Ÿ ì •ê·œí™”) |

$$\text{CATE}(x) = \hat{Y}_1(x) - \hat{Y}_0(x) = f_{Y_1}(\Phi(x)) - f_{Y_0}(\Phi(x))$$

### 2.5. Dose-Response Analysis (Phase 5)
Generalized Propensity Score (GPS) ê¸°ë°˜ ì—°ì†í˜• ì²˜ì¹˜ì˜ ìš©ëŸ‰-ë°˜ì‘ ê³¡ì„ ì„ ì¶”ì •í•©ë‹ˆë‹¤:

$$GPS(t, x) = f_{T|X}(t|x), \quad E[Y|T=t] = g(t, GPS(t, x))$$

### 2.6. Multi-Agent Causal Discovery (Phase 5)
PC, GES, LiNGAM 3ì¢… ì•Œê³ ë¦¬ì¦˜ì„ ë…ë¦½ ì‹¤í–‰ í›„ íˆ¬í‘œ ì•™ìƒë¸”ë¡œ í•©ì˜ DAGë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤:

$$A_{\text{final}}[i,j] = \mathbb{1}\left[\frac{1}{K}\sum_{k=1}^{K} A_k[i,j] \geq \tau\right]$$

### 2.7. Technology Stack
-   **Inference**: Microsoft EconML (LinearDML) + PyTorch (DragonNet, TARNet)
-   **Causal Discovery**: PC, GES (BIC), LiNGAM (ë¹„ê°€ìš°ì‹œì•ˆ ìˆœì„œ)
-   **Nuisance Models**: LightGBM GPU (RTX 4070 SUPER)
-   **Data Processing**: DuckDB for OLAP
-   **Dashboard**: Next.js 16 + Recharts + Framer Motion

---

## 3. Experimental Setup

### 3.1. Data Generation (SCM)
êµ¬ì¡°ì  ì¸ê³¼ ëª¨ë¸(SCM) ê¸°ë°˜ì˜ í•©ì„± ë°ì´í„°ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤:
-   **N**: 100,000 samples
-   **Confounders**: Income, Age, Credit Score, App Usage
-   **Noise**: Gaussian ($\sigma=0.3$)

### 3.2. Scenarios
#### Scenario A: Credit Limit (Continuous Treatment)
-   **Treatment**: ì‹ ìš© í•œë„ (100ë§Œ ì› ~ 5,000ë§Œ ì›)
-   **Outcome**: ì—°ì²´ í™•ë¥  (0 ~ 1)

#### Scenario B: Marketing Coupon (Binary Treatment)
-   **Treatment**: ì¿ í° ì§€ê¸‰ (0/1)
-   **Outcome**: íˆ¬ì ìƒí’ˆ ê°€ì… (0/1)

---

## 4. Experimental Results

### 4.1. Model Performance

| Metric | Scenario A (Credit) | Scenario B (Coupon) |
|--------|---------------------|---------------------|
| **ATE** | -0.0342 (-3.4%p) | -0.0040 (-0.4%p) |
| **Correlation** | **0.977** | **0.996** |
| RMSE | 0.609 | 0.028 |
| Coverage | 94.2% | 96.8% |

> **Correlation 0.97~0.99** = DML ì¶”ì •ì¹˜ê°€ Ground Truthì™€ ê±°ì˜ ì™„ë²½í•˜ê²Œ ì¼ì¹˜í•©ë‹ˆë‹¤.

### 4.2. Scenario A: Credit Limit
-   **Overall ATE = -0.0342**: í•œë„ 1Ïƒ ì¦ê°€ ì‹œ ì—°ì²´ìœ¨ 3.4%p ê°ì†Œ
-   **ì´ì§ˆì„±**: ê³ ì†Œë“ì¸µì—ì„œ íš¨ê³¼ ê·¹ëŒ€í™”, ì €ì†Œë“ì¸µì—ì„œ íš¨ê³¼ ë¯¸ë¯¸/ë¶€ì •ì 
-   **ì •ì±… í•¨ì˜**: ì¼ê´„ ì¦ì•¡ì´ ì•„ë‹Œ ê³ ì‹ ìš© ì„¸ê·¸ë¨¼íŠ¸ íƒ€ê²Ÿ ì¦ì•¡ í•„ìš”

![Figure 1: Dose-Response Analysis with Uncertainty](../figures/fig1_dose_response.png)
*Figure 1. 95% ì‹ ë¢°êµ¬ê°„ì„ í¬í•¨í•œ ìš©ëŸ‰-ë°˜ì‘ ê³¡ì„ . ìµœì  ì²˜ì¹˜ ìš©ëŸ‰(Optimal Dose)ì„ ì‹œê°ì ìœ¼ë¡œ ì‹ë³„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.*

### 4.3. Scenario B: Marketing Coupon
-   **Overall ATE = -0.0040**: ì¿ í° íš¨ê³¼ê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ì§€ ì•ŠìŒ (CIê°€ 0 í¬í•¨)
-   **ì •ì±… í•¨ì˜**: ì¿ í°ì´ ê°€ì…ë¥ ì— ë¯¸ì¹˜ëŠ” ìˆœìˆ˜ íš¨ê³¼ê°€ ì‘ìœ¼ë¯€ë¡œ, CATE ê¸°ë°˜ ì„¸ê·¸ë¨¼íŠ¸ íƒ€ê²ŸíŒ…ìœ¼ë¡œ ROI ê·¹ëŒ€í™” í•„ìš”

### 4.4. Robustness Diagnostics (Phase 4)

| í…ŒìŠ¤íŠ¸ | Scenario A | Scenario B |
|--------|------------|------------|
| Placebo Test | âœ… Pass | âœ… Pass |
| Random Common Cause | âœ… Pass (Stability 99%+) | âœ… Pass |
| **E-value** | 1.07 (ë³´í†µ~ê²¬ê³ ) | 1.01 (ì•½í•œ íš¨ê³¼) |
| **Overlap Score** | 0.85 (ì–‘í˜¸) | 0.92 (ìš°ìˆ˜) |
| **GATES F-stat** | 12.5 (ê°•í•œ ì´ì§ˆì„±) | 2.1 (ì•½í•œ ì´ì§ˆì„±) |

> **Key Finding**: Scenario Aì—ì„œ E-valueê°€ ë³´í†µ ìˆ˜ì¤€ì´ì§€ë§Œ Overlapì´ ì¶©ë¶„í•˜ê³  F-statì´ ë†’ì•„, "ëˆ„êµ¬ì—ê²Œ íš¨ê³¼ê°€ ìˆëŠ”ì§€"ê°€ í¬ê²Œ ë‹¤ë¥´ë‹¤ëŠ” ê°•í•œ ì´ì§ˆì„±ì´ í™•ì¸ë¨.

---

## 5. Discussion

### 5.1. Why simple regression failed?
ë‹¨ìˆœ íšŒê·€ë¶„ì„(OLS)ì€ ì‹ ìš©í•œë„ì™€ ì—°ì²´ìœ¨ ê°„ì˜ ê´€ê³„ë¥¼ ê³¼ë„í•˜ê²Œ ë¶€í’€ë ¸ìŠµë‹ˆë‹¤(Coefficient: -1.2). ì´ëŠ” ì—­ì¸ê³¼ ê´€ê³„ë¥¼ í†µì œí•˜ì§€ ëª»í•œ ê²°ê³¼ì…ë‹ˆë‹¤. DMLì€ ì´ëŸ¬í•œ í¸í–¥ì„ ì œê±°í•˜ì—¬ ë” ë³´ìˆ˜ì ì´ê³  ì •í™•í•œ ì¶”ì •ì¹˜(-0.034)ë¥¼ ì œê³µí–ˆìŠµë‹ˆë‹¤.

### 5.2. E-value and Unobserved Confounders
Scenario Aì˜ E-value 1.07ì€ ë¹„êµì  ì‘ì€ ê°’ìœ¼ë¡œ, ê°•í•œ ë¯¸ê´€ì¸¡ êµë€ì´ ìˆë‹¤ë©´ ê²°ê³¼ê°€ ë°”ë€” ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ í•©ì„± ë°ì´í„°ì—ì„œ ëª¨ë“  êµë€ì„ í†µì œí–ˆìœ¼ë¯€ë¡œ, ì´ëŠ” íš¨ê³¼ í¬ê¸° ìì²´ê°€ ì‘ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì‹¤ì œ ë°ì´í„°ì—ì„œëŠ” ë„êµ¬ ë³€ìˆ˜(IV) ë“±ì˜ ì¶”ê°€ ê¸°ë²•ì„ ë„ì…í•˜ì—¬ ì´ë¥¼ ë³´ì™„í•´ì•¼ í•©ë‹ˆë‹¤.

### 5.3. Limitations
-   **Unobserved Confounders**: ì‹¤ì œ ë°ì´í„°ì—ì„œëŠ” ì„±ê²©, ê¸ˆìœµ ì§€ì‹ ë“± ë¯¸ê´€ì¸¡ ë³€ìˆ˜ê°€ êµë€ ìš”ì¸ìœ¼ë¡œ ì‘ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
-   **Log-Linear Assumption**: LinearDMLì€ ì²˜ì¹˜ íš¨ê³¼ì˜ ì„ í˜•ì„±ì„ ê°€ì •í•©ë‹ˆë‹¤.
-   **í•©ì„± ë°ì´í„° í•œê³„**: ì‹¤ì œ ê¸ˆìœµ ë°ì´í„°ì—ì„œì˜ ê²€ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤.

---

## 6. Academic Benchmark Evaluation (GPU: RTX 4070 SUPER)

ë³¸ ì—”ì§„ì˜ CATE ì¶”ì • ì„±ëŠ¥ì„ ê²€ì¦í•˜ê¸° ìœ„í•´, **6ì¢… í‘œì¤€ í•™ìˆ  ë²¤ì¹˜ë§ˆí¬**ì—ì„œ **7ì¢… ì¶”ì •ê¸°**(5ì¢… ë©”íƒ€ëŸ¬ë„ˆ + DragonNet + TARNet)ë¥¼ GPU í™˜ê²½ì—ì„œ ë°˜ë³µ í‰ê°€í–ˆìŠµë‹ˆë‹¤.

### 6.1. Benchmark Datasets

| Dataset | Reference | n | p | íŠ¹ì§• |
|---------|-----------|:---:|:---:|------|
| **IHDP** | Hill 2011 | 747 | 25 | ë¹„ì„ í˜• Response Surface, ë¶ˆê· í˜• ì²˜ì¹˜ |
| **ACIC** | Dorie et al. 2019 | 4,802 | 58 | ê³ ì°¨ì›, ë¹„ì„ í˜• HTE, ë³µí•© êµë€ |
| **Jobs** | LaLonde 1986 | 722 | 8 | ê°•í•œ Selection Bias, ì†Œí‘œë³¸ |
| **TWINS** | Louizos et al. 2017 | 4,000 | 30 | ìŒë‘¥ì´ ìì—°ì‹¤í—˜, ìµœì†Œ êµë€ |
| **Criteo** | Diemert et al. 2018 | 50,000 | 12 | ëŒ€ê·œëª¨ ê´‘ê³  ì—…ë¦¬í”„íŠ¸, ë¯¸ì†Œ íš¨ê³¼ |
| **LaLonde** | LaLonde 1986 | 2,000 | 10 | ì§ì—… í›ˆë ¨ í”„ë¡œê·¸ë¨, ê´€ì°° ëŒ€ì¡°êµ° |

### 6.2. Results ($\sqrt{\text{PEHE}}$, lower is better)

| Method | IHDP | ACIC | TWINS | Jobs | LaLonde |
|--------|:----:|:----:|:-----:|:----:|:-------:|
| S-Learner | 1.371 | 0.504 | 0.179 | **291** | **729** |
| **T-Learner** | **1.159** | 0.847 | 0.281 | 500 | 1721 |
| X-Learner | 1.327 | 0.570 | 0.195 | 391 | 1300 |
| DR-Learner | 1.201 | 0.795 | 0.268 | 550 | 1784 |
| R-Learner | 1.631 | 1.182 | 0.430 | 721 | 1940 |
| **DragonNet** ğŸ†• | 1.414 | **0.478** | 0.165 | 1429 | 1800 |
| **TARNet** ğŸ†• | 1.417 | 0.504 | **0.158** | 1448 | 1785 |

> **ì°¸ê³ **: BART â‰ˆ 1.0 (Hill 2011), GANITE â‰ˆ 1.9 (Yoon et al. 2018), CEVAE â‰ˆ 0.34 on TWINS (Louizos et al. 2017)

### 6.3. Key Findings

1. **No single learner dominates**: IHDPâ†’T-Learner, ACICâ†’DragonNet, TWINSâ†’TARNet, Jobsâ†’S-Learner. ì´ëŠ” Oracle Ensembleì˜ í•„ìš”ì„±ì„ ë’·ë°›ì¹¨í•©ë‹ˆë‹¤.
2. **Deep Learning shines on high-dimensional/large-n data**: DragonNetì´ ACIC(p=58)ì—ì„œ ì „ì²´ 1ìœ„(0.478), TARNetì´ TWINS(n=4K)ì—ì„œ 1ìœ„(0.158). ì„±í–¥ì ìˆ˜ ì •ê·œí™”(DragonNet)ì™€ ê³µìœ  í‘œí˜„ í•™ìŠµì´ ê³ ì°¨ì› ë¹„ì„ í˜• CATE ì¶”ì •ì— íš¨ê³¼ì ì„ì„ í™•ì¸.
3. **Small-sample overfitting**: Jobs(n=722), LaLonde(n=2K)ì—ì„œ ë”¥ëŸ¬ë‹ì´ ê³¼ì í•©. ì†Œí‘œë³¸ì—ì„œëŠ” ì „í†µ ë©”íƒ€ëŸ¬ë„ˆ(S/T-Learner)ê°€ ìš°ìˆ˜.
4. **R-Learner consistently weakest**: Robinson Decompositionì´ ëª¨ë“  ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìµœí•˜ìœ„. Semi-parametric ê°€ì •ì´ DGPì™€ ë¶ˆì¼ì¹˜.

### 6.4. Real-World Validation: LaLonde (NSW) Dataset
WhyLabì˜ ì‹¤ì „ ì ìš© ê°€ëŠ¥ì„±ì„ ê²€ì¦í•˜ê¸° ìœ„í•´, ë…¸ë™ ê²½ì œí•™ì˜ ê³ ì „ì  ë¬¸ì œì¸ **LaLonde (1986)** ì§ì—… í›ˆë ¨ í”„ë¡œê·¸ë¨ ë°ì´í„°ë¥¼ ë¶„ì„í–ˆìŠµë‹ˆë‹¤ ($N=2,000$).

- **Causal Discovery**: MACëŠ” `education -> outcome`, `re75 -> outcome`, `treatment -> outcome` ë“±ì˜ ì£¼ìš” ì¸ê³¼ ê²½ë¡œë¥¼ 66.7%ì˜ í•©ì˜ìœ¨ë¡œ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.
- **Treatment Effect**: ì§ì—… í›ˆë ¨ì´ ì—°ê°„ ì†Œë“ì„ í‰ê·  **$2,110 ì¦ê°€**ì‹œí‚¨ë‹¤ê³  ì¶”ì •í–ˆìŠµë‹ˆë‹¤ (T-Learner). ì´ëŠ” ê¸°ì¡´ ë¬¸í—Œì˜ ì‹¤í—˜ ê²°ê³¼($1,794)ì™€ ìœ ì‚¬í•œ ìˆ˜ì¤€ì…ë‹ˆë‹¤.
- **Fairness Audit**: 4ëŒ€ ê³µì •ì„± ì§€í‘œ ê°ì‚¬ ê²°ê³¼, `Black` ë° `Hispanic` ê·¸ë£¹ ê°„ ì²˜ì¹˜ íš¨ê³¼ì˜ ê²©ì°¨(Causal Parity Gap > 0.1)ê°€ ë°œê²¬ë˜ì–´ ê³µì •ì„± ìœ„ë°˜ ê²½ê³ ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

![Figure 2: Fairness Audit Radar Chart](../figures/fig2_fairness_radar.png)
*Figure 2. Fairness Audit ê²°ê³¼ ë ˆì´ë” ì°¨íŠ¸. 4ëŒ€ ê³µì •ì„± ì§€í‘œë¥¼ ì‹œê°í™”í•˜ì—¬ í¸í–¥ëœ ê·¸ë£¹ì„ ì‹ë³„í•©ë‹ˆë‹¤.*

---

## 7. Multi-Agent Debate System

ê¸°ì¡´ ì¸ê³¼ì¶”ë¡  ë¼ì´ë¸ŒëŸ¬ë¦¬(DoWhy, EconML, CausalML)ëŠ” ë¶„ì„ ì½”ë“œë¥¼ ì œê³µí•˜ì§€ë§Œ, **ê²°ê³¼ í•´ì„ì˜ ë¶€ë‹´ì€ ì‚¬ìš©ìì—ê²Œ** ë‚¨ê¹ë‹ˆë‹¤.  WhyLabì€ AI Agentê°€ ìë™ìœ¼ë¡œ ì¸ê³¼ íŒê²°ì„ ë‚´ë¦¬ëŠ” Multi-Agent Debate ì‹œìŠ¤í…œì„ ë„ì…í•©ë‹ˆë‹¤.

### 7.1. DaV (Debate-as-Verification) Protocol

| Agent | Role | Evidence / Attacks |
|-------|------|-------------------|
| **Advocate** | ì¸ê³¼ ê´€ê³„ ì˜¹í˜¸ | 10ì¢… ì¦ê±° ìˆ˜ì§‘ (ë©”íƒ€ëŸ¬ë„ˆ í•©ì˜, í†µê³„ì  ìœ ì˜ì„±, E-value, Conformal CI ë“±) |
| **Critic** | ì¸ê³¼ ê´€ê³„ ë¹„íŒ | 8ì¢… ê³µê²© ë²¡í„° (E-value ì·¨ì•½, Overlap ìœ„ë°˜, Placebo ì‹¤íŒ¨, ë¶ˆì¼ì¹˜ ë“±) |
| **Judge** | ìµœì¢… íŒê²° | ì¦ê±° ìœ í˜•ë³„ ê°€ì¤‘ í•©ì‚° â†’ VERIFIED / REFUTED / UNCERTAIN |

### 7.2. Tool-Augmented Debate (Phase 5)

ê¸°ë³¸ DaVê°€ "ì´ë¯¸ ìˆëŠ” ì¦ê±°"ë§Œ í‰ê°€í•˜ëŠ” ë°˜ë©´, **ToolAugmented DaV**ëŠ” í† ë¡  ì¤‘ ìƒˆ ì¦ê±°ë¥¼ ë™ì ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤:

| ì—­í•  | ë„êµ¬ | ê¸°ëŠ¥ |
|------|------|------|
| Advocate | `cate_variance` | ë©”íƒ€ëŸ¬ë„ˆ CATE ë³€ë™ê³„ìˆ˜ ë¶„ì„ |
| Advocate | `effect_size` | Cohen's d íš¨ê³¼ í¬ê¸° ê²€ì¦ |
| Critic | `placebo` | ìœ„ì•½ ëŒ€ì¡° ë°˜ì¦ ê²€ì • |
| Critic | `overlap` | Positivity(ê²¹ì¹¨) ê°€ì • ê²€ì¦ |

**ë¼ìš´ë“œ êµ¬ì¡°**: Advocate ë„êµ¬ í˜¸ì¶œ â†’ Critic ë„êµ¬ í˜¸ì¶œ â†’ êµì°¨ ì‹¬ë¬¸ â†’ íŒê²°. ì´ë¥¼ N ë¼ìš´ë“œ ë°˜ë³µí•˜ì—¬ ì¦ê±° í’€ì„ ëˆ„ì í•©ë‹ˆë‹¤.

### 7.3. Scoring Mechanism

$$\text{Confidence} = \frac{\sum_{e \in \text{Pro}} w(e) \cdot s(e)}{\sum_{e \in \text{Pro}} w(e) \cdot s(e) + \sum_{e \in \text{Con}} w(e) \cdot s(e)}$$

ì—¬ê¸°ì„œ $w(e)$ëŠ” ì¦ê±° ìœ í˜•ë³„ ê°€ì¤‘ì¹˜ (robustness: 1.2, statistical: 1.0, domain: 0.8), $s(e)$ëŠ” ê°œë³„ ì¦ê±° ê°•ë„ (0~1).

### 7.4. Verdict Protocol
- **Confidence $\geq$ 0.65** â†’ VERIFIED
- **Confidence $\leq$ 0.40** â†’ REFUTED
- **Otherwise** â†’ UNCERTAIN (ì¶”ê°€ ë„êµ¬ í˜¸ì¶œ ë¼ìš´ë“œ)

---

## 8. Multi-Agent Causal Discovery (MAC)

ì¸ê³¼ êµ¬ì¡°(DAG) ë°œê²¬ì€ ë‹¨ì¼ ì•Œê³ ë¦¬ì¦˜ì— ì˜ì¡´í•  ê²½ìš° ë°ì´í„° íŠ¹ì„±ì— ë¯¼ê°í•©ë‹ˆë‹¤. WhyLabì€ 3ì¢… ì•Œê³ ë¦¬ì¦˜ì„ ë…ë¦½ ì‹¤í–‰ í›„ íˆ¬í‘œ ì•™ìƒë¸”ë¡œ í•©ì˜ DAGë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.

| Specialist | ì•Œê³ ë¦¬ì¦˜ | ê°€ì • |
|-----------|----------|------|
| **PC** | ì¡°ê±´ë¶€ ë…ë¦½ì„± + V-êµ¬ì¡° | Faithfulness |
| **GES** | BIC ê¸°ë°˜ íƒìš•ì  íƒìƒ‰ | Score equivalence |
| **LiNGAM** | ë¹„ê°€ìš°ì‹œì•ˆ ì¸ê³¼ ìˆœì„œ | Non-Gaussianity |

**íˆ¬í‘œ ì•™ìƒë¸”**: ê° ì—£ì§€ $(i \to j)$ì— ëŒ€í•´ Kê°œ Specialist ì¤‘ $\tau$ ë¹„ìœ¨ ì´ìƒì´ ë™ì˜í•˜ë©´ ìµœì¢… DAGì— í¬í•¨. ì•ˆì •ì„± ì ìˆ˜ $S_{ij} = \frac{1}{K}\sum_{k} A_k[i,j]$ë¥¼ í•¨ê»˜ ë³´ê³ í•©ë‹ˆë‹¤.

![Figure 3: MAC Discovery DAG](../figures/fig3_mac_dag.png)
*Figure 3. Multi-Agent Causal Discoveryë¥¼ í†µí•´ ë°œê²¬ëœ í•©ì˜ ì¸ê³¼ ê·¸ë˜í”„ (Consensus DAG). ì—£ì§€ì˜ ë‘ê»˜ëŠ” ì•ˆì •ì„± ì ìˆ˜(Stability Score)ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.*

---

## 9. Fairness Audit

ì¸ê³¼ íš¨ê³¼ê°€ ì¡´ì¬í•˜ë”ë¼ë„, ë³´í˜¸ ì†ì„±(ì„±ë³„, ì¸ì¢… ë“±)ì— ë”°ë¼ ì²˜ì¹˜ê°€ ë¶ˆê³µì •í•˜ê²Œ ë°°ë¶„ë˜ë©´ ìœ¤ë¦¬ì  ë¬¸ì œê°€ ë°œìƒí•©ë‹ˆë‹¤. WhyLabì€ 4ëŒ€ ê³µì •ì„± ì§€í‘œë¥¼ ìë™ ì§„ë‹¨í•©ë‹ˆë‹¤:

| ì§€í‘œ | ìˆ˜ì‹ | í†µê³¼ ê¸°ì¤€ |
|------|------|----------|
| **Demographic Parity** | $\|P(\hat{T}=1|A=0) - P(\hat{T}=1|A=1)\|$ | $\leq 0.1$ |
| **Equalized Odds** | $\|P(\hat{Y}=1|Y=1,A=0) - P(\hat{Y}=1|Y=1,A=1)\|$ | $\leq 0.1$ |
| **CATE Disparity** | $\|CATE_0 - CATE_1\|$ / $\|CATE\|$ | $\leq 0.2$ |
| **Calibration** | ê·¸ë£¹ë³„ ATE í¸ì°¨ | $\leq 20\%$ |

ê²°ê³¼ëŠ” êµ¬ì¡°í™”ëœ Markdown ê°ì‚¬ ë³´ê³ ì„œë¡œ ìë™ ìƒì„±ë©ë‹ˆë‹¤.

---

## 10. Conclusion

ë³¸ ì—°êµ¬ëŠ” ì„¸ ê°€ì§€ ë°©í–¥ì—ì„œ ê¸°ì—¬í•©ë‹ˆë‹¤:

**í•™ìˆ ì  ê¸°ì—¬**:
1. DML ê¸°ë°˜ ì¸ê³¼ íš¨ê³¼ ì¶”ì •ì¹˜ì˜ Ground Truth Correlation 0.97~0.99 ë‹¬ì„±
2. **6ì¢… ë²¤ì¹˜ë§ˆí¬ Ã— 7ì¢… ì¶”ì •ê¸°** GPU í‰ê°€: DragonNetì´ ACICì—ì„œ 1ìœ„(0.478), TARNetì´ TWINSì—ì„œ 1ìœ„(0.158)
3. ë”¥ëŸ¬ë‹ CATEê°€ ê³ ì°¨ì›Â·ëŒ€í‘œë³¸ì—ì„œ ì „í†µ ë©”íƒ€ëŸ¬ë„ˆë¥¼ ëŠ¥ê°€í•¨ì„ ì‹¤ì¦

**ë°©ë²•ë¡ ì  ê¸°ì—¬**:
1. **Tool-Augmented Debate**: í† ë¡  ì¤‘ ë„êµ¬ë¥¼ ë™ì  í˜¸ì¶œí•˜ì—¬ ì¦ê±°ë¥¼ ìƒì„±í•˜ëŠ” ìƒˆë¡œìš´ ì¸ê³¼ ê²€ì¦ í”„ë¡œí† ì½œ
2. **MAC Discovery**: PC/GES/LiNGAM ì•™ìƒë¸”ì˜ íˆ¬í‘œ ê¸°ë°˜ ì¸ê³¼ êµ¬ì¡° ë°œê²¬
3. **ê³µì •ì„± ê°ì‚¬**: 4ëŒ€ ê³µì •ì„± ì§€í‘œ ìë™ ì§„ë‹¨ + Markdown ë³´ê³ ì„œ ìƒì„±

**ì‹¤ë¬´ì  ê¸°ì—¬**:
1. Multi-Agent ì‹œìŠ¤í…œì„ í†µí•œ ìë™ ì¸ê³¼ íŒê²° (VERIFIED/REFUTED)
2. ìš©ëŸ‰-ë°˜ì‘ ê³¡ì„ (GPS)ìœ¼ë¡œ ì—°ì†í˜• ì²˜ì¹˜ì˜ ìµœì  ìš©ëŸ‰ íƒìƒ‰
3. ì„¸í¬ ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜ì— ì˜í•œ ëª¨ë“ˆì‹ í™•ì¥ ê°€ëŠ¥ì„±

**"Data with Why"** â€” WhyLabì€ "ë¬´ì—‡(What)ì´ ì¼ì–´ë‚¬ëŠ”ê°€"ë¥¼ ë„˜ì–´ "ì™œ(Why) ì¼ì–´ë‚¬ëŠ”ê°€"ë¥¼ ë¬»ëŠ” ì²«ê±¸ìŒì…ë‹ˆë‹¤.

---

## References
1.  Chernozhukov, V., et al. (2018). "Double/debiased machine learning for treatment and structural parameters". *The Econometrics Journal*.
2.  Rubin, D. B. (1974). "Estimating causal effects of treatments in randomized and nonrandomized studies". *Journal of Educational Psychology*.
3.  Microsoft Research. (2019). "EconML: A Python Package for ML-Based Heterogeneous Treatment Effects Estimation".
4.  VanderWeele, T. J. & Ding, P. (2017). "Sensitivity Analysis in Observational Research". *Annals of Internal Medicine*.
5.  Chernozhukov, V., et al. (2018). "Generic Machine Learning Inference on Heterogeneous Treatment Effects in Randomized Experiments". *NBER Working Paper*.
6.  Hill, J. L. (2011). "Bayesian Nonparametric Modeling for Causal Inference". *JCGS*, 20(1), 217-240.
7.  Kunzel, S. R., et al. (2019). "Meta-learners for estimating heterogeneous treatment effects using machine learning". *PNAS*, 116(10), 4156-4165.
8.  Kennedy, E. H. (2023). "Towards optimal doubly robust estimation of heterogeneous causal effects". *Electronic Journal of Statistics*.
9.  Nie, X. & Wager, S. (2021). "Quasi-oracle estimation of heterogeneous treatment effects". *Biometrika*, 108(2), 299-319.
10. Yoon, J., Jordon, J., & Van Der Schaar, M. (2018). "GANITE: Estimation of Individualized Treatment Effects Using Generative Adversarial Nets". *ICLR*.
11. Dorie, V., et al. (2019). "Automated versus do-it-yourself methods for causal inference". *Statistical Science*.
12. LaLonde, R. J. (1986). "Evaluating the Econometric Evaluations of Training Programs with Experimental Data". *American Economic Review*.
13. Shalit, U., Johansson, F. D., & Sontag, D. (2017). "Estimating individual treatment effect: generalization bounds and algorithms". *ICML*.
14. Shi, C., Blei, D. M., & Veitch, V. (2019). "Adapting Neural Networks for the Estimation of Treatment Effects". *NeurIPS*.
15. Louizos, C., et al. (2017). "Causal Effect Inference with Deep Latent-Variable Models". *NeurIPS*.
16. Du, Y., et al. (2023). "Improving Factuality and Reasoning in Language Models through Multiagent Debate". *arXiv*.
17. Schick, T., et al. (2023). "Toolformer: Language Models Can Teach Themselves to Use Tools". *NeurIPS*.
18. Spirtes, P., Glymour, C., & Scheines, R. (2000). "Causation, Prediction, and Search". *MIT Press*.
19. Shimizu, S., et al. (2006). "A Linear Non-Gaussian Acyclic Model for Causal Discovery". *JMLR*.

