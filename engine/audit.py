# -*- coding: utf-8 -*-
"""AuditLogger â€” ì¸ê³¼ ë¶„ì„ ê°ì‚¬ ì¶”ì  ì‹œìŠ¤í…œ.

ëª¨ë“  ì¸ê³¼ ë¶„ì„ ì‹¤í–‰ê³¼ íŒê²°ì„ ì¶”ì  ê°€ëŠ¥í•œ ê°ì‚¬ ë¡œê·¸ë¡œ ê¸°ë¡í•©ë‹ˆë‹¤.
"ì™œ ì´ ì •ì±…ì„ ìŠ¹ì¸í–ˆëŠ”ê°€?"ì— ëŒ€í•œ ì¦ê±° ì²´ì¸ì„ ì œê³µí•©ë‹ˆë‹¤.

Phase 11-4: ê±°ë²„ë„ŒìŠ¤.
"""

from __future__ import annotations

import json
import logging
import os
import time
import uuid
from dataclasses import asdict, dataclass, field
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, List, Optional

logger = logging.getLogger(__name__)

# ê°ì‚¬ ë¡œê·¸ ì €ì¥ ê²½ë¡œ (í™˜ê²½ ë³€ìˆ˜ë¡œ ì˜¤ë²„ë¼ì´ë“œ ê°€ëŠ¥)
AUDIT_LOG_DIR = os.environ.get("WHYLAB_AUDIT_DIR", "audit_logs")


@dataclass
class AuditEntry:
    """ë‹¨ì¼ ê°ì‚¬ ë¡œê·¸ í•­ëª©."""
    audit_id: str = ""
    timestamp: str = ""
    action: str = ""           # "analyze" | "discover" | "debate" | "export"
    user: str = "anonymous"
    treatment: str = ""
    outcome: str = ""
    dataset_hash: str = ""
    n_samples: int = 0
    result_summary: Dict[str, Any] = field(default_factory=dict)
    verdict: str = ""
    confidence: float = 0.0
    methods_used: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)
    execution_time_ms: int = 0
    metadata: Dict[str, Any] = field(default_factory=dict)


class AuditLogger:
    """ê°ì‚¬ ë¡œê·¸ ê´€ë¦¬ì.

    ëª¨ë“  ì¸ê³¼ ë¶„ì„ì˜ ì…ë ¥, ë°©ë²•ë¡ , ê²°ê³¼, íŒê²°ì„
    JSON Lines í˜•ì‹ìœ¼ë¡œ ê¸°ë¡í•©ë‹ˆë‹¤.
    """

    def __init__(self, log_dir: Optional[str] = None) -> None:
        self.log_dir = Path(log_dir or AUDIT_LOG_DIR)
        self.log_dir.mkdir(parents=True, exist_ok=True)
        self._current_session = str(uuid.uuid4())[:8]
        self._entries: List[AuditEntry] = []
        logger.info("ğŸ“‹ ê°ì‚¬ ë¡œê·¸ ì´ˆê¸°í™” (ë””ë ‰í† ë¦¬: %s)", self.log_dir)

    def log_analysis(
        self,
        context: Dict[str, Any],
        execution_time_ms: int = 0,
        user: str = "anonymous",
    ) -> str:
        """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼ë¥¼ ê°ì‚¬ ë¡œê·¸ì— ê¸°ë¡í•©ë‹ˆë‹¤.

        Args:
            context: íŒŒì´í”„ë¼ì¸ ìµœì¢… ì»¨í…ìŠ¤íŠ¸.
            execution_time_ms: ì‹¤í–‰ ì‹œê°„ (ë°€ë¦¬ì´ˆ).
            user: ì‹¤í–‰ ì‚¬ìš©ì.

        Returns:
            ê°ì‚¬ ID.
        """
        import hashlib

        audit_id = f"AUD-{self._current_session}-{len(self._entries):04d}"

        # ë°ì´í„°ì…‹ í•´ì‹œ (ì¬í˜„ì„±)
        df = context.get("dataframe")
        if df is not None:
            try:
                dataset_hash = hashlib.sha256(
                    str(df.shape).encode() + str(df.columns.tolist()).encode()
                ).hexdigest()[:12]
            except Exception:
                dataset_hash = "unknown"
        else:
            dataset_hash = "synthetic"

        # ì‚¬ìš©ëœ ë°©ë²•ë¡  ìˆ˜ì§‘
        methods = []
        if context.get("ate"):
            methods.append("DML")
        if context.get("meta_learners"):
            methods.extend(list(context["meta_learners"].keys()))
        if context.get("quasi_experimental"):
            methods.extend([f"QE:{k}" for k in context["quasi_experimental"].keys()])
        if context.get("temporal_causal"):
            methods.extend([f"TC:{k}" for k in context["temporal_causal"].keys()])
        if context.get("counterfactual"):
            methods.append("Counterfactual")
        if context.get("dag_edges"):
            methods.append("Discovery")

        # Debate ê²°ê³¼
        debate = context.get("debate", {})
        verdict = debate.get("verdict", "N/A") if isinstance(debate, dict) else "N/A"
        confidence = debate.get("confidence", 0.0) if isinstance(debate, dict) else 0.0

        # ê²½ê³  ìˆ˜ì§‘
        warnings = []
        profile = context.get("data_profile", {})
        if isinstance(profile, dict):
            warnings.extend(profile.get("warnings", []))
        recommendation = context.get("auto_recommendation", {})
        if isinstance(recommendation, dict):
            warnings.extend(recommendation.get("warnings", []))

        # ATE ìš”ì•½
        ate_raw = context.get("ate", {})
        if isinstance(ate_raw, dict):
            ate_val = ate_raw.get("point_estimate", ate_raw.get("value", 0))
        elif isinstance(ate_raw, (int, float)):
            ate_val = ate_raw
        else:
            ate_val = 0

        entry = AuditEntry(
            audit_id=audit_id,
            timestamp=datetime.now(timezone.utc).isoformat(),
            action="analyze",
            user=user,
            treatment=context.get("treatment_col", ""),
            outcome=context.get("outcome_col", ""),
            dataset_hash=dataset_hash,
            n_samples=len(df) if df is not None else 0,
            result_summary={"ate": ate_val, "verdict": verdict, "confidence": confidence},
            verdict=verdict,
            confidence=confidence,
            methods_used=methods,
            warnings=warnings,
            execution_time_ms=execution_time_ms,
            metadata={
                "discovery_mode": context.get("discovery_mode", ""),
                "recommended_method": context.get("auto_recommendation", {}).get(
                    "primary_method", ""
                ) if isinstance(context.get("auto_recommendation"), dict) else "",
                "pipeline_cells": 16,
            },
        )

        self._entries.append(entry)
        self._write_entry(entry)

        logger.info(
            "ğŸ“‹ ê°ì‚¬ ë¡œê·¸ ê¸°ë¡ [%s]: %s â†’ %s (í™•ì‹ ë„=%.1f%%)",
            audit_id, entry.treatment, entry.verdict, entry.confidence * 100,
        )

        return audit_id

    def get_entries(self, limit: int = 100) -> List[Dict[str, Any]]:
        """ìµœê·¼ ê°ì‚¬ ë¡œê·¸ í•­ëª©ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return [asdict(e) for e in self._entries[-limit:]]

    def search(self, treatment: Optional[str] = None, verdict: Optional[str] = None) -> List[Dict[str, Any]]:
        """ê°ì‚¬ ë¡œê·¸ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
        results = []
        for entry in self._entries:
            if treatment and entry.treatment != treatment:
                continue
            if verdict and entry.verdict != verdict:
                continue
            results.append(asdict(entry))
        return results

    def _write_entry(self, entry: AuditEntry) -> None:
        """ê°ì‚¬ ë¡œê·¸ë¥¼ JSON Lines íŒŒì¼ì— ê¸°ë¡í•©ë‹ˆë‹¤."""
        today = datetime.now().strftime("%Y-%m-%d")
        log_file = self.log_dir / f"audit_{today}.jsonl"

        try:
            with open(log_file, "a", encoding="utf-8") as f:
                f.write(json.dumps(asdict(entry), ensure_ascii=False) + "\n")
        except Exception as e:
            logger.error("ê°ì‚¬ ë¡œê·¸ ê¸°ë¡ ì‹¤íŒ¨: %s", e)
