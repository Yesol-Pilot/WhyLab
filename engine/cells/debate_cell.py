# -*- coding: utf-8 -*-
"""DebateCell â€” Multi-Agent Debate íŒŒì´í”„ë¼ì¸ ì…€.

Orchestrator íŒŒì´í”„ë¼ì¸ì˜ ìµœì¢… ë‹¨ê³„ë¡œ,
Advocate/Critic/Judge 3-ì—ì´ì „íŠ¸ Debateë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

Phase 9: LLM ìì—°ì–´ í† ë¡  ë ˆì´ì–´ í†µí•©.
ê·œì¹™ ê¸°ë°˜ ì¦ê±° ìˆ˜ì§‘ â†’ LLM ìì—°ì–´ í† ë¡  ìƒì„± â†’ ê°€ì¤‘ ìŠ¤ì½”ì–´ë§ íŒê²°.
LLM ë¹„í™œì„±/ì¥ì•  ì‹œ ê¸°ì¡´ ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ ìë™ Fallback.
"""

from __future__ import annotations

import logging
from typing import Any, Dict

from engine.cells.base_cell import BaseCell
from engine.agents.debate import AdvocateAgent, CriticAgent, JudgeAgent, Verdict
from engine.agents.llm_adapter import LLMDebateAdapter
from engine.config import WhyLabConfig

logger = logging.getLogger(__name__)


class DebateCell(BaseCell):
    """Multi-Agent Debate ì…€.

    íŒŒì´í”„ë¼ì¸ ê²°ê³¼ë¥¼ 3-ì—ì´ì „íŠ¸ Debateë¡œ íŒê²°í•©ë‹ˆë‹¤.
    LLMì´ í™œì„±í™”ë˜ë©´ ìì—°ì–´ í† ë¡ ë¬¸ì„ ì¶”ê°€ ìƒì„±í•©ë‹ˆë‹¤.
    """

    def __init__(self, config: WhyLabConfig) -> None:
        super().__init__(name="debate_cell", config=config)

    def execute(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """Debate ì‹¤í–‰.

        Args:
            inputs: ì „ì²´ íŒŒì´í”„ë¼ì¸ ê²°ê³¼.

        Returns:
            íŒê²° ê²°ê³¼ í¬í•¨ dict.
        """
        cfg = self.config.debate
        advocate = AdvocateAgent()
        critic = CriticAgent()
        judge = JudgeAgent(weights=cfg.evidence_weights)

        # LLM ì–´ëŒ‘í„° ì´ˆê¸°í™”
        llm_adapter = None
        if cfg.use_llm:
            llm_adapter = LLMDebateAdapter(model_name=cfg.llm_model)
            if llm_adapter.is_llm_active:
                self.logger.info("ğŸ¤– LLM í† ë¡  ëª¨ë“œ í™œì„±í™” (ëª¨ë¸: %s)", cfg.llm_model)
            else:
                self.logger.info("ğŸ“ LLM ë¯¸ì„¤ì • â†’ ê·œì¹™ ê¸°ë°˜ Fallback í† ë¡  ëª¨ë“œ")

        self.logger.info("ğŸ™ï¸ Multi-Agent Debate ì‹œì‘ (ìµœëŒ€ %d ë¼ìš´ë“œ)", cfg.max_rounds)

        verdict = None
        all_pro = []
        all_con = []

        for round_num in range(1, cfg.max_rounds + 1):
            self.logger.info("â”€â”€ Round %d â”€â”€", round_num)

            # 1ë‹¨ê³„: ê·œì¹™ ê¸°ë°˜ ì¦ê±° ìˆ˜ì§‘
            pro = advocate.gather_evidence(inputs)
            con = critic.challenge(inputs)

            # ëˆ„ì 
            all_pro.extend(pro)
            all_con.extend(con)

            # 2ë‹¨ê³„: ê°€ì¤‘ ìŠ¤ì½”ì–´ë§ íŒê²°
            verdict = judge.deliberate(
                all_pro, all_con, threshold=cfg.confidence_threshold,
            )
            verdict.rounds = round_num

            if verdict.verdict != "UNCERTAIN":
                self.logger.info(
                    "ğŸ›ï¸ íŒê²° í™•ì • (Round %d): %s (í™•ì‹ ë„=%.2f)",
                    round_num, verdict.verdict, verdict.confidence,
                )
                break

            self.logger.info(
                "âš ï¸ Round %d: UNCERTAIN (í™•ì‹ ë„=%.2f) â†’ ì¶”ê°€ ë¼ìš´ë“œ",
                round_num, verdict.confidence,
            )

        # 3ë‹¨ê³„: LLM ìì—°ì–´ í† ë¡  ìƒì„± (ìµœì¢… íŒê²° í›„)
        llm_debate = {}
        if llm_adapter is not None:
            # ATE ê°’ ì¶”ì¶œ (float ë˜ëŠ” dict)
            ate_raw = inputs.get("ate")
            if isinstance(ate_raw, dict):
                ate_value = ate_raw.get("value", "N/A")
            elif isinstance(ate_raw, (int, float)):
                ate_value = f"{ate_raw:.4f}"
            else:
                ate_value = "N/A"

            llm_context = {
                "treatment_col": inputs.get("treatment_col", "Treatment"),
                "outcome_col": inputs.get("outcome_col", "Outcome"),
                "ate_value": ate_value,
            }

            self.logger.info("ğŸ¤– LLM í† ë¡ ë¬¸ ìƒì„± ì¤‘...")

            advocate_arg = llm_adapter.generate_advocate_argument(
                all_pro, llm_context,
            )
            critic_arg = llm_adapter.generate_critic_argument(
                all_con, llm_context,
            )
            verdict_arg = llm_adapter.generate_verdict(
                advocate_arg, critic_arg,
                {
                    "verdict": verdict.verdict,
                    "confidence": verdict.confidence,
                    "pro_score": verdict.pro_score,
                    "con_score": verdict.con_score,
                    "recommendation": verdict.recommendation,
                },
                llm_context,
            )

            llm_debate = {
                "advocate_argument": advocate_arg,
                "critic_argument": critic_arg,
                "judge_verdict": verdict_arg,
                **llm_adapter.get_debate_summary(),
            }

            self.logger.info(
                "âœ… LLM í† ë¡  ì™„ë£Œ (í™œì„±: %s, ì‘ë‹µ %dê±´)",
                llm_adapter.is_llm_active,
                len(llm_adapter.responses),
            )

        # ìµœì¢… ê²°ê³¼
        debate_summary = {
            "verdict": verdict.verdict,
            "confidence": verdict.confidence,
            "pro_score": verdict.pro_score,
            "con_score": verdict.con_score,
            "rounds": verdict.rounds,
            "recommendation": verdict.recommendation,
            "pro_evidence": [
                {"claim": e.claim, "type": e.evidence_type,
                 "strength": e.strength, "source": e.source,
                 "business_impact": e.business_impact}
                for e in verdict.pro_evidence
            ],
            "con_evidence": [
                {"claim": e.claim, "type": e.evidence_type,
                 "strength": e.strength, "source": e.source,
                 "business_impact": e.business_impact}
                for e in verdict.con_evidence
            ],
            # LLM í† ë¡  ê²°ê³¼ í¬í•¨
            "llm_debate": llm_debate,
        }

        self.logger.info(
            "ğŸ“‹ Debate ì™„ë£Œ: verdict=%s, rounds=%d, "
            "pro_evidence=%d, con_evidence=%d, llm=%s",
            verdict.verdict, verdict.rounds,
            len(verdict.pro_evidence), len(verdict.con_evidence),
            "active" if llm_debate.get("llm_active") else "fallback",
        )

        return {
            **inputs,
            "debate_verdict": verdict,
            "debate_summary": debate_summary,
        }
