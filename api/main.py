# -*- coding: utf-8 -*-
"""WhyLab Dashboard Backend API (Persistence Enabled)."""

import sys
import uuid
import logging
import io
import os
import shutil
import joblib
from pathlib import Path
from typing import List, Dict, Any, Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(ROOT))

import pandas as pd
import numpy as np
from fastapi import FastAPI, UploadFile, File, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from sqlalchemy.orm import Session

from api import models, schemas, crud
from api.database import SessionLocal, engine, get_db

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("whylab-api")

# DB í…Œì´ë¸” ìƒì„± (Productionì—ì„œëŠ” Migration ë„êµ¬ ì‚¬ìš© ê¶Œì¥)
models.Base.metadata.create_all(bind=engine)

app = FastAPI(title="WhyLab API", version="2.0.0")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:4000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# â”€â”€ ì„œë²„ ì‹œì‘ ì‹œ ììœ¨ ì—°êµ¬(Autopilot) ìë™ ì‹¤í–‰ â”€â”€
@app.on_event("startup")
def _auto_start_autopilot():
    """ì„œë²„ ë¶€íŒ… ì™„ë£Œ í›„ Autopilotì„ ìë™ìœ¼ë¡œ ì‹œì‘í•©ë‹ˆë‹¤."""
    import threading
    def _delayed_start():
        import time
        time.sleep(3)  # DB/ì„œë²„ ì´ˆê¸°í™” ëŒ€ê¸°
        try:
            from api.agents.autopilot import autopilot
            if not autopilot.running:
                result = autopilot.start(db_factory=SessionLocal)
                logger.info(f"ğŸš€ [AUTOPILOT] ìë™ ì‹œì‘ ì™„ë£Œ: {result}")
        except Exception as e:
            logger.error(f"âŒ [AUTOPILOT] ìë™ ì‹œì‘ ì‹¤íŒ¨: {e}")
    threading.Thread(target=_delayed_start, daemon=True).start()

# ... (rest of code)

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("api.main:app", host="0.0.0.0", port=4001, reload=True)

# íŒŒì¼ ì €ì¥ ê²½ë¡œ ì„¤ì •
UPLOAD_DIR = ROOT / "data" / "uploads"
MODEL_DIR = ROOT / "data" / "models"
UPLOAD_DIR.mkdir(parents=True, exist_ok=True)
MODEL_DIR.mkdir(parents=True, exist_ok=True)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Endpoints
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@app.get("/")
def health_check():
    return {"status": "ok", "version": "2.0.0", "persistence": "sqlite"}

@app.get("/session/{session_id}", response_model=schemas.SessionResponse)
def get_session_info(session_id: str, db: Session = Depends(get_db)):
    """ì„¸ì…˜ ìƒíƒœ ë° ë¶„ì„ ì´ë ¥ ì¡°íšŒ (ë³µêµ¬ìš©)."""
    session = crud.get_session(db, session_id)
    if not session:
        raise HTTPException(status_code=404, detail="Session not found")
    return session

@app.post("/upload", response_model=schemas.UploadResponse)
async def upload_file(file: UploadFile = File(...), db: Session = Depends(get_db)):
    """CSV íŒŒì¼ ì—…ë¡œë“œ, ë¡œì»¬ ì €ì¥, DB ë©”íƒ€ë°ì´í„° ê¸°ë¡."""
    try:
        # 1. ì„¸ì…˜ ìƒì„±
        session = crud.create_session(db)
        session_id = session.id
        
        # 2. íŒŒì¼ ì €ì¥
        safe_filename = f"{session_id}_{file.filename}"
        file_path = UPLOAD_DIR / safe_filename
        
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
            
        # 3. ë°ì´í„° ë¡œë“œ ë° ë¯¸ë¦¬ë³´ê¸° (ê²€ì¦)
        df = pd.read_csv(file_path)
        # ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ë°ëª¨ìš©)
        df_clean = df.dropna()
        if len(df) != len(df_clean):
            # ë®ì–´ì“°ê¸°
            df_clean.to_csv(file_path, index=False)
            df = df_clean

        # 4. DB ê¸°ë¡
        crud.create_dataset(
            db=db,
            session_id=session_id,
            filename=file.filename,
            file_path=str(file_path),
            rows=len(df),
            columns=list(df.columns)
        )
        
        return {
            "session_id": session_id,
            "filename": file.filename,
            "rows": len(df),
            "columns": list(df.columns),
            "preview": df.head().to_dict(orient="records")
        }
    except Exception as e:
        logger.error(f"Upload failed: {e}")
        raise HTTPException(status_code=400, detail=str(e))

def get_df_from_db(session_id: str, db: Session) -> pd.DataFrame:
    dataset = crud.get_dataset(db, session_id)
    if not dataset:
        raise HTTPException(status_code=404, detail="Dataset not found for this session")
    
    if not os.path.exists(dataset.file_path):
        raise HTTPException(status_code=500, detail="Data file lost on server")
        
    return pd.read_csv(dataset.file_path)

@app.post("/analysis/dose-response")
async def analyze_dose_response(req: schemas.AnalysisRequest, db: Session = Depends(get_db)):
    try:
        df = get_df_from_db(req.session_id, db)
        
        from engine.cells.dose_response_cell import DoseResponseCell, DoseResponseConfig
        
        cell = DoseResponseCell(dr_config=DoseResponseConfig(n_grid_points=50))
        input_data = {
            "dataframe": df,
            "treatment_col": req.treatment,
            "outcome_col": req.outcome,
            "feature_names": req.confounders
        }
        
        result = cell.execute(input_data)
        
        # ëª¨ë¸ ì €ì¥ (Pickle)
        model_filename = f"{req.session_id}_dose_response.joblib"
        model_path = MODEL_DIR / model_filename
        
        # Cell ì „ì²´ë¥¼ ì €ì¥ (Helper function needed to pickle cell properly?)
        # For simplicity, we save the trained 'response_model' if it exists, or the cell itself.
        # But cell object might be large or unpicklable if it has logger etc.
        # DoseResponseCell handles numpy, it should be fine.
        # *ì¤‘ìš”*: LoggerëŠ” pickle ì•ˆë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì²˜ë¦¬ê°€ í•„ìš”í•˜ì§€ë§Œ, ì—¬ê¸°ì„  joblibì´ ê°•ë ¥í•˜ë¯€ë¡œ ì‹œë„.
        # ì•ˆì „í•˜ê²ŒëŠ” response_modelê³¼ configë§Œ ì €ì¥í•˜ëŠ” ê²ƒì´ ì¢‹ìŒ.
        
        # cell.logger ì œê±° í›„ ì €ì¥
        cell.logger = None 
        joblib.dump(cell, model_path)
        
        res = result["dose_response"]
        serializable_res = {
            "t_grid": res["t_grid"],
            "dr_curve": res["dr_curve"],
            "ci_lower": res.get("ci_lower"),
            "ci_upper": res.get("ci_upper"),
            "optimal_dose": float(res["optimal_dose"]),
            "optimal_effect": float(res["optimal_effect"]),
            "has_effect": bool(res["has_effect"])
        }
        
        # DB ì €ì¥
        crud.create_analysis_result(
            db=db,
            session_id=req.session_id,
            analysis_type="dose_response",
            config=req.dict(),
            result=serializable_res,
            model_path=str(model_path)
        )
        
        return {"status": "success", "result": serializable_res}
        
    except Exception as e:
        logger.error(f"Dose-response failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/analysis/discovery")
async def analyze_discovery(req: schemas.DiscoveryRequest, db: Session = Depends(get_db)):
    try:
        df = get_df_from_db(req.session_id, db)
        vars_to_use = req.variables if req.variables else list(df.columns)
        
        from engine.agents.mac_discovery_agent import MACDiscoveryAgent
        agent = MACDiscoveryAgent()
        
        dag = await agent.discover_causal_structure(df, variable_names=vars_to_use)
        
        edges = [{"source": e.source, "target": e.target} for e in dag.edges]
        nodes = [{"id": v, "label": v} for v in vars_to_use]
        
        res_data = {
             "nodes": nodes,
             "edges": edges,
             "consensus_level": dag.consensus_level,
             "stability_scores": dag.stability_scores
        }
        
        crud.create_analysis_result(
            db=db,
            session_id=req.session_id,
            analysis_type="discovery",
            config=req.dict(),
            result=res_data
        )
        
        return {"status": "success", "result": res_data}
    except Exception as e:
        logger.error(f"Discovery failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/analysis/fairness")
async def analyze_fairness(req: schemas.FairnessRequest, db: Session = Depends(get_db)):
    try:
        df = get_df_from_db(req.session_id, db)
        
        from engine.cells.meta_learner_cell import TLearner
        from engine.config import WhyLabConfig
        from engine.cells.fairness_audit_cell import FairnessAuditCell
        
        X = df[req.confounders].values
        T = df[req.treatment].values
        Y = df[req.outcome].values
        
        config = WhyLabConfig()
        learner = TLearner(config=config)
        learner.fit(X, T, Y)
        cate = learner.predict_cate(X)
        
        cell = FairnessAuditCell()
        audit_results = cell.audit(cate, df, req.sensitive_attrs)
        
        serialized = []
        for res in audit_results:
            serialized.append({
                "attribute": res.group_name,
                "overall_cate": float(res.overall_cate),
                "is_fair": res.is_fair,
                "metrics": res.metrics,
                "subgroups": [ 
                    {"name": str(k), "mean_cate": float(v.mean_cate), "size": int(v.size)} 
                    for k, v in res.subgroups.items() 
                ]
            })
            
        crud.create_analysis_result(
            db=db,
            session_id=req.session_id,
            analysis_type="fairness",
            config=req.dict(),
            result=serialized
        )
            
        return {"status": "success", "result": serialized}
        
    except Exception as e:
        logger.error(f"Fairness failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/analysis/simulate")
async def simulate_policy(req: schemas.SimulationRequest, db: Session = Depends(get_db)):
    try:
        # DBì—ì„œ ëª¨ë¸ ê²½ë¡œ ì¡°íšŒ
        analysis = crud.get_analysis_result(db, req.session_id, "dose_response")
        if not analysis or not analysis.model_path:
             raise HTTPException(status_code=400, detail="Dose-Response analysis required first.")
             
        # ëª¨ë¸ ë¡œë“œ
        if not os.path.exists(analysis.model_path):
             raise HTTPException(status_code=500, detail="Model file lost.")
             
        cell = joblib.load(analysis.model_path)
        # config = analysis.config # DBì— ì €ì¥ëœ config ì‚¬ìš© ê°€ëŠ¥
        
        # ë°ì´í„° ë¡œë“œ
        df = get_df_from_db(req.session_id, db)
        
        # ê¸°ì¡´ main.pyì˜ ë¡œì§ ì¬ì‚¬ìš©
        # (models.pyì˜ AnalysisResult.configëŠ” JSONì´ë¯€ë¡œ dictë¡œ ìë™ ë³€í™˜ë¨)
        config = analysis.config 
        
        n_users = len(df)
        n_target = int(n_users * (req.target_percent / 100))
        if n_target == 0: n_target = 1
            
        df_sorted = df.sort_values(by=config['outcome'])
        target_indices = df_sorted.index[:n_target]
        
        X_target = df.loc[target_indices, config['confounders']].values
        T_target = df.loc[target_indices, config['treatment']].values
        
        T_new = T_target + req.intensity
        
        try:
            Y_pred_old = cell.predict(X_target, T_target)
            Y_pred_new = cell.predict(X_target, T_new)
        except ValueError:
            raise HTTPException(status_code=400, detail="Prediction model not ready.")
            
        benefit = np.sum(Y_pred_new - Y_pred_old)
        cost = req.intensity * req.cost_per_unit * n_target
        net_profit = benefit - cost
        roi = (net_profit / (cost + 1e-10)) * 100
        avg_outcome_change = np.mean(Y_pred_new - Y_pred_old)
        
        # Sensitivity
        sensitivity_data = []
        intensity_range = np.linspace(0, 2000, 11)
        for val in intensity_range:
            T_sens = T_target + val
            try:
                Y_sens = cell.predict(X_target, T_sens)
                sens_benefit = np.sum(Y_sens - Y_pred_old)
                sens_cost = val * req.cost_per_unit * n_target
                sens_profit = sens_benefit - sens_cost
                sens_risk = (val / 2000.0) * 0.1
                sensitivity_data.append({
                    "intensity": float(val),
                    "profit": float(sens_profit),
                    "risk": float(sens_risk * 100)
                })
            except:
                continue

        return {
            "status": "success",
            "result": {
                "current": {
                    "net_profit": float(net_profit),
                    "roi": float(roi),
                    "total_cost": float(cost),
                    "total_benefit": float(benefit),
                    "target_users": int(n_target),
                    "avg_outcome_boost": float(avg_outcome_change)
                },
                "sensitivity": sensitivity_data
            }
        }
        
    except Exception as e:
        logger.error(f"Simulation failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# System & Control Room Endpoints
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@app.on_event("startup")
def startup_event():
    """ì„œë²„ ì‹œì‘ ì‹œ: ì—ì´ì „íŠ¸ ì´ˆê¸°í™” + Director ì•„ì  ë‹¤ + ë¡œê·¸ ë¡œí…Œì´ì…˜."""
    db = SessionLocal()
    try:
        if not crud.get_agents(db):
            logger.info("Initializing Genesis Agents...")
            crud.create_agent(db, "theorist-1", "Albert", "Theorist", {"model": "GPT-4o"})
            crud.create_agent(db, "engineer-1", "Tesla", "Engineer", {"sandbox": "Firecracker"})
            crud.create_agent(db, "critic-1", "Kant", "Critic", {"method": "Do-calculus"})
            crud.create_agent(db, "coordinator-1", "Manager", "Coordinator", {"policy": "Themis"})
            
            crud.create_log(db, "coordinator-1", "INFO", "System Boot Sequence Initiated.")
            crud.create_log(db, "theorist-1", "INFO", "Connecting to Knowledge Graph...")

        # Director ì•„ì  ë‹¤ ì„¤ì • ë° ë¡œê·¸ ê¸°ë¡
        agenda = _lab_director.get_current_agenda()
        if agenda and "title" in agenda:
            crud.create_log(db, "director", "INFO",
                f"ğŸ“¢ [DIRECTIVE] ê¸ˆì£¼ ì—°êµ¬ ì£¼ì œ: '{agenda['title']}' | ì¹´í…Œê³ ë¦¬: {agenda.get('category', 'N/A')} | ë‚œì´ë„: {agenda.get('difficulty', 'N/A')}")
            crud.create_log(db, "director", "INFO",
                f"ğŸ¯ {agenda.get('description', '')}")
            crud.create_log(db, "coordinator-1", "INFO",
                f"âš¡ Director ì§€ì‹œ ìˆ˜ì‹ . '{agenda['title']}' ì—°êµ¬ ì¤€ë¹„ ì¤‘...")
            crud.create_log(db, "theorist-1", "INFO",
                f"ğŸ“š '{agenda['title']}' ê´€ë ¨ ì„ í–‰ ì—°êµ¬ íƒìƒ‰ ì‹œì‘...")
            logger.info(f"Director agenda set: {agenda['title']}")

        # Sprint 30: ì„œë²„ ì‹œì‘ ì‹œ ìë™ ë¡œê·¸ ë¡œí…Œì´ì…˜
        from api.log_rotation import log_rotation
        rotation_stats = log_rotation.rotate()
        if rotation_stats["hot_to_warm"] > 0 or rotation_stats["hot_trimmed"] > 0:
            logger.info(
                "ë¡œê·¸ ë¡œí…Œì´ì…˜ ì™„ë£Œ: Hotâ†’Warm %dê±´, íŠ¸ë¦¬ë° %dê±´",
                rotation_stats["hot_to_warm"], rotation_stats["hot_trimmed"]
            )
    finally:
        db.close()

@app.get("/system/agents", response_model=List[schemas.AgentBase])
def get_agents(db: Session = Depends(get_db)):
    return crud.get_agents(db)

@app.get("/system/logs", response_model=List[schemas.SystemLogBase])
def get_system_logs(limit: int = 50, db: Session = Depends(get_db)):
    """ìµœì‹  ì‹œìŠ¤í…œ ë¡œê·¸ ì¡°íšŒ (ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¼ìš©)."""
    return crud.get_logs(db, limit=limit)

@app.post("/system/logs", response_model=schemas.SystemLogBase)
def post_system_log(log: schemas.SystemLogBase, db: Session = Depends(get_db)):
    """ì—ì´ì „íŠ¸ê°€ ì§ì ‘ ë¡œê·¸ë¥¼ ë‚¨ê¸°ëŠ” ì¸í„°í˜ì´ìŠ¤."""
    # Note: ìŠ¤í‚¤ë§ˆê°€ id, created_atì„ í¬í•¨í•˜ë¯€ë¡œ ì‹¤ì œ ìš”ì²­ìš© ìŠ¤í‚¤ë§ˆ ë¶„ë¦¬ê°€ ì´ìƒì ì´ë‚˜,
    # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ í•„ë“œë§Œ ì·¨í•¨.
    return crud.create_log(db, log.agent_id, log.level, log.message)

@app.get("/system/graph")
def get_knowledge_graph():
    """ì§€ì‹ ê·¸ë˜í”„ ë°ì´í„° ì¡°íšŒ (NetworkX -> JSON)."""
    from api.graph import kg
    if not kg.initialized:
        kg.initialize_seed_data()
    return kg.get_graph_data()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Agent Activation (Sprint 12)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.post("/system/agents/{agent_id}/activate")
def activate_agent(agent_id: str, db: Session = Depends(get_db)):
    """ì—ì´ì „íŠ¸ë¥¼ í™œì„±í™”í•˜ì—¬ ììœ¨ ì—°êµ¬ ì‚¬ì´í´ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    agent = db.query(models.Agent).filter(models.Agent.id == agent_id).first()
    if not agent:
        raise HTTPException(status_code=404, detail=f"Agent '{agent_id}' not found")
    
    if agent.status == "WORKING":
        raise HTTPException(status_code=409, detail=f"Agent '{agent_id}' is already working")
    
    # ìƒíƒœ ì „ì´: IDLE â†’ WORKING
    agent.status = "WORKING"
    db.commit()
    crud.create_log(db, agent_id, "INFO", f"Agent '{agent.name}' activated. Status â†’ WORKING")
    
    result = {}
    try:
        cycle_logs = []
        
        if agent.role == "Theorist":
            from api.agents.theorist import run_theorist_cycle
            cycle_logs = run_theorist_cycle()
        elif agent.role == "Engineer":
            from api.agents.engineer import run_engineer_cycle
            cycle_logs = run_engineer_cycle()
        elif agent.role == "Critic":
            from api.agents.critic import run_critic_cycle
            cycle_logs = run_critic_cycle()
        elif agent.role == "Coordinator":
            from api.agents.coordinator import run_coordinator_cycle
            cycle_logs = run_coordinator_cycle()
        
        if cycle_logs:
            # ê° ë‹¨ê³„ë¥¼ SystemLogì— ê¸°ë¡
            for entry in cycle_logs:
                crud.create_log(db, agent_id, "INFO", f"[{entry['step']}] {entry['message']}")
            
            result = {
                "agent_id": agent_id,
                "role": agent.role,
                "cycle_logs": cycle_logs,
                "status": "COMPLETE",
            }
        else:
            crud.create_log(db, agent_id, "WARNING", f"Agent '{agent.name}' ({agent.role}) returned no logs.")
            result = {
                "agent_id": agent_id,
                "role": agent.role,
                "status": "EMPTY",
                "message": f"{agent.role} ì‚¬ì´í´ì´ ê²°ê³¼ ì—†ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
            }
    except Exception as e:
        agent.status = "ERROR"
        db.commit()
        crud.create_log(db, agent_id, "ERROR", f"Execution failed: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))
    
    # ìƒíƒœ ì „ì´: WORKING â†’ IDLE
    agent.status = "IDLE"
    db.commit()
    crud.create_log(db, agent_id, "INFO", f"Agent '{agent.name}' cycle complete. Status â†’ IDLE")
    
    return result

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Agent Evolution (Sprint 15)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.post("/system/evolve")
def run_evolution(db: Session = Depends(get_db)):
    """ì—ì´ì „íŠ¸ ì„±ê³¼ í‰ê°€ ë° ì„¸ëŒ€ ì§„í™”ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤ (v2)."""
    from api.agents.evolution import run_evolution_cycle
    
    # Managerë¥¼ WORKING ìƒíƒœë¡œ
    manager = db.query(models.Agent).filter(models.Agent.role == "Coordinator").first()
    if manager:
        manager.status = "WORKING"
        db.commit()
        crud.create_log(db, manager.id, "INFO", "Evolution Cycle ì‹œì‘ (v2)")
    
    try:
        evo_logs, evolved_agents = run_evolution_cycle(db)
        
        # ë¡œê·¸ ê¸°ë¡
        agent_id = manager.id if manager else None
        for entry in evo_logs:
            crud.create_log(db, agent_id, "INFO", f"[{entry['step']}] {entry['message']}")
        
    except Exception as e:
        if manager:
            manager.status = "ERROR"
            db.commit()
            crud.create_log(db, manager.id, "ERROR", f"Evolution failed: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))
    
    if manager:
        manager.status = "IDLE"
        db.commit()
        crud.create_log(db, manager.id, "INFO", "Evolution Cycle ì™„ë£Œ")
    
    return {
        "status": "COMPLETE",
        "evolved_agents": [
            {"name": a["name"], "role": a["role"], "generation": a["generation"],
             "specialization": a["specialization"], "parent_score": a["parent_score"]}
            for a in evolved_agents
        ],
        "total_logs": len(evo_logs),
    }

@app.get("/system/evolution/status")
def get_evo_status():
    """ì§„í™” ì‹œìŠ¤í…œ í˜„í™© (ì „ëµ ë©”ëª¨ë¦¬ + ëˆ„ì  ì„±ê³¼) ì¡°íšŒ"""
    from api.agents.evolution import get_evolution_status
    return get_evolution_status()

@app.get("/system/evolution-tree")
def get_evolution_tree(db: Session = Depends(get_db)):
    """ì„¸ëŒ€ë³„ ì—ì´ì „íŠ¸ ì§„í™” íŠ¸ë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    agents = db.query(models.Agent).all()
    
    tree = []
    for agent in agents:
        tree.append({
            "id": agent.id,
            "name": agent.name,
            "role": agent.role,
            "generation": agent.generation or 1,
            "parent_id": agent.parent_id,
            "status": agent.status,
            "config": agent.config,
            "created_at": agent.created_at.isoformat() if agent.created_at else None,
        })
    
    return {"agents": tree}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Research Cycle Dashboard (Sprint 16)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.get("/system/cycles")
def get_research_cycles(db: Session = Depends(get_db)):
    """ì—°êµ¬ ì‚¬ì´í´ íˆìŠ¤í† ë¦¬ë¥¼ ë¡œê·¸ ê¸°ë°˜ìœ¼ë¡œ ì§‘ê³„í•©ë‹ˆë‹¤."""
    all_logs = db.query(models.SystemLog).order_by(models.SystemLog.created_at.asc()).all()
    
    cycles = []
    current_cycle = None
    
    for log in all_logs:
        msg = log.message or ""
        
        # ì‚¬ì´í´ ì‹œì‘ ê°ì§€
        if "Research Cycle ì‹œì‘" in msg or "ORCHESTRATE" in msg and "Research Cycle ì‹œì‘" in msg:
            current_cycle = {
                "id": len(cycles) + 1,
                "started_at": log.created_at.isoformat() if log.created_at else None,
                "ended_at": None,
                "status": "RUNNING",
                "phases": {"theorist": [], "engineer": [], "critic": []},
                "hypotheses": 0,
                "experiments": 0,
                "reviews": 0,
                "verdict": None,
                "logs": [],
            }
        
        if current_cycle:
            current_cycle["logs"].append({
                "message": msg,
                "level": log.level,
                "agent_id": log.agent_id,
                "timestamp": log.created_at.isoformat() if log.created_at else None,
            })
            
            # ê°€ì„¤ ì¹´ìš´íŠ¸
            if "ê°€ì„¤ ìƒì„±" in msg or "Hypothesis" in msg:
                current_cycle["hypotheses"] += 1
            
            # ì‹¤í—˜ ì¹´ìš´íŠ¸
            if "ì‹¤í—˜" in msg and ("ì„¤ê³„" in msg or "ì‹¤í–‰" in msg):
                current_cycle["experiments"] += 1
            
            # ë¦¬ë·° ì¹´ìš´íŠ¸
            if "ê²€í† " in msg or "Review" in msg or "íŒì •" in msg:
                current_cycle["reviews"] += 1
            
            # íŒì • ì¶”ì¶œ
            if "ACCEPT" in msg:
                current_cycle["verdict"] = "ACCEPT"
            elif "REVISE" in msg:
                current_cycle["verdict"] = "REVISE"
            elif "REJECT" in msg:
                current_cycle["verdict"] = "REJECT"
            
            # ì‚¬ì´í´ ì™„ë£Œ ê°ì§€
            if "Research Cycle ì™„ë£Œ" in msg or "cycle complete" in msg.lower():
                current_cycle["ended_at"] = log.created_at.isoformat() if log.created_at else None
                current_cycle["status"] = "COMPLETE"
                cycles.append(current_cycle)
                current_cycle = None
    
    # ì•„ì§ ì§„í–‰ ì¤‘ì¸ ì‚¬ì´í´
    if current_cycle:
        current_cycle["status"] = "RUNNING"
        cycles.append(current_cycle)
    
    # í†µê³„ ì§‘ê³„
    stats = {
        "total_cycles": len(cycles),
        "completed_cycles": sum(1 for c in cycles if c["status"] == "COMPLETE"),
        "total_hypotheses": sum(c["hypotheses"] for c in cycles),
        "total_experiments": sum(c["experiments"] for c in cycles),
        "total_reviews": sum(c["reviews"] for c in cycles),
        "verdicts": {
            "ACCEPT": sum(1 for c in cycles if c.get("verdict") == "ACCEPT"),
            "REVISE": sum(1 for c in cycles if c.get("verdict") == "REVISE"),
            "REJECT": sum(1 for c in cycles if c.get("verdict") == "REJECT"),
        },
    }
    
    # ë¡œê·¸ ìƒì„¸ëŠ” ìµœê·¼ 5ê°œ ì‚¬ì´í´ë§Œ
    for cycle in cycles:
        cycle["log_count"] = len(cycle["logs"])
        if len(cycles) > 5:
            cycle.pop("logs", None)
    
    return {"cycles": cycles, "stats": stats}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Auto Research Report (Sprint 17)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.get("/system/report")
def get_research_report():
    """ìë™ ì—°êµ¬ ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    from api.agents.report_generator import generate_report
    return generate_report()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Academic Forum (Sprint 18)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.post("/system/forum")
def run_forum(db: Session = Depends(get_db)):
    """ì—ì´ì „íŠ¸ ê°„ í•™ìˆ  í† ë¡ ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    from api.agents.forum import run_forum_debate
    
    result = run_forum_debate()
    
    # ë¡œê·¸ ê¸°ë¡
    manager = db.query(models.Agent).filter(models.Agent.role == "Coordinator").first()
    agent_id = manager.id if manager else None
    crud.create_log(db, agent_id, "INFO", f"[FORUM] ë…¼ì œ: {result['topic']['topic']}")
    crud.create_log(db, agent_id, "INFO", f"[FORUM] í•©ì˜: {result['consensus']['label']}")
    
    return result

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Autopilot Mode (Sprint 19)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.post("/system/autopilot/start")
def start_autopilot():
    """Autopilot ììœ¨ ìˆœí™˜ì„ ì‹œì‘í•©ë‹ˆë‹¤."""
    from api.agents.autopilot import autopilot
    return autopilot.start(db_factory=SessionLocal)

@app.post("/system/autopilot/stop")
def stop_autopilot():
    """Autopilotì„ ì •ì§€í•©ë‹ˆë‹¤."""
    from api.agents.autopilot import autopilot
    return autopilot.stop()

@app.get("/system/autopilot/status")
def autopilot_status():
    """Autopilot ìƒíƒœë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
    from api.agents.autopilot import autopilot
    return autopilot.get_status()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Method Registry (Sprint 21)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.get("/system/methods")
def get_methods_status():
    """ì ì‘í˜• ë©”ì„œë“œ ë ˆì§€ìŠ¤íŠ¸ë¦¬ í˜„í™©ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
    from api.agents.method_registry import method_registry
    return method_registry.get_stats()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Lab Director & Autonomous Agenda (Sprint 28)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from engine.agents.director import LabDirector

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ ê²½ë¡œ ì‚¬ìš©
_lab_director = LabDirector(knowledge_path=str(ROOT / "data" / "grand_challenges.json"))

@app.get("/system/director/agenda")
def get_director_agenda():
    """ì—°êµ¬ì†Œì¥ì˜ í˜„ì¬ ì—°êµ¬ ì•„ì  ë‹¤ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
    return _lab_director.get_current_agenda()

@app.post("/system/director/agenda/next")
def next_director_agenda():
    """ì—°êµ¬ì†Œì¥ì´ ìƒˆë¡œìš´ ì—°êµ¬ ì£¼ì œë¥¼ ì„ íƒí•©ë‹ˆë‹¤."""
    return _lab_director.set_agenda()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Sandbox & ConstitutionGuard (Sprint 29)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.get("/system/sandbox/status")
def get_sandbox_status():
    """SandboxExecutor ì‹¤í–‰ í†µê³„ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
    from engine.sandbox.executor import sandbox
    return sandbox.get_stats()

@app.post("/system/sandbox/reset")
def reset_sandbox_circuit_breaker():
    """íšŒë¡œ ì°¨ë‹¨ê¸°ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ë¦¬ì…‹í•©ë‹ˆë‹¤."""
    from engine.sandbox.executor import sandbox
    sandbox.reset_circuit_breaker()
    return {"status": "ok", "message": "íšŒë¡œ ì°¨ë‹¨ê¸°ê°€ ë¦¬ì…‹ë˜ì—ˆìŠµë‹ˆë‹¤."}

@app.get("/system/constitution/info")
def get_constitution_info():
    """ì—°êµ¬ í—Œë²• ê°€ë“œë ˆì¼ ì„¤ì • ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
    from api.guards.constitution_guard import ConstitutionGuard
    return {
        "version": "v1.0",
        "rules": {
            "ì œ1ì¡°_ë°˜ì¦í…ŒìŠ¤íŠ¸_ìµœì†Œí†µê³¼": ConstitutionGuard.MIN_REFUTATION_PASSED,
            "ì œ4ì¡°_ìµœì†Œë°©ë²•ë¡ ìˆ˜": ConstitutionGuard.MIN_METHODS_COUNT,
            "ì œ5ì¡°_í‘œë³¸í¬ê¸°_ìµœì†Œ": ConstitutionGuard.SAMPLE_SIZE_MIN,
            "ì œ5ì¡°_í‘œë³¸í¬ê¸°_ê¶Œì¥": ConstitutionGuard.SAMPLE_SIZE_RECOMMENDED,
            "ì œ12ì¡°_ë©”ì„œë“œì§‘ì¤‘ë„_ìƒí•œ": ConstitutionGuard.METHOD_CONCENTRATION_LIMIT,
        },
    }

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Log Rotation & DB Health (Sprint 30)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.get("/system/db/status")
def get_db_status():
    """DB ìƒíƒœ ë° ë¡œê·¸ ë¡œí…Œì´ì…˜ í˜„í™©ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
    from api.log_rotation import log_rotation
    return log_rotation.get_status()

@app.post("/system/db/rotate")
def run_log_rotation():
    """ìˆ˜ë™ìœ¼ë¡œ ë¡œê·¸ ë¡œí…Œì´ì…˜ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    from api.log_rotation import log_rotation
    return log_rotation.rotate()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# STEAM Synthetic Data (Sprint 31)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.get("/system/steam/dgps")
def get_steam_dgps():
    """ì‚¬ìš© ê°€ëŠ¥í•œ STEAM DGP í…œí”Œë¦¿ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
    from engine.data.steam_generator import steam, DGP_TEMPLATES
    return {
        "available_dgps": steam.available_dgps,
        "templates": {
            name: {
                "name": t.name,
                "grand_challenge_id": t.grand_challenge_id,
                "category": t.category,
                "treatment": t.treatment_name,
                "outcome": t.outcome_name,
                "confounders": t.confounders,
                "moderators": t.moderators,
                "n_default": t.n_default,
                "effect_type": t.effect_type,
            }
            for name, t in DGP_TEMPLATES.items()
        },
    }

@app.post("/system/steam/generate")
def generate_steam_data(dgp_name: str, n: int = 3000, seed: int = 42):
    """STEAM í•©ì„± ë°ì´í„°ë¥¼ ìƒì„±í•˜ê³  ìš”ì•½ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    from engine.data.steam_generator import steam
    try:
        data = steam.generate(dgp_name, n=n, seed=seed)
        metrics = steam.evaluate_quality(data)
        return {
            "status": "ok",
            "dgp": dgp_name,
            "sample_size": data.n,
            "ate_true": data.ate_true,
            "columns": list(data.df.columns),
            "head": data.df.head(5).to_dict(orient="records"),
            "quality_metrics": metrics,
        }
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.get("/system/agent-registry")
def get_agent_registry():
    """ì—ì´ì „íŠ¸ ì¤‘ì•™ ë ˆì§€ìŠ¤íŠ¸ë¦¬ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
    from api.agent_registry import get_registry_summary
    return get_registry_summary()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Architect & Hot-Swap (Sprint 33)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.get("/system/architect/diagnose")
def run_architect_diagnosis():
    """Architectê°€ ì „ì²´ ì‹œìŠ¤í…œ ì§„ë‹¨ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    from engine.agents.architect import architect
    result = architect.diagnose()
    return result.to_dict()

@app.post("/system/architect/hot-swap")
def hot_swap_module(module_name: str):
    """ëª¨ë“ˆì„ ëŸ°íƒ€ì„ í•« ìŠ¤ì™‘í•©ë‹ˆë‹¤."""
    from engine.utils.reloader import reloader
    result = reloader.hot_swap(module_name)
    return result.to_dict()

@app.get("/system/architect/backups")
def get_swap_backups():
    """í•« ìŠ¤ì™‘ ë°±ì—… ë° ì´ë ¥ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
    from engine.utils.reloader import reloader
    return {
        "backups": reloader.list_backups(),
        "swap_history": reloader.get_history(),
    }

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Paper & SaaS (Sprint 34)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.post("/system/paper/draft")
def generate_paper_draft(grand_challenge_id: Optional[str] = None, include_latex: bool = False):
    """ë…¼ë¬¸ ì´ˆì•ˆì„ ìë™ ìƒì„±í•©ë‹ˆë‹¤."""
    from engine.paper.draft_generator import paper_generator
    return paper_generator.generate_draft(grand_challenge_id, include_latex)

@app.get("/system/saas/readiness")
def get_saas_readiness():
    """SaaS ì „í™˜ ì¤€ë¹„ë„ë¥¼ í‰ê°€í•©ë‹ˆë‹¤."""
    from engine.paper.saas_blueprint import saas_blueprint
    return saas_blueprint.assess_readiness()

@app.get("/system/saas/migration-plan")
def get_migration_plan():
    """SaaS ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íšì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
    from engine.paper.saas_blueprint import saas_blueprint
    return saas_blueprint.get_migration_plan()

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("api.main:app", host="0.0.0.0", port=4001, reload=True)
