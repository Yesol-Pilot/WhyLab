# -*- coding: utf-8 -*-
"""RefutationCell â€” ì§„ì§œ ì¸ê³¼ íš¨ê³¼ ë°˜ì¦ ì—”ì§„.

Mockì´ ì•„ë‹Œ ì‹¤ì œ ëª¨ë¸ ì¬í•™ìŠµ ê¸°ë°˜ ë°˜ì¦ í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
- Placebo Test: Treatment ë¬´ì‘ìœ„ ì…”í”Œ â†’ ëª¨ë¸ ì¬í•™ìŠµ â†’ Null ATE ë¶„í¬
- Bootstrap CI: ë¹„ëª¨ìˆ˜ ë¶€íŠ¸ìŠ¤íŠ¸ë© â†’ ATE ì‹ ë¢°êµ¬ê°„
- Leave-One-Out Confounder: êµë€ ë³€ìˆ˜ ì œê±° â†’ ATE ì•ˆì •ì„±
- Subset Validation: ë°ì´í„° í¬ê¸°ë³„ ì•ˆì •ì„± ê²€ì¦
"""

from __future__ import annotations

import logging
from typing import Any, Dict, List

import numpy as np
import pandas as pd

from engine.cells.base_cell import BaseCell
from engine.config import WhyLabConfig


class RefutationCell(BaseCell):
    """ì‹¤ì œ ëª¨ë¸ ì¬í•™ìŠµ ê¸°ë°˜ ì¸ê³¼ íš¨ê³¼ ë°˜ì¦ ì…€.

    ê¸°ì¡´ SensitivityCellì˜ Mock ì½”ë“œë¥¼ ëŒ€ì²´í•©ë‹ˆë‹¤.
    ë§¤ ë°˜ì¦ë§ˆë‹¤ DML ëª¨ë¸ì„ ì¬í•™ìŠµí•˜ì—¬ ì§„ì§œ Null ë¶„í¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """

    def __init__(self, config: WhyLabConfig) -> None:
        super().__init__(name="refutation_cell", config=config)

    def execute(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """ì „ì²´ ë°˜ì¦ íŒŒì´í”„ë¼ì¸ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

        Args:
            inputs: CausalCell ì¶œë ¥ + ì›ë³¸ ë°ì´í„°.
                í•„ìˆ˜: dataframe, feature_names, treatment_col, outcome_col,
                      ate, model_type, discrete_treatment

        Returns:
            ë°˜ì¦ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ (ê° í…ŒìŠ¤íŠ¸ì˜ Pass/Fail, ë¶„í¬, p-value).
        """
        self.validate_inputs(
            inputs,
            ["dataframe", "feature_names", "treatment_col", "outcome_col", "ate"],
        )

        df = inputs["dataframe"]
        X_cols = inputs["feature_names"]
        T_col = inputs["treatment_col"]
        Y_col = inputs["outcome_col"]
        original_ate = inputs["ate"]
        is_discrete = inputs.get("discrete_treatment", False)
        cfg = self.config.sensitivity

        results = {}

        # â”€â”€ 1. Placebo Treatment Test â”€â”€
        if cfg.placebo_treatment:
            self.logger.info("ğŸ”¬ [Refutation 1/4] Placebo Test ì‹œì‘ (n=%d)", cfg.n_refutation_iter)
            results["placebo_test"] = self._placebo_test(
                df, T_col, Y_col, X_cols, original_ate,
                is_discrete, n_iter=cfg.n_refutation_iter,
            )

        # â”€â”€ 2. Bootstrap CI â”€â”€
        self.logger.info("ğŸ”¬ [Refutation 2/4] Bootstrap CI ì‹œì‘ (n=%d)", cfg.n_bootstrap)
        results["bootstrap"] = self._bootstrap_ci(
            df, T_col, Y_col, X_cols, is_discrete,
            n_boot=cfg.n_bootstrap,
        )

        # â”€â”€ 3. Leave-One-Out Confounder â”€â”€
        self.logger.info("ğŸ”¬ [Refutation 3/4] Leave-One-Out Confounder ì‹œì‘")
        results["leave_one_out"] = self._leave_one_out_confounder(
            df, T_col, Y_col, X_cols, original_ate, is_discrete,
        )

        # â”€â”€ 4. Subset Validation â”€â”€
        self.logger.info("ğŸ”¬ [Refutation 4/4] Subset Validation ì‹œì‘")
        results["subset"] = self._subset_validation(
            df, T_col, Y_col, X_cols, original_ate, is_discrete,
        )

        # Overall íŒì •
        pass_count = sum(
            1 for v in results.values()
            if isinstance(v, dict) and v.get("status") == "Pass"
        )
        total = len(results)
        results["overall"] = {
            "pass_count": pass_count,
            "total": total,
            "status": "Pass" if pass_count >= total * 0.75 else "Fail",
        }

        self.logger.info(
            "ğŸ›¡ï¸ ë°˜ì¦ ì¢…í•©: %d/%d Pass â†’ %s",
            pass_count, total, results["overall"]["status"],
        )

        return {**inputs, "refutation_results": results}

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 1. Placebo Treatment Test
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _placebo_test(
        self,
        df: pd.DataFrame,
        T_col: str,
        Y_col: str,
        X_cols: List[str],
        original_ate: float,
        is_discrete: bool,
        n_iter: int = 20,
    ) -> Dict[str, Any]:
        """Treatmentë¥¼ ë¬´ì‘ìœ„ ì…”í”Œ í›„ ëª¨ë¸ ì¬í•™ìŠµ â†’ Null ATE ë¶„í¬ ìƒì„±.

        Hâ‚€: Treatmentê°€ Outcomeì— ì˜í–¥ ì—†ìŒ
        ê²€ì¦: ì…”í”Œëœ Treatmentë¡œ ì¶”ì •í•œ ATEê°€ 0 ê·¼ì²˜ì— ë¶„í¬í•´ì•¼ í•¨.
        """
        null_ates = []

        for i in range(n_iter):
            df_shuf = df.copy()
            df_shuf[T_col] = np.random.permutation(df[T_col].values)

            ate_null = self._fit_and_estimate_ate(
                df_shuf, T_col, Y_col, X_cols, is_discrete,
            )
            null_ates.append(ate_null)

            if (i + 1) % 5 == 0:
                self.logger.info("      Placebo iter %d/%d, null_ate=%.5f", i + 1, n_iter, ate_null)

        null_ates = np.array(null_ates)
        # p-value: |null_ate| â‰¥ |original_ate| ì¸ ë¹„ìœ¨
        p_value = float(np.mean(np.abs(null_ates) >= np.abs(original_ate)))
        null_mean = float(np.mean(null_ates))
        null_std = float(np.std(null_ates))

        return {
            "null_mean": null_mean,
            "null_std": null_std,
            "p_value": p_value,
            "original_ate": original_ate,
            "n_iter": n_iter,
            "status": "Pass" if p_value < 0.05 else "Fail",
            "interpretation": (
                f"Placebo ATE í‰ê· ={null_mean:.5f} (â‰ˆ0), "
                f"ì›ë˜ ATE={original_ate:.5f}ëŠ” Null ë¶„í¬ì—ì„œ "
                f"{'ì´ë¡€ì  (p={p_value:.3f}<0.05) â†’ ì§„ì§œ íš¨ê³¼' if p_value < 0.05 else 'êµ¬ë³„ ë¶ˆê°€'}"
            ),
        }

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 2. Bootstrap CI
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _bootstrap_ci(
        self,
        df: pd.DataFrame,
        T_col: str,
        Y_col: str,
        X_cols: List[str],
        is_discrete: bool,
        n_boot: int = 100,
        alpha: float = 0.05,
    ) -> Dict[str, Any]:
        """ë¹„ëª¨ìˆ˜ ë¶€íŠ¸ìŠ¤íŠ¸ë© â†’ ATE ì‹ ë¢°êµ¬ê°„.

        ì •ê·œë¶„í¬ ê°€ì • ì—†ì´,
        ë°ì´í„°ë¥¼ ë³µì›ì¶”ì¶œí•˜ì—¬ ê° ìƒ˜í”Œì˜ ATEë¥¼ ì¶”ì •í•©ë‹ˆë‹¤.
        """
        boot_ates = []
        n = len(df)

        for i in range(n_boot):
            idx = np.random.choice(n, n, replace=True)
            df_boot = df.iloc[idx].reset_index(drop=True)

            ate_boot = self._fit_and_estimate_ate(
                df_boot, T_col, Y_col, X_cols, is_discrete,
            )
            boot_ates.append(ate_boot)

            if (i + 1) % 25 == 0:
                self.logger.info("      Bootstrap iter %d/%d", i + 1, n_boot)

        boot_ates = np.array(boot_ates)
        ci_lower = float(np.percentile(boot_ates, 100 * alpha / 2))
        ci_upper = float(np.percentile(boot_ates, 100 * (1 - alpha / 2)))
        mean_ate = float(np.mean(boot_ates))
        std_ate = float(np.std(boot_ates))

        # 0ì´ CIì— í¬í•¨ë˜ë©´ ìœ ì˜í•˜ì§€ ì•ŠìŒ
        significant = not (ci_lower <= 0 <= ci_upper)

        return {
            "mean_ate": mean_ate,
            "std_ate": std_ate,
            "ci_lower": ci_lower,
            "ci_upper": ci_upper,
            "n_boot": n_boot,
            "significant": significant,
            "status": "Pass" if significant else "Fail",
            "interpretation": (
                f"Bootstrap 95% CI: [{ci_lower:.5f}, {ci_upper:.5f}], "
                f"{'0ì„ í¬í•¨í•˜ì§€ ì•ŠìŒ â†’ í†µê³„ì ìœ¼ë¡œ ìœ ì˜' if significant else '0ì„ í¬í•¨ â†’ ìœ ì˜í•˜ì§€ ì•ŠìŒ'}"
            ),
        }

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 3. Leave-One-Out Confounder
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _leave_one_out_confounder(
        self,
        df: pd.DataFrame,
        T_col: str,
        Y_col: str,
        X_cols: List[str],
        original_ate: float,
        is_discrete: bool,
    ) -> Dict[str, Any]:
        """êµë€ ë³€ìˆ˜ë¥¼ í•˜ë‚˜ì”© ì œê±° í›„ ATE ë³€í™” ì¸¡ì •.

        ëª©ì : ê° êµë€ ë³€ìˆ˜ì˜ ê¸°ì—¬ë„ì™€ ATEì˜ ì•ˆì •ì„± íŒŒì•….
        ATE ë¶€í˜¸ê°€ ë’¤ì§‘íˆë©´ í•´ë‹¹ ë³€ìˆ˜ê°€ í•µì‹¬ êµë€ì„.
        """
        loo_results = []

        for excluded in X_cols:
            remaining = [c for c in X_cols if c != excluded]
            if not remaining:
                continue

            ate_loo = self._fit_and_estimate_ate(
                df, T_col, Y_col, remaining, is_discrete,
            )
            delta = ate_loo - original_ate
            sign_flip = (np.sign(ate_loo) != np.sign(original_ate))

            loo_results.append({
                "excluded_variable": excluded,
                "ate_without": float(ate_loo),
                "delta": float(delta),
                "pct_change": float(abs(delta) / (abs(original_ate) + 1e-10) * 100),
                "sign_flip": bool(sign_flip),
            })
            self.logger.info(
                "      LOO [-%s]: ATE=%.5f (Î”=%.5f, %s)",
                excluded, ate_loo, delta,
                "âš ï¸ ë¶€í˜¸ ë°˜ì „!" if sign_flip else "ì•ˆì •",
            )

        # ìµœëŒ€ ë³€í™”ìœ¨ ê¸°ì¤€ íŒì •
        max_change = max(r["pct_change"] for r in loo_results) if loo_results else 0
        any_flip = any(r["sign_flip"] for r in loo_results)

        return {
            "results": loo_results,
            "max_pct_change": max_change,
            "any_sign_flip": any_flip,
            "status": "Fail" if any_flip else ("Pass" if max_change < 50 else "Warning"),
            "interpretation": (
                f"ìµœëŒ€ ATE ë³€í™”: {max_change:.1f}%. "
                + ("ë¶€í˜¸ ë°˜ì „ ê°ì§€ â†’ í•µì‹¬ êµë€ ì¡´ì¬ ê°€ëŠ¥" if any_flip else "ëª¨ë“  ë³€ìˆ˜ ì œê±° í›„ì—ë„ ë°©í–¥ ì¼ê´€")
            ),
        }

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 4. Subset Validation
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _subset_validation(
        self,
        df: pd.DataFrame,
        T_col: str,
        Y_col: str,
        X_cols: List[str],
        original_ate: float,
        is_discrete: bool,
        fractions: list = None,
    ) -> Dict[str, Any]:
        """ì„œë¸Œìƒ˜í”Œ ì•ˆì •ì„±: ë°ì´í„° ë¹„ìœ¨ë³„ ATE ì•ˆì •ì„± ê²€ì¦.

        50%, 70%, 90% ì„œë¸Œìƒ˜í”Œì—ì„œ ATEê°€ ì•ˆì •ì ì´ë©´ ê²¬ê³ .
        """
        if fractions is None:
            fractions = [0.5, 0.7, 0.9]

        subset_results = []
        n = len(df)

        for frac in fractions:
            sub_n = int(n * frac)
            idx = np.random.choice(n, sub_n, replace=False)
            df_sub = df.iloc[idx].reset_index(drop=True)

            ate_sub = self._fit_and_estimate_ate(
                df_sub, T_col, Y_col, X_cols, is_discrete,
            )
            delta = ate_sub - original_ate
            stability = 1.0 - abs(delta) / (abs(original_ate) + 1e-10)

            subset_results.append({
                "fraction": frac,
                "n_samples": sub_n,
                "ate": float(ate_sub),
                "delta": float(delta),
                "stability": float(max(0, stability)),
            })
            self.logger.info(
                "      Subset %.0f%% (n=%d): ATE=%.5f, stability=%.3f",
                frac * 100, sub_n, ate_sub, stability,
            )

        avg_stability = float(np.mean([r["stability"] for r in subset_results]))

        return {
            "results": subset_results,
            "avg_stability": avg_stability,
            "status": "Pass" if avg_stability > 0.8 else "Fail",
            "interpretation": (
                f"í‰ê·  ì•ˆì •ì„±: {avg_stability:.3f} "
                f"{'(>0.8 â†’ ê²¬ê³ )' if avg_stability > 0.8 else '(<0.8 â†’ ë¶ˆì•ˆì •)'}"
            ),
        }

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ê³µí†µ ìœ í‹¸: DML ì¬í•™ìŠµ â†’ ATE
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _fit_and_estimate_ate(
        self,
        df: pd.DataFrame,
        T_col: str,
        Y_col: str,
        X_cols: List[str],
        is_discrete: bool,
    ) -> float:
        """DML ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ATEë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

        ê²½ëŸ‰ ì„¤ì •(CV=2, estimators=100)ìœ¼ë¡œ ë¹ ë¥´ê²Œ ì¬í•™ìŠµí•©ë‹ˆë‹¤.
        """
        from econml.dml import LinearDML
        from engine.gpu_factory import create_lgbm_regressor

        Y = df[Y_col].values.astype(np.float64)
        T = df[T_col].values.astype(np.float64)
        X = df[X_cols].values.astype(np.float64)

        # ì—°ì†í˜• Treatment ì •ê·œí™”
        if not is_discrete:
            t_mean, t_std = float(T.mean()), float(T.std())
            if t_std > 0:
                T = (T - t_mean) / t_std

        # ê²½ëŸ‰ nuisance ëª¨ë¸ (GPU ê°€ì† + ë°˜ì¦ ìµœì í™”)
        model_y = create_lgbm_regressor(self.config, lightweight=True)
        model_t = create_lgbm_regressor(self.config, lightweight=True)

        model = LinearDML(
            model_y=model_y,
            model_t=model_t,
            discrete_treatment=is_discrete,
            cv=2,  # ë°˜ì¦ìš© ê²½ëŸ‰ CV
            random_state=self.config.data.random_seed,
        )
        model.fit(Y=Y, T=T, X=X)

        # ATE = CATE í‰ê· 
        cate = model.effect(X)
        return float(np.mean(cate))
