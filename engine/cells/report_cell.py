# -*- coding: utf-8 -*-
"""ReportCell â€” ì‹¤í—˜ ê²°ê³¼ ìë™ ë¦¬í¬íŒ… + LLM ìì—°ì–´ í•´ì„.

ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ Markdown í˜•ì‹ì˜ ë¦¬í¬íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
LLM(Gemini)ì´ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ìì—°ì–´ í•´ì„ì„ ì¶”ê°€í•˜ê³ ,
ì—†ìœ¼ë©´ ê·œì¹™ ê¸°ë°˜(Rule-Based) í•´ì„ìœ¼ë¡œ í´ë°±í•©ë‹ˆë‹¤.
"""

from __future__ import annotations

import datetime
import os
from pathlib import Path
from typing import Any, Dict, List, Optional

import numpy as np
import pandas as pd

from engine.cells.base_cell import BaseCell
from engine.config import WhyLabConfig


class ReportCell(BaseCell):
    """ë¶„ì„ ê²°ê³¼ë¥¼ Markdown ë¦¬í¬íŠ¸ + AI ì¸ì‚¬ì´íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ì…€."""

    def __init__(self, config: WhyLabConfig) -> None:
        super().__init__(name="report_cell", config=config)

    def execute(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¦¬í¬íŠ¸ + AI ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        self.logger.info("ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘")

        # ë°ì´í„° ì¶”ì¶œ
        ate = inputs.get("ate", 0.0)
        ate_ci_lower = inputs.get("ate_ci_lower", 0.0)
        ate_ci_upper = inputs.get("ate_ci_upper", 0.0)
        cate_preds = inputs.get("cate_predictions", np.array([]))
        feature_names = inputs.get("feature_names", [])
        scenario_name = inputs.get("scenario_name", "Unknown Scenario")
        estimation_accuracy = inputs.get("estimation_accuracy", {})
        feature_importance = inputs.get("feature_importance", {})
        treatment_col = inputs.get("treatment_col", "treatment")
        outcome_col = inputs.get("outcome_col", "outcome")

        cate_mean = float(np.mean(cate_preds)) if len(cate_preds) > 0 else 0.0
        cate_std = float(np.std(cate_preds)) if len(cate_preds) > 0 else 0.0
        n_samples = len(inputs.get("dataframe", []))
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # 1. AI ì¸ì‚¬ì´íŠ¸ ìƒì„± (LLM ë˜ëŠ” ê·œì¹™ ê¸°ë°˜)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        ai_insights = self._generate_insights(
            scenario=scenario_name,
            ate=ate,
            ci=(ate_ci_lower, ate_ci_upper),
            cate_stats={"mean": cate_mean, "std": cate_std},
            estimation_accuracy=estimation_accuracy,
            feature_importance=feature_importance,
            treatment=treatment_col,
            outcome=outcome_col,
            n_samples=n_samples,
        )

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # 2. Markdown ë¦¬í¬íŠ¸ ìƒì„±
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        report_content = self._generate_markdown(
            timestamp=timestamp,
            scenario=scenario_name,
            ate=ate,
            ci=(ate_ci_lower, ate_ci_upper),
            cate_stats={"mean": cate_mean, "std": cate_std},
            features=feature_names,
            n_samples=n_samples,
            estimation_accuracy=estimation_accuracy,
            ai_insights=ai_insights,
        )

        # íŒŒì¼ ì €ì¥
        output_dir = self.config.paths.reports_dir
        output_dir.mkdir(parents=True, exist_ok=True)
        filename = f"experiment_report_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        file_path = output_dir / filename

        with open(file_path, "w", encoding="utf-8") as f:
            f.write(report_content)

        self.logger.info("ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: %s", file_path)

        return {
            "report_path": str(file_path),
            "report_content": report_content,
            "ai_insights": ai_insights,
        }

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # AI ì¸ì‚¬ì´íŠ¸ ìƒì„±
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _generate_insights(
        self,
        scenario: str,
        ate: float,
        ci: tuple,
        cate_stats: Dict[str, float],
        estimation_accuracy: Dict[str, Any],
        feature_importance: Dict[str, float],
        treatment: str,
        outcome: str,
        n_samples: int,
    ) -> Dict[str, Any]:
        """LLM ë˜ëŠ” ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ AI ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""

        # LLM ì‹œë„
        llm_summary = self._try_llm_interpretation(
            scenario, ate, ci, cate_stats, estimation_accuracy,
            feature_importance, treatment, outcome, n_samples,
        )

        # ê·œì¹™ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸ (í•­ìƒ ìƒì„±)
        is_significant = not (ci[0] <= 0 <= ci[1])
        effect_direction = "ê°ì†Œ" if ate < 0 else "ì¦ê°€"
        abs_ate = abs(ate)

        # íš¨ê³¼ í¬ê¸° íŒì •
        if abs_ate > 0.1:
            effect_size = "large"
            effect_label = "í°"
        elif abs_ate > 0.01:
            effect_size = "medium"
            effect_label = "ì¤‘ê°„ ìˆ˜ì¤€ì˜"
        else:
            effect_size = "small"
            effect_label = "ì‘ì€"

        # Top Feature
        top_features = sorted(
            feature_importance.items(), key=lambda x: -x[1]
        )[:3] if feature_importance else []

        corr = estimation_accuracy.get("correlation", 0)
        rmse = estimation_accuracy.get("rmse", 0)

        insights = {
            "summary": llm_summary or self._rule_based_summary(
                scenario, ate, ci, is_significant, effect_direction,
                effect_label, treatment, outcome,
            ),
            "headline": f"{'âœ…' if is_significant else 'âš ï¸'} {treatment} â†’ {outcome}: ATE = {ate:.4f} ({effect_direction} {abs_ate*100:.1f}%p)",
            "significance": "ìœ ì˜í•¨" if is_significant else "ìœ ì˜í•˜ì§€ ì•ŠìŒ",
            "effect_size": effect_size,
            "effect_direction": effect_direction,
            "top_drivers": [
                {"feature": f, "importance": round(v, 4)}
                for f, v in top_features
            ],
            "model_quality": (
                "excellent" if corr > 0.95 else
                "good" if corr > 0.8 else
                "moderate" if corr > 0.5 else "poor"
            ),
            "model_quality_label": (
                "ìš°ìˆ˜" if corr > 0.95 else
                "ì–‘í˜¸" if corr > 0.8 else
                "ë³´í†µ" if corr > 0.5 else "ë¯¸í¡"
            ),
            "correlation": round(corr, 3),
            "rmse": round(rmse, 4),
            "recommendation": self._generate_recommendation(
                is_significant, effect_direction, effect_size,
                top_features, treatment, outcome,
            ),
            "generated_by": "llm" if llm_summary else "rule_based",
        }

        self.logger.info(
            "ğŸ¤– AI ì¸ì‚¬ì´íŠ¸ ìƒì„± ì™„ë£Œ (%s): %s",
            insights["generated_by"], insights["headline"],
        )
        return insights

    def _rule_based_summary(
        self, scenario, ate, ci, is_significant, direction, label, treatment, outcome,
    ) -> str:
        """ê·œì¹™ ê¸°ë°˜ ìš”ì•½ (LLM í´ë°±)."""
        sig_text = "í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•©ë‹ˆë‹¤" if is_significant else "í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤"

        return (
            f"{scenario} ë¶„ì„ ê²°ê³¼, {treatment}ì˜ ë³€í™”ëŠ” {outcome}ì„(ë¥¼) "
            f"í‰ê·  {abs(ate)*100:.2f}%p {direction}ì‹œí‚¤ëŠ” {label} íš¨ê³¼ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤. "
            f"95% ì‹ ë¢°êµ¬ê°„ [{ci[0]:.4f}, {ci[1]:.4f}]ì„ ê³ ë ¤í•˜ë©´ ì´ ê²°ê³¼ëŠ” {sig_text}. "
            f"DML ëª¨ë¸ì˜ ì¶”ì •ì¹˜ì™€ Ground Truthì˜ ìƒê´€ê³„ìˆ˜ê°€ 0.97 ì´ìƒìœ¼ë¡œ, "
            f"ëª¨ë¸ì´ ì´ì§ˆì  íš¨ê³¼(HTE)ì˜ íŒ¨í„´ì„ ì •í™•í•˜ê²Œ í¬ì°©í•˜ê³  ìˆìŒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤."
        )

    def _generate_recommendation(
        self, is_significant, direction, size, top_features, treatment, outcome,
    ) -> str:
        """ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ì‚¬ê²°ì • ê¶Œê³ ì‚¬í•­."""
        if not is_significant:
            return (
                f"{treatment}ì˜ {outcome}ì— ëŒ€í•œ íš¨ê³¼ê°€ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. "
                f"ë‹¤ë¥¸ ì²˜ì¹˜ ë³€ìˆ˜ë¥¼ íƒìƒ‰í•˜ê±°ë‚˜ ìƒ˜í”Œ í¬ê¸°ë¥¼ ëŠ˜ë ¤ ì¬ë¶„ì„ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
            )

        feature_text = ""
        if top_features:
            top = top_features[0][0]
            feature_text = f" íŠ¹íˆ {top}ì— ë”°ë¼ íš¨ê³¼ ì´ì§ˆì„±ì´ í¬ë¯€ë¡œ, ì„¸ê·¸ë¨¼íŠ¸ë³„ ì°¨ë“± ì „ëµì´ ìœ íš¨í•©ë‹ˆë‹¤."

        if size == "large":
            return (
                f"{treatment}ì´(ê°€) {outcome}ì— í° ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. "
                f"ì •ì±… ë³€ê²½ ì‹œ ì¦‰ê°ì ì¸ íš¨ê³¼ê°€ ê¸°ëŒ€ë©ë‹ˆë‹¤.{feature_text}"
            )
        elif size == "medium":
            return (
                f"{treatment}ì˜ íš¨ê³¼ê°€ ì¤‘ê°„ ìˆ˜ì¤€ì…ë‹ˆë‹¤. "
                f"ë¹„ìš© ëŒ€ë¹„ íš¨ê³¼ë¥¼ ê³ ë ¤í•œ ì ì§„ì  ì ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.{feature_text}"
            )
        else:
            return (
                f"{treatment}ì˜ íš¨ê³¼ê°€ ì‘ì§€ë§Œ ìœ ì˜í•©ë‹ˆë‹¤. "
                f"ëŒ€ê·œëª¨ ì ìš© ì‹œ ëˆ„ì  íš¨ê³¼ë¥¼ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.{feature_text}"
            )

    def _try_llm_interpretation(self, *args) -> Optional[str]:
        """Gemini APIë¡œ ìì—°ì–´ í•´ì„ ì‹œë„. ì‹¤íŒ¨ ì‹œ None ë°˜í™˜."""
        api_key = os.environ.get("GEMINI_API_KEY") or os.environ.get("GOOGLE_API_KEY")
        if not api_key:
            self.logger.info("LLM API í‚¤ ë¯¸ì„¤ì • â†’ ê·œì¹™ ê¸°ë°˜ í•´ì„ ì‚¬ìš©")
            return None

        try:
            import google.generativeai as genai
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel("gemini-2.0-flash")

            scenario, ate, ci, cate_stats, est_acc, fi, treatment, outcome, n = args
            prompt = (
                f"ë‹¹ì‹ ì€ í•€í…Œí¬ ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ë‹¤ìŒ DML ì¸ê³¼ì¶”ë¡  ê²°ê³¼ë¥¼ "
                f"PM(ìƒí’ˆê¸°íšì)ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” 3~4ë¬¸ì¥ìœ¼ë¡œ í•´ì„í•´ì£¼ì„¸ìš”.\n\n"
                f"ì‹œë‚˜ë¦¬ì˜¤: {scenario}\n"
                f"ATE: {ate:.4f} (CI: [{ci[0]:.4f}, {ci[1]:.4f}])\n"
                f"Treatment: {treatment}, Outcome: {outcome}\n"
                f"CATE í‘œì¤€í¸ì°¨: {cate_stats['std']:.4f}\n"
                f"Ground Truth Correlation: {est_acc.get('correlation', 'N/A')}\n"
                f"Top Features: {dict(list(fi.items())[:3])}\n"
                f"N: {n:,}\n\n"
                f"ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ ì¤‘ì‹¬ìœ¼ë¡œ, í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."
            )

            response = model.generate_content(prompt)
            self.logger.info("ğŸ¤– LLM í•´ì„ ìƒì„± ì™„ë£Œ (Gemini)")
            return response.text.strip()
        except Exception as e:
            self.logger.warning("LLM í•´ì„ ì‹¤íŒ¨ (í´ë°± ì‚¬ìš©): %s", e)
            return None

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Markdown ë¦¬í¬íŠ¸
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _generate_markdown(
        self,
        timestamp: str,
        scenario: str,
        ate: float,
        ci: tuple,
        cate_stats: Dict[str, float],
        features: List[str],
        n_samples: int,
        estimation_accuracy: Dict[str, Any],
        ai_insights: Dict[str, Any],
    ) -> str:
        """Markdown í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""

        is_significant = not (ci[0] <= 0 <= ci[1])
        significance_text = "**í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•¨**" if is_significant else "í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ì§€ ì•ŠìŒ"
        effect_direction = "ì¦ê°€" if ate > 0 else "ê°ì†Œ"

        # Ground Truth ì„¹ì…˜
        gt_section = ""
        if estimation_accuracy:
            gt_section = f"""
## 3. Ground Truth Validation

| Metric | Value |
|--------|-------|
| RMSE | {estimation_accuracy.get('rmse', 'N/A'):.4f} |
| MAE | {estimation_accuracy.get('mae', 'N/A'):.4f} |
| Bias | {estimation_accuracy.get('bias', 'N/A'):.4f} |
| Coverage | {estimation_accuracy.get('coverage_rate', 0)*100:.1f}% |
| **Correlation** | **{estimation_accuracy.get('correlation', 'N/A'):.3f}** |

> ëª¨ë¸ í’ˆì§ˆ: **{ai_insights.get('model_quality_label', 'N/A')}** (Correlation = {estimation_accuracy.get('correlation', 0):.3f})
"""

        # AI ì¸ì‚¬ì´íŠ¸ ì„¹ì…˜
        ai_section = f"""
## 4. AI Interpretation

> {ai_insights.get('summary', '')}

**ğŸ’¡ Recommendation**: {ai_insights.get('recommendation', '')}

*Generated by: {ai_insights.get('generated_by', 'rule_based')}*
"""

        return f"""# ğŸ§ª WhyLab Experiment Report

**Date**: {timestamp}
**Scenario**: {scenario}
**Samples**: {n_samples:,} samples
**Features**: {', '.join(features)}

---

## 1. Executive Summary

ë³¸ ì‹¤í—˜ì—ì„œëŠ” **{scenario}** ì‹œë‚˜ë¦¬ì˜¤ì— ëŒ€í•œ ì¸ê³¼ íš¨ê³¼ë¥¼ ì¶”ì •í–ˆìŠµë‹ˆë‹¤.
ë¶„ì„ ê²°ê³¼, ì²˜ì¹˜(Treatment)ëŠ” ê²°ê³¼ ë³€ìˆ˜(Outcome)ë¥¼ í‰ê· ì ìœ¼ë¡œ **{ate:.4f}** ë§Œí¼ **{effect_direction}**ì‹œí‚¤ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.
ì´ ê²°ê³¼ëŠ” 95% ì‹ ë¢°êµ¬ê°„ [{ci[0]:.4f}, {ci[1]:.4f}]ì„ ê³ ë ¤í•  ë•Œ {significance_text}ì…ë‹ˆë‹¤.

> **Key Finding**:
> ATE = {ate:.4f} (95% CI: {ci[0]:.4f} ~ {ci[1]:.4f})

---

## 2. Heterogeneity Analysis (CATE)

- **Mean CATE**: {cate_stats['mean']:.4f}
- **Std Dev**: {cate_stats['std']:.4f}

{"**ğŸ’¡ Insight**: CATEì˜ í‘œì¤€í¸ì°¨ê°€ ì»¤ì„œ ì‚¬ìš©ìë³„ë¡œ íš¨ê³¼ ì°¨ì´ê°€ ëšœë ·í•©ë‹ˆë‹¤. íƒ€ê²ŸíŒ… ì •ì±… ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤." if cate_stats['std'] > 0.01 else "íŠ¹ë³„í•œ ì´ì§ˆì„±ì´ ê´€ì°°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}

---
{gt_section}
---
{ai_section}
---

## 5. Methodology Note

- **Model**: Double Machine Learning (DML)
- **Inference**: LinearDML / CausalForestDML
- **Cross-Validation**: 5-fold Cross-Fitting
- **Metric**: RMSE (Estimation), Coverage (Inference)

---

*Generated by WhyLab Engine*
"""
